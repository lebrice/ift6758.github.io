log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:27:38, val_loss: 8.651, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.001, l2_reg=0.0, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:28:37, val_loss: 1216.603, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.0, l2_reg=0.05, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:29:19, val_loss: 2086.142, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.05, l2_reg=0.005, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:29:59, val_loss: 24.617, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.0, l2_reg=0.005, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:30:55, val_loss: 31.546, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.001, l2_reg=0.0, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:31:36, val_loss: 7.119, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.0, l2_reg=0.01, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:32:35, val_loss: 923.683, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.05, l2_reg=0.05, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:33:19, val_loss: 6.828, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.0, l2_reg=0.0, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:33:57, val_loss: 21.676, hparams: HyperParameters(batch_size=256, num_layers=2, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.001, l2_reg=0.05, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:34:39, val_loss: 471.537, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.005, l2_reg=0.0, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:35:20, val_loss: 15.425, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.0, l2_reg=0.0, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:36:01, val_loss: 850.082, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.01, l2_reg=0.01, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:36:41, val_loss: 10.238, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.001, l2_reg=0.005, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:37:49, val_loss: 44.791, hparams: HyperParameters(batch_size=256, num_layers=2, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.01, l1_reg=0.01, l2_reg=0.0, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:38:39, val_loss: 86.072, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.0, l2_reg=0.01, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=False)
log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:39:18, val_loss: 1566.868, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.01, l2_reg=0.001, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0008, val_loss: 97.735, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:41:09, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.05, l2_reg=0.001, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0025, val_loss: 36.891, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:41:50, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.001, l2_reg=0.0, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
Total epochs: 0007, val_loss: 32.494, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:42:48, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.005, l2_reg=0.0, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0007, val_loss: 218.300, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:43:29, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.01, l1_reg=0.05, l2_reg=0.0, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0008, val_loss: 27.500, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:44:12, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.01, l1_reg=0.005, l2_reg=0.05, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0008, val_loss: 32.319, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:44:52, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=128, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.01, l2_reg=0.001, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0006, val_loss: 255.369, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:45:36, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.005, l2_reg=0.001, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0006, val_loss: 11.046, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:46:16, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.0, l2_reg=0.001, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0006, val_loss: 576.218, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:46:57, hparams: HyperParameters(batch_size=256, num_layers=2, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.001, l2_reg=0.0, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0006, val_loss: 2369.765, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:47:38, hparams: HyperParameters(batch_size=256, num_layers=1, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.05, l2_reg=0.05, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0006, val_loss: 1039.575, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:48:17, hparams: HyperParameters(batch_size=256, num_layers=2, dense_units=256, activation='tanh', optimizer='adam', learning_rate=0.1, l1_reg=0.0, l2_reg=0.05, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
Total epochs: 0011, val_loss: 94.420, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:48:57, hparams: HyperParameters(batch_size=256, num_layers=3, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.05, l1_reg=0.005, l2_reg=0.005, num_like_pages=5000, use_dropout=False, dropout_rate=0.1, use_batchnorm=False)
Total epochs: 0009, val_loss: 26.813, log_dir: checkpoints/SGD_with_regularization/2019-11-01_23:49:41, hparams: HyperParameters(batch_size=256, num_layers=2, dense_units=64, activation='tanh', optimizer='adam', learning_rate=0.005, l1_reg=0.01, l2_reg=0.01, num_like_pages=5000, use_dropout=True, dropout_rate=0.1, use_batchnorm=True)
