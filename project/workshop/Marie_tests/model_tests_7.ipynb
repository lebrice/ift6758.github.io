{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import *\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_data(input_dir):\n",
    "    \"\"\"\n",
    "    Purpose: preprocess liwc and nrc\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        id_list {numpy array of strings}: array of user ids sorted alphabetically,\n",
    "                                        to determine order of features and labels DataFrames\n",
    "        text_data {pandas DataFrame of float}: unscaled text data (liwc and nrc combined)\n",
    "    \"\"\"\n",
    "    # Load and sort text data\n",
    "    liwc = pd.read_csv(os.path.join(input_dir, \"Text\", \"liwc.csv\"), sep = ',')\n",
    "    liwc = liwc.sort_values(by=['userId'])\n",
    "\n",
    "    nrc = pd.read_csv(os.path.join(input_dir, \"Text\", \"nrc.csv\"), sep = ',')\n",
    "    nrc = nrc.sort_values(by=['userId'])\n",
    "\n",
    "    # Build list of subject ids ordered alphabetically\n",
    "    # Check if same subject lists in both sorted DataFrames (liwc and nrc)\n",
    "    if np.array_equal(liwc['userId'], nrc['userId']):\n",
    "        id_list = liwc['userId'].to_numpy()\n",
    "    else:\n",
    "        raise Exception('userIds do not match between liwc and nrc data')\n",
    "\n",
    "    # merge liwc and nrc DataFrames using userId as index\n",
    "    liwc.set_index('userId', inplace=True)\n",
    "    nrc.set_index('userId', inplace=True)\n",
    "\n",
    "    text_data = pd.concat([liwc, nrc], axis=1, sort=False)\n",
    "\n",
    "    return id_list, text_data\n",
    "\n",
    "\n",
    "def get_image_clean(sub_ids, oxford, means):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 2)\n",
    "    Input:\n",
    "        sub_ids {numpy array of strings}: ordered list of userIDs\n",
    "        oxford {pandas DataFrame of floats}: unscaled oxford features of users with 1+ face\n",
    "        means {list of float}: mean values for each feature averaged from train set,\n",
    "                    to replace missing values for userids with no face (train and test set)\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "                with mean values replacing missing entries\n",
    "    '''\n",
    "    # list of ids with at least one face on image: 7174 out of 9500 in train set\n",
    "    ox_list = np.sort(oxford['userId'].unique(), axis=None)\n",
    "    # list of ids in text_list who have no face metrics in oxford.csv (2326 in train set)\n",
    "    ox_noface = np.setdiff1d(sub_ids, ox_list)\n",
    "\n",
    "    # Create DataFrame for userids with no face (1 row per userid)\n",
    "    # values are mean metrics averaged from users with entries (training set)\n",
    "    ox_nf = pd.DataFrame(ox_noface, columns = ['userId'])\n",
    "    columns = oxford.columns[2:].tolist()\n",
    "    for column, mean in zip(columns, means):\n",
    "        ox_nf.insert(loc=ox_nf.shape[1], column=column, value=mean, allow_duplicates=True)\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='noface', value=1, allow_duplicates=True)\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    ox_nf.set_index('userId', inplace=True)\n",
    "\n",
    "    # Format DataFrame from userids with 1+ face\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='noface', value=0, allow_duplicates=True)\n",
    "    # list userIds with multiple faces (714 in train set)\n",
    "    ox_multiples = oxford['userId'][oxford['userId'].duplicated()].tolist()\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    multi_mask = pd.Series([uid in ox_multiples for uid in oxford['userId']])\n",
    "    i = oxford[multi_mask].index\n",
    "    oxford.loc[i, 'multiface'] = 1\n",
    "    # drop duplicate entries with same userId (keep first entry per userId)\n",
    "    oxford.drop_duplicates(subset ='userId', keep='first', inplace=True)\n",
    "\n",
    "    # merge the two DataFrames\n",
    "    oxford.drop(['faceID'], axis=1, inplace=True)\n",
    "    oxford.set_index('userId', inplace=True)\n",
    "    image_data = pd.concat([ox_nf, oxford], axis=0, sort=False).sort_values(by=['userId'])\n",
    "\n",
    "    if not np.array_equal(image_data.index, sub_ids):\n",
    "        raise Exception('userIds do not match between oxford file and id list')\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "def get_image_raw(data_dir):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 1)\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "    '''\n",
    "    # Load data of oxford features extracted from profile picture (face metrics)\n",
    "    # 7915 entries; some users have no face, some have multiple faces on image.\n",
    "    # userids with 1+ face on image: 7174 out of 9500 (train set)\n",
    "    # duplicated entries (userids with > 1 face on same image): 741 in train set\n",
    "    oxford = pd.read_csv(os.path.join(data_dir, \"Image\", \"oxford.csv\"), sep = ',')\n",
    "    #oxford = oxford.sort_values(by=['userId'])\n",
    "    '''\n",
    "    NOTE: headPose_pitch has NO RANGE, drop that feature\n",
    "    '''\n",
    "    oxford.drop(['headPose_pitch'], axis=1, inplace=True)\n",
    "\n",
    "    return oxford\n",
    "\n",
    "\n",
    "def get_likes_kept(data_dir, num_features) -> List[str]:\n",
    "    '''\n",
    "    Purpose: get list of likes to keep as features\n",
    "    Input:\n",
    "        data_dir {str} : the parent input directory\n",
    "        num_features {int} : the number of likes to keep as features,\n",
    "                        starting from those with highest frequencies\n",
    "    Output:\n",
    "        freq_like_id {List of strings}: frequency of most frequent likes,\n",
    "                    (number = num_features), in descending ordered, indexed by like_id\n",
    "    '''\n",
    "    #Why return frequency?\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "    like_ids_to_keep = relation['like_id'].value_counts(sort=True, ascending=False)[:num_features] #This sorts features by frequency\n",
    "\n",
    "    #sort like indices (which are the keys associated with the values kepts)\n",
    "    likes_int64_list = sorted(like_ids_to_keep.keys()) # This sorts indices by like_id\n",
    "    likes_str_list = [str(l) for l in likes_int64_list]\n",
    "    return likes_str_list\n",
    "\n",
    "\n",
    "def get_relations(data_dir: str, sub_ids: List[str], like_ids_to_keep: List[str]):\n",
    "    '''\n",
    "    Purpose: preprocess relations dataset ('likes')\n",
    "\n",
    "    Input:\n",
    "        data_dir {str} -- the parent input directory\n",
    "        sub_ids {numpy array of strings} -- the ordered list of userids\n",
    "        like_ids_to_keep {List[str]} -- The list of page IDs to keep.\n",
    "\n",
    "    Returns:\n",
    "        relations_data -- multihot matrix of the like_id. Rows are indexed with userid, entries are boolean.\n",
    "    '''\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    ## One HUGE step:\n",
    "    # likes_to_keep = like_ids_to_keep.keys()\n",
    "    # kept_relations = relation[relation.like_id.isin(likes_to_keep)]\n",
    "    # multi_hot_relations = pd.get_dummies(kept_relations, columns=[\"like_id\"], prefix=\"\")\n",
    "    # multi_hot = multi_hot_relations.groupby((\"userid\")).sum()\n",
    "    # return multi_hot_relations\n",
    "    ###\n",
    "    total_num_pages = len(like_ids_to_keep)\n",
    "    # Create a multihot likes matrix of booleans (rows = userids, cols = likes), by batch\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Create empty DataFrame with sub_ids as index list\n",
    "    relation_data = pd.DataFrame(sub_ids, columns = ['userid'])\n",
    "    relation_data.set_index('userid', inplace=True)\n",
    "\n",
    "    for start_index in range(0, total_num_pages, batch_size):\n",
    "        end_index = min(start_index + batch_size, total_num_pages)\n",
    "\n",
    "        # sets are better for membership testing than lists.\n",
    "        like_ids_for_this_batch = set(like_ids_to_keep[start_index:end_index])\n",
    "\n",
    "        filtered_table = relation[relation['like_id'].isin(like_ids_for_this_batch)]\n",
    "        ## THIS is the slow part:\n",
    "        relHot = pd.get_dummies(filtered_table, columns=['like_id'], prefix=\"\", prefix_sep=\"\")\n",
    "        ##\n",
    "        relHot = relHot.groupby(['userid']).sum().astype(float) # this makes userid the index\n",
    "\n",
    "        relation_data = pd.concat([relation_data, relHot], axis=1, sort=True)\n",
    "\n",
    "    relation_data = relation_data.reindex(like_ids_to_keep, axis=1)\n",
    "    relation_data.fillna(0.0, inplace=True)\n",
    "    relation_data = relation_data.astype(\"bool\")\n",
    "\n",
    "    # will be different if users in relation.csv are not in sub_ids\n",
    "    if not np.array_equal(relation_data.index, sub_ids):\n",
    "        raise Exception(f\"\"\"userIds do not match between relation file and id list:\n",
    "    {relation_data.index}\n",
    "    {sub_ids}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    return relation_data\n",
    "\n",
    "def get_likes_lists(likes_data, max_num_likes):\n",
    "    '''\n",
    "    Purpose: make list of lists of indices of liked pages per user\n",
    "    Input:\n",
    "        likes_data {pandas DataFrame}: multihot matrix of the like_id. Rows are indexed with userid, entries are boolean\n",
    "    Output:\n",
    "        lists_of_likes {list of lists of int}: indices of pages liked by each user,\n",
    "                padded with zeros to lenght = max_num_likes\n",
    "\n",
    "    '''\n",
    "    # create list of lists of indices (one per user) corresponding to liked pages in one-hot matrix\n",
    "    index_lists = []\n",
    "    for index in likes_data.index:\n",
    "        likes_indices = np.nonzero(likes_data.loc[index].to_numpy())[0].tolist()\n",
    "        index_lists.append(likes_indices)\n",
    "\n",
    "    # pad each list of indices with 0s to set lenght = max_num_likes\n",
    "    lists_padded = tf.keras.preprocessing.sequence.pad_sequences(index_lists,\n",
    "    padding='post', maxlen=max_num_likes)\n",
    "\n",
    "    lists_of_likes = pd.DataFrame(lists_padded)\n",
    "\n",
    "    lists_of_likes.insert(loc=lists_of_likes.shape[1], column='userid', value=likes_data.index, allow_duplicates=True)\n",
    "    lists_of_likes.set_index('userid', inplace=True)\n",
    "\n",
    "    return lists_of_likes\n",
    "\n",
    "def make_label_dict(labels):\n",
    "    '''\n",
    "    Purpose: make dictionnary of labels from pandas DataFrame\n",
    "    Input:\n",
    "        labels {pandas DataFrame}: labels ordered per userids (alphabetical order)\n",
    "    Output:\n",
    "        labels_dict {dictionary of pandas DataFrames}: labels (one entry per metric) ordered alphabetically\n",
    "                by userid for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    gender = labels['gender']\n",
    "\n",
    "    age_grps = labels[['age_xx_24', 'age_25_34', 'age_35_49', 'age_50_xx']]\n",
    "\n",
    "    '''\n",
    "    Note: : each DataFrames (value) is indexed by userid in labels_dict\n",
    "    '''\n",
    "    labels_dict = {}\n",
    "    labels_dict['userid'] = labels.index\n",
    "    labels_dict['gender'] = gender\n",
    "    labels_dict['age_grps'] = age_grps\n",
    "    labels_dict['ope'] = labels['ope']\n",
    "    labels_dict['con'] = labels['con']\n",
    "    labels_dict['ext'] = labels['ext']\n",
    "    labels_dict['agr'] = labels['agr']\n",
    "    labels_dict['neu'] = labels['neu']\n",
    "\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def preprocess_labels(data_dir, sub_ids):\n",
    "    '''\n",
    "    Purpose: preprocess entry labels from training set\n",
    "    Input:\n",
    "        datadir {string} : path to training data directory\n",
    "        sub_ids {numpy array of strings}: list of subject ids ordered alphabetically\n",
    "    Output:\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    labels = pd.read_csv(os.path.join(data_dir, \"Profile\", \"Profile.csv\"))\n",
    "\n",
    "    def age_group_id(age_str: str) -> int:\n",
    "        \"\"\"Returns the age group category ID (an integer from 0 to 3) for the given age (string)\n",
    "\n",
    "        Arguments:\n",
    "            age_str {str} -- the age\n",
    "\n",
    "        Returns:\n",
    "            int -- the ID of the age group: 0 for xx-24, 1 for 25-34, 2 for 35-49 and 3 for 50-xx.\n",
    "        \"\"\"\n",
    "        age = int(age_str)\n",
    "        if age <= 24:\n",
    "            return 0\n",
    "        elif age <= 34:\n",
    "            return 1\n",
    "        elif age <= 49:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    labels = labels.assign(age_group = lambda dt: pd.Series([age_group_id(age_str) for age_str in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_xx_24 = lambda dt: pd.Series([int(age) <= 24 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_25_34 = lambda dt: pd.Series([25 <= int(age) <= 34 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_35_49 = lambda dt: pd.Series([35 <= int(age) <= 49 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_50_xx = lambda dt: pd.Series([50 <= int(age) for age in dt[\"age\"]]))\n",
    "\n",
    "    labels = labels.sort_values(by=['userid'])\n",
    "    # check if same subject ids in labels and sub_ids\n",
    "    if not np.array_equal(labels['userid'].to_numpy(), sub_ids):\n",
    "        raise Exception('userIds do not match between profiles labels and id list')\n",
    "\n",
    "    labels = labels.drop(['Unnamed: 0'], axis=1)\n",
    "    labels.set_index('userid', inplace=True)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def preprocess_train(data_dir, num_likes=10_000, max_num_likes=2145):\n",
    "    '''\n",
    "    Purpose: preprocesses training dataset (with labels) and returns scaled features,\n",
    "    labels and parameters to scale the test data set\n",
    "    Input\n",
    "        data_dir {string}: path to ~/Train data directory\n",
    "        num_likes {int}: number of like_ids to keep as features\n",
    "        max_num_likes {int}: maximum number of pages liked by a single user\n",
    "    Output:\n",
    "        train_features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        **(updated:)features_q10_q90 {tupple of 2 pandas Series}: series of 10th and 90th quantile values of\n",
    "                text + image features from train dataset, to be used to scale test data.\n",
    "                Note that the multihot relation features do not necessitate scaling.\n",
    "        image_means {list of float}: means from oxford dataset to replace missing entries in oxford test set\n",
    "        likes_kept {list of strings}: ordered likes_ids to serve as columns for test set relation features matrix\n",
    "        train_labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    TO CONSIDER: convert outputted pandas to tensorflow tf.data.Dataset...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_means = image_data_raw.iloc[:, 2:].mean().tolist()\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    Update: scaling w RobustScaler rather than MinMaxScaler algo, due to outliers\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = features_to_scale.min()\n",
    "    #feat_max = features_to_scale.max()\n",
    "    feat_q10 = features_to_scale.quantile(q = 0.10)\n",
    "    feat_q90 = features_to_scale.quantile(q = 0.90)\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    #features_min_max = (feat_min, feat_max)\n",
    "    feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "    features_q10_q90 = (feat_q10, feat_q90)\n",
    "\n",
    "    likes_kept = get_likes_kept(data_dir, num_likes)\n",
    "\n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept)\n",
    "\n",
    "    train_likes_lists = get_likes_lists(likes_data, max_num_likes)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    additional_weird_features = image_data.iloc[:, -2:]\n",
    "    train_features = pd.concat([feat_scaled, additional_weird_features, train_likes_lists], axis=1, sort=False)\n",
    "\n",
    "    # DataFrame of training set labels\n",
    "    train_labels = preprocess_labels(data_dir, sub_ids)\n",
    "\n",
    "\n",
    "    #return train_features, features_min_max, image_means, likes_kept, train_labels\n",
    "    return train_features, features_q10_q90, image_means, likes_kept, train_labels\n",
    "\n",
    "\n",
    "#def preprocess_test(data_dir, min_max_train, image_means_train, likes_kept_train):\n",
    "def preprocess_test(data_dir, q10_q90_train, image_means_train, likes_kept_train, max_num_likes=2145):\n",
    "    '''\n",
    "    Purpose: preprocesses test dataset (no labels)\n",
    "    Input:\n",
    "        datadir {string}: path to Test data directory\n",
    "        (**updated)q10_q90_train {tupple of two numpy arrays}: 10th and 90th quantile values for\n",
    "                concatenated text and image features (from train set)\n",
    "        image_means_train {list of float}: means from oxford training dataset to replace\n",
    "                missing entries in oxford test set\n",
    "        likes_kept_train {list of strings}: most frequent likes_ids from train set\n",
    "                (ordered by frequency) to serve as columns in relation features matrix\n",
    "        max_num_likes {int}: maximum number of pages liked by a single user (from train set)\n",
    "    Output:\n",
    "        test_features {pandas DataFrame}: vectorized features of test set\n",
    "\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means_train)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = min_max_train[0]\n",
    "    #feat_max = min_max_train[1]\n",
    "    feat_q10 = q10_q90_train[0]\n",
    "    feat_q90 = q10_q90_train[1]\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "\n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept_train)\n",
    "\n",
    "    # list of lists of indices corresponding to pages liked\n",
    "    # each padded with 0s (list's max length = max_num_likes)\n",
    "    test_likes_lists = get_likes_lists(likes_data, max_num_likes)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    test_features = pd.concat([feat_scaled, image_data.iloc[:, -2:], test_likes_lists], axis=1, sort=False)\n",
    "\n",
    "    return test_features\n",
    "\n",
    "\n",
    "def get_train_val_sets(features, labels, val_prop):\n",
    "    '''\n",
    "    Purpose: Splits training dataset into a train and a validation set of\n",
    "    ratio determined by val_prop (x = features, y = labels)\n",
    "    Input\n",
    "        features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "        val_prop {float between 0 and 1}: proportion of sample in validation set\n",
    "                    (e.g. 0.2 = 20% validation, 80% training)\n",
    "    Output:\n",
    "        x_train, x_val {pandas DataFrames}: vectorized features for train and validation sets\n",
    "        y_train, y_val {pandas DataFrames}: train and validation set labels\n",
    "\n",
    "    TO DO: convert outputted pandas to tensorflow tf.data.Dataset?...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # NOTE: UNUSED\n",
    "    from sklearn import model_selection\n",
    "    x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        features, # training features to split\n",
    "        labels, # training labels to split\n",
    "        test_size = val_prop, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "        shuffle= True,\n",
    "        #stratify = y_data[:1],\n",
    "        # random_state = 42  # can use to always obtain the same train/validation split\n",
    "        )\n",
    "\n",
    "    return x_train, x_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to preprocess the training dataset:\n",
    "# 1. set path to Train directory\n",
    "# 2. call preprocess_train\n",
    "\n",
    "train_path = '../Train' #modify if working from other directory\n",
    "\n",
    "train_features, features_q10_q90, image_means, likes_kept, train_labels = preprocess_train(train_path, num_likes=10_000, max_num_likes=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_200, features_q10_q90_200, image_means_200, likes_kept_200, train_labels_200 = preprocess_train(train_path, num_likes=10_000, max_num_likes=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different number of max liked pages per user\n",
    "\n",
    "train_features_100, features_q10_q90_100, image_means_100, likes_kept_100, train_labels_100 = preprocess_train(train_path, num_likes=10_000, max_num_likes=100)\n",
    "train_features_500, features_q10_q90_500, image_means_500, likes_kept_500, train_labels_500 = preprocess_train(train_path, num_likes=10_000, max_num_likes=500)\n",
    "train_features_1000, features_q10_q90_1000, image_means_1000, likes_kept_1000, train_labels_1000 = preprocess_train(train_path, num_likes=10_000, max_num_likes=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT: save (as .csv) the features needed as arguments for preprocess_test in submission; \n",
    "# load in test script to feed model\n",
    "# save tensorflow models in submissions\n",
    "# https://www.tensorflow.org/guide/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = preprocess_test(train_path, features_q10_q90, image_means, likes_kept, max_num_likes=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_features.columns == test_features.columns)/test_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set for Age Group Classifier\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    train_features, # training features to split\n",
    "    train_labels, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels['age_group']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n",
    "\n",
    "x_train_100, x_val_100, y_train_100, y_val_100 = model_selection.train_test_split(\n",
    "    train_features_100, # training features to split\n",
    "    train_labels_100, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels_100['age_group']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n",
    "\n",
    "x_train_200, x_val_200, y_train_200, y_val_200 = model_selection.train_test_split(\n",
    "    train_features_200, # training features to split\n",
    "    train_labels_200, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels_200['age_group']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n",
    "\n",
    "x_train_500, x_val_500, y_train_500, y_val_500 = model_selection.train_test_split(\n",
    "    train_features_500, # training features to split\n",
    "    train_labels_500, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels_500['age_group']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n",
    "\n",
    "x_train_1000, x_val_1000, y_train_1000, y_val_1000 = model_selection.train_test_split(\n",
    "    train_features_1000, # training features to split\n",
    "    train_labels_1000, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels_1000['age_group']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters model age with embedded likes\n",
    "\n",
    "#batch_size=64\n",
    "num_layers=2\n",
    "dense_units=62\n",
    "#activation='tanh'\n",
    "#optimizer='sgd'\n",
    "learning_rate=0.0001\n",
    "l1_reg=0.0025\n",
    "l2_reg=0.005\n",
    "#num_like_pages=5000\n",
    "#use_dropout=True\n",
    "dropout_rate=0.1\n",
    "#use_batchnorm=False\n",
    "\n",
    "#age_weights = [0.42100598, 0.98445596, 2.27817746, 5.88235294]\n",
    "    \n",
    "num_text_features = 91\n",
    "num_image_features = 65 # added back noface and multiface    \n",
    "#num_like_features = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.4189636163175303, 1: 0.9890681936491411, 2: 2.272727272727273, 3: 6.1688311688311686}\n",
      "{0: 0.5, 1: 1.0, 2: 1.5, 3: 2.0}\n",
      "{0: 1.0, 1: 2.0, 2: 3.0, 3: 0.1}\n"
     ]
    }
   ],
   "source": [
    "# calculating weights for age categories w sklearn\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "\n",
    "a_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes = np.unique(y_train['age_group']), y= y_train['age_group'])\n",
    "\n",
    "age_weights_dict = {}\n",
    "\n",
    "for i in range(len(a_weights)):\n",
    "    age_weights_dict[i] = a_weights[i]\n",
    "    \n",
    "print(age_weights_dict)   \n",
    "\n",
    "age_weights_dict_mild = {}\n",
    "age_weights_dict_mild[0] = 0.5\n",
    "age_weights_dict_mild[1] = 1.0\n",
    "age_weights_dict_mild[2] = 1.5\n",
    "age_weights_dict_mild[3] = 2.0\n",
    "\n",
    "print(age_weights_dict_mild)\n",
    "\n",
    "age_weights_dict_first3 = {}\n",
    "age_weights_dict_first3[0] = 1.0\n",
    "age_weights_dict_first3[1] = 2.0\n",
    "age_weights_dict_first3[2] = 3.0\n",
    "age_weights_dict_first3[3] = 0.1\n",
    "\n",
    "print(age_weights_dict_first3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "likes_features (InputLayer)     [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_features (InputLayer)      [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "likes_embedding_block (Sequenti (None, 16000)        80000       likes_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_layers (Sequential)       (None, 62)           1005640     text_features[0][0]              \n",
      "                                                                 image_features[0][0]             \n",
      "                                                                 likes_embedding_block[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "age_group (Dense)               (None, 4)            252         dense_layers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,085,892\n",
      "Trainable params: 1,085,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model category age using embedding for likes\n",
    "\n",
    "max_len = 2000\n",
    "\n",
    "image_features = tf.keras.Input([num_image_features], dtype=tf.float32, name=\"image_features\")\n",
    "text_features  = tf.keras.Input([num_text_features], dtype=tf.float32, name=\"text_features\")\n",
    "likes_features = tf.keras.Input([max_len], dtype=tf.int32, name=\"likes_features\")\n",
    "\n",
    "likes_embedding_block = tf.keras.Sequential(name=\"likes_embedding_block\")\n",
    "likes_embedding_block.add(tf.keras.layers.Embedding(10000, 8, input_length=max_len,\n",
    "                                                    #embeddings_regularizer=tf.keras.regularizers.L1L2(l1=0.0001, l2=0.0001),\n",
    "                                                   mask_zero=True))\n",
    "\n",
    "### GlobalAveragePooling1D averages the embeddings of all pages liked by a user\n",
    "#likes_embedding_block.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "likes_embedding_block.add(tf.keras.layers.Flatten())\n",
    "\n",
    "## Experimenting: Not helping at all... just learning the baseline\n",
    "# Trying to reduce contribution of likes to balance out input modalities\n",
    "#likes_embedding_block.add(tf.keras.layers.Dense(\n",
    "#    units = 128, activation= 'tanh', \n",
    "#    kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "## Experimenting\n",
    "\n",
    "condensed_likes = likes_embedding_block(likes_features)\n",
    "\n",
    "dense_layers = tf.keras.Sequential(name=\"dense_layers\")\n",
    "dense_layers.add(tf.keras.layers.Concatenate())\n",
    "for i in range(num_layers):\n",
    "    dense_layers.add(tf.keras.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation= 'tanh', #'tanh',\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg),      \n",
    "        ))\n",
    "        \n",
    "    dense_layers.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "features = dense_layers([text_features, image_features, condensed_likes])\n",
    "\n",
    "age_group = tf.keras.layers.Dense(units=4, activation=\"softmax\", name=\"age_group\")(features)\n",
    "\n",
    "model_age = tf.keras.Model(\n",
    "    inputs=[text_features, image_features, likes_features],\n",
    "    outputs= age_group\n",
    ")    \n",
    "\n",
    "model_age.compile(\n",
    "    optimizer = tf.keras.optimizers.get({\"class_name\": \"ADAM\", #'ADAM'\n",
    "                               \"config\": {\"learning_rate\": 0.0001}}),    \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc', 'categorical_accuracy']\n",
    ")\n",
    "\n",
    "print(model_age.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_txt = x_train.iloc[:, :91].values\n",
    "x_train_img = x_train.iloc[:, 91:156].values\n",
    "x_train_lik = x_train.iloc[:, 156:].values\n",
    "\n",
    "x_val_txt = x_val.iloc[:, :91].values\n",
    "x_val_img = x_val.iloc[:, 91:156].values\n",
    "x_val_lik = x_val.iloc[:, 156:].values\n",
    "\n",
    "y_train_age = tf.keras.utils.to_categorical(y_train['age_group'].values)\n",
    "\n",
    "y_val_age = tf.keras.utils.to_categorical(y_val['age_group'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/55\n",
      "7600/7600 [==============================] - 3s 431us/sample - loss: 16.2611 - acc: 0.4787 - categorical_accuracy: 0.4787 - val_loss: 7.3069 - val_acc: 0.5921 - val_categorical_accuracy: 0.5921\n",
      "Epoch 2/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 4.0962 - acc: 0.5612 - categorical_accuracy: 0.5612 - val_loss: 2.9153 - val_acc: 0.5963 - val_categorical_accuracy: 0.5963\n",
      "Epoch 3/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 2.8442 - acc: 0.5611 - categorical_accuracy: 0.5611 - val_loss: 2.7698 - val_acc: 0.5826 - val_categorical_accuracy: 0.5826\n",
      "Epoch 4/55\n",
      "7600/7600 [==============================] - 2s 248us/sample - loss: 2.7214 - acc: 0.5704 - categorical_accuracy: 0.5704 - val_loss: 2.6593 - val_acc: 0.5826 - val_categorical_accuracy: 0.5826\n",
      "Epoch 5/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 2.6119 - acc: 0.5836 - categorical_accuracy: 0.5836 - val_loss: 2.5646 - val_acc: 0.5347 - val_categorical_accuracy: 0.5347\n",
      "Epoch 6/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 2.5237 - acc: 0.5682 - categorical_accuracy: 0.5682 - val_loss: 2.4740 - val_acc: 0.5863 - val_categorical_accuracy: 0.5863\n",
      "Epoch 7/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 2.4402 - acc: 0.5786 - categorical_accuracy: 0.5786 - val_loss: 2.3987 - val_acc: 0.5705 - val_categorical_accuracy: 0.5705\n",
      "Epoch 8/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 2.3613 - acc: 0.5787 - categorical_accuracy: 0.5787 - val_loss: 2.3268 - val_acc: 0.5563 - val_categorical_accuracy: 0.5563\n",
      "Epoch 9/55\n",
      "7600/7600 [==============================] - 2s 256us/sample - loss: 2.2934 - acc: 0.5722 - categorical_accuracy: 0.5722 - val_loss: 2.2545 - val_acc: 0.5953 - val_categorical_accuracy: 0.5953\n",
      "Epoch 10/55\n",
      "7600/7600 [==============================] - 2s 256us/sample - loss: 2.2287 - acc: 0.5878 - categorical_accuracy: 0.5878 - val_loss: 2.1969 - val_acc: 0.5868 - val_categorical_accuracy: 0.5868\n",
      "Epoch 11/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 2.1732 - acc: 0.5807 - categorical_accuracy: 0.5807 - val_loss: 2.1436 - val_acc: 0.5779 - val_categorical_accuracy: 0.5779\n",
      "Epoch 12/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 2.1175 - acc: 0.5855 - categorical_accuracy: 0.5855 - val_loss: 2.0893 - val_acc: 0.5758 - val_categorical_accuracy: 0.5758\n",
      "Epoch 13/55\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 2.0681 - acc: 0.5854 - categorical_accuracy: 0.5854 - val_loss: 2.0386 - val_acc: 0.5932 - val_categorical_accuracy: 0.5932\n",
      "Epoch 14/55\n",
      "7600/7600 [==============================] - 2s 254us/sample - loss: 2.0156 - acc: 0.5839 - categorical_accuracy: 0.5839 - val_loss: 1.9960 - val_acc: 0.5679 - val_categorical_accuracy: 0.5679\n",
      "Epoch 15/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.9735 - acc: 0.5874 - categorical_accuracy: 0.5874 - val_loss: 1.9569 - val_acc: 0.5958 - val_categorical_accuracy: 0.5958\n",
      "Epoch 16/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 1.9309 - acc: 0.5966 - categorical_accuracy: 0.5966 - val_loss: 1.9142 - val_acc: 0.5684 - val_categorical_accuracy: 0.5684\n",
      "Epoch 17/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.8915 - acc: 0.5920 - categorical_accuracy: 0.5920 - val_loss: 1.8786 - val_acc: 0.5837 - val_categorical_accuracy: 0.5837\n",
      "Epoch 18/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 1.8618 - acc: 0.5947 - categorical_accuracy: 0.5947 - val_loss: 1.8493 - val_acc: 0.6032 - val_categorical_accuracy: 0.6032\n",
      "Epoch 19/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 1.8264 - acc: 0.6012 - categorical_accuracy: 0.6012 - val_loss: 1.8108 - val_acc: 0.6042 - val_categorical_accuracy: 0.6042\n",
      "Epoch 20/55\n",
      "7600/7600 [==============================] - 2s 253us/sample - loss: 1.7927 - acc: 0.6017 - categorical_accuracy: 0.6017 - val_loss: 1.7746 - val_acc: 0.6163 - val_categorical_accuracy: 0.6163\n",
      "Epoch 21/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 1.7501 - acc: 0.6070 - categorical_accuracy: 0.6070 - val_loss: 1.7338 - val_acc: 0.5905 - val_categorical_accuracy: 0.5905\n",
      "Epoch 22/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.7219 - acc: 0.6105 - categorical_accuracy: 0.6105 - val_loss: 1.7018 - val_acc: 0.5911 - val_categorical_accuracy: 0.5911\n",
      "Epoch 23/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.6921 - acc: 0.6053 - categorical_accuracy: 0.6053 - val_loss: 1.6794 - val_acc: 0.5937 - val_categorical_accuracy: 0.5937\n",
      "Epoch 24/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.6709 - acc: 0.6047 - categorical_accuracy: 0.6047 - val_loss: 1.6566 - val_acc: 0.5963 - val_categorical_accuracy: 0.5963\n",
      "Epoch 25/55\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 1.6482 - acc: 0.6076 - categorical_accuracy: 0.6076 - val_loss: 1.6368 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 26/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 1.6260 - acc: 0.6072 - categorical_accuracy: 0.6072 - val_loss: 1.6138 - val_acc: 0.6026 - val_categorical_accuracy: 0.6026\n",
      "Epoch 27/55\n",
      "7600/7600 [==============================] - 2s 253us/sample - loss: 1.6036 - acc: 0.6139 - categorical_accuracy: 0.6139 - val_loss: 1.6005 - val_acc: 0.6042 - val_categorical_accuracy: 0.6042\n",
      "Epoch 28/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.5808 - acc: 0.6087 - categorical_accuracy: 0.6087 - val_loss: 1.6018 - val_acc: 0.6316 - val_categorical_accuracy: 0.6316\n",
      "Epoch 29/55\n",
      "7600/7600 [==============================] - 2s 253us/sample - loss: 1.5683 - acc: 0.6172 - categorical_accuracy: 0.6172 - val_loss: 1.5640 - val_acc: 0.6153 - val_categorical_accuracy: 0.6153\n",
      "Epoch 30/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.5441 - acc: 0.6205 - categorical_accuracy: 0.6205 - val_loss: 1.5428 - val_acc: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 31/55\n",
      "7600/7600 [==============================] - 2s 255us/sample - loss: 1.5257 - acc: 0.6209 - categorical_accuracy: 0.6209 - val_loss: 1.5333 - val_acc: 0.5995 - val_categorical_accuracy: 0.5995\n",
      "Epoch 32/55\n",
      "7600/7600 [==============================] - 2s 253us/sample - loss: 1.5045 - acc: 0.6249 - categorical_accuracy: 0.6249 - val_loss: 1.5088 - val_acc: 0.6189 - val_categorical_accuracy: 0.6189\n",
      "Epoch 33/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.4846 - acc: 0.6307 - categorical_accuracy: 0.6307 - val_loss: 1.4929 - val_acc: 0.6195 - val_categorical_accuracy: 0.6195\n",
      "Epoch 34/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.4680 - acc: 0.6386 - categorical_accuracy: 0.6386 - val_loss: 1.4797 - val_acc: 0.6258 - val_categorical_accuracy: 0.6258\n",
      "Epoch 35/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 1.4498 - acc: 0.6422 - categorical_accuracy: 0.6422 - val_loss: 1.4674 - val_acc: 0.6258 - val_categorical_accuracy: 0.6258\n",
      "Epoch 36/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.4336 - acc: 0.6421 - categorical_accuracy: 0.6421 - val_loss: 1.4577 - val_acc: 0.6411 - val_categorical_accuracy: 0.6411\n",
      "Epoch 37/55\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 1.4076 - acc: 0.6576 - categorical_accuracy: 0.6576 - val_loss: 1.4377 - val_acc: 0.6337 - val_categorical_accuracy: 0.6337\n",
      "Epoch 38/55\n",
      "7600/7600 [==============================] - 2s 258us/sample - loss: 1.3895 - acc: 0.6608 - categorical_accuracy: 0.6608 - val_loss: 1.4251 - val_acc: 0.6347 - val_categorical_accuracy: 0.6347\n",
      "Epoch 39/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.3730 - acc: 0.6650 - categorical_accuracy: 0.6650 - val_loss: 1.4154 - val_acc: 0.6416 - val_categorical_accuracy: 0.6416\n",
      "Epoch 40/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.3543 - acc: 0.6675 - categorical_accuracy: 0.6675 - val_loss: 1.4065 - val_acc: 0.6516 - val_categorical_accuracy: 0.6516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/55\n",
      "7600/7600 [==============================] - 2s 252us/sample - loss: 1.3386 - acc: 0.6734 - categorical_accuracy: 0.6734 - val_loss: 1.3959 - val_acc: 0.6453 - val_categorical_accuracy: 0.6453\n",
      "Epoch 42/55\n",
      "7600/7600 [==============================] - 2s 248us/sample - loss: 1.3228 - acc: 0.6813 - categorical_accuracy: 0.6813 - val_loss: 1.3821 - val_acc: 0.6384 - val_categorical_accuracy: 0.6384\n",
      "Epoch 43/55\n",
      "7600/7600 [==============================] - 2s 254us/sample - loss: 1.3121 - acc: 0.6809 - categorical_accuracy: 0.6809 - val_loss: 1.3813 - val_acc: 0.6521 - val_categorical_accuracy: 0.6521\n",
      "Epoch 44/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.2951 - acc: 0.6899 - categorical_accuracy: 0.6899 - val_loss: 1.3672 - val_acc: 0.6595 - val_categorical_accuracy: 0.6595\n",
      "Epoch 45/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.2853 - acc: 0.6908 - categorical_accuracy: 0.6908 - val_loss: 1.3589 - val_acc: 0.6458 - val_categorical_accuracy: 0.6458\n",
      "Epoch 46/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.2690 - acc: 0.6955 - categorical_accuracy: 0.6955 - val_loss: 1.3545 - val_acc: 0.6584 - val_categorical_accuracy: 0.6584\n",
      "Epoch 47/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 1.2531 - acc: 0.6968 - categorical_accuracy: 0.6968 - val_loss: 1.3474 - val_acc: 0.6547 - val_categorical_accuracy: 0.6547\n",
      "Epoch 48/55\n",
      "7600/7600 [==============================] - 2s 250us/sample - loss: 1.2466 - acc: 0.7028 - categorical_accuracy: 0.7028 - val_loss: 1.3417 - val_acc: 0.6542 - val_categorical_accuracy: 0.6542\n",
      "Epoch 49/55\n",
      "7600/7600 [==============================] - 2s 248us/sample - loss: 1.2352 - acc: 0.7007 - categorical_accuracy: 0.7007 - val_loss: 1.3396 - val_acc: 0.6437 - val_categorical_accuracy: 0.6437\n",
      "Epoch 50/55\n",
      "7600/7600 [==============================] - 2s 253us/sample - loss: 1.2215 - acc: 0.7017 - categorical_accuracy: 0.7017 - val_loss: 1.3426 - val_acc: 0.6705 - val_categorical_accuracy: 0.6705\n",
      "Epoch 51/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.2150 - acc: 0.7099 - categorical_accuracy: 0.7099 - val_loss: 1.3353 - val_acc: 0.6626 - val_categorical_accuracy: 0.6626\n",
      "Epoch 52/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.2054 - acc: 0.7086 - categorical_accuracy: 0.7086 - val_loss: 1.3293 - val_acc: 0.6489 - val_categorical_accuracy: 0.6489\n",
      "Epoch 53/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 1.1914 - acc: 0.7117 - categorical_accuracy: 0.7117 - val_loss: 1.3277 - val_acc: 0.6589 - val_categorical_accuracy: 0.6589\n",
      "Epoch 54/55\n",
      "7600/7600 [==============================] - 2s 249us/sample - loss: 1.1818 - acc: 0.7134 - categorical_accuracy: 0.7134 - val_loss: 1.3254 - val_acc: 0.6600 - val_categorical_accuracy: 0.6600\n",
      "Epoch 55/55\n",
      "7600/7600 [==============================] - 2s 251us/sample - loss: 1.1705 - acc: 0.7187 - categorical_accuracy: 0.7187 - val_loss: 1.3356 - val_acc: 0.6768 - val_categorical_accuracy: 0.6768\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[926, 202,   6,   0],\n",
       "       [145, 276,  59,   0],\n",
       "       [ 14, 111,  84,   0],\n",
       "       [  7,  32,  38,   0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "history_age_balanced = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=64, epochs=100, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     #validation_split=0.2, \n",
    "                                     class_weight=age_weights_dict\n",
    "                                    )\n",
    "\n",
    "'''\n",
    "history_age_balanced_mild = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=64, epochs=55, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     class_weight=age_weights_dict_first3\n",
    "                                    )\n",
    "\n",
    "# validation baseline for age group:\n",
    "print(y_val['age_group'].value_counts()[0]/y_val.shape[0])\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_age.save('saved_models/age_model_embedding_2000.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training notes: \n",
    "# Without rebalancing of weights, at learning rate 0.0001, starts overfitting (loss increasing) \n",
    "# around epoch 70\n",
    "\n",
    "# More balanced classification: batches 16, 30 epochs, reweight 1, 2, 3, 0.1\n",
    "# For 64 size batches, loss increases around 55... still good classification around 70\n",
    "\n",
    "## Better training: 64 batches, 55 epochs, reweight 1, 2, 3, 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/70\n",
      "7600/7600 [==============================] - 3s 452us/sample - loss: 31.9606 - acc: 0.5414 - categorical_accuracy: 0.5414 - val_loss: 13.2020 - val_acc: 0.5816 - val_categorical_accuracy: 0.5816\n",
      "Epoch 2/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 7.0353 - acc: 0.5792 - categorical_accuracy: 0.5792 - val_loss: 4.9713 - val_acc: 0.5974 - val_categorical_accuracy: 0.5974\n",
      "Epoch 3/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 4.7719 - acc: 0.5913 - categorical_accuracy: 0.5913 - val_loss: 4.5375 - val_acc: 0.6011 - val_categorical_accuracy: 0.6011\n",
      "Epoch 4/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 4.3552 - acc: 0.5972 - categorical_accuracy: 0.5972 - val_loss: 4.1439 - val_acc: 0.6026 - val_categorical_accuracy: 0.6026\n",
      "Epoch 5/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 3.9794 - acc: 0.5987 - categorical_accuracy: 0.5987 - val_loss: 3.7877 - val_acc: 0.6021 - val_categorical_accuracy: 0.6021\n",
      "Epoch 6/70\n",
      "7600/7600 [==============================] - 2s 261us/sample - loss: 3.6403 - acc: 0.6034 - categorical_accuracy: 0.6034 - val_loss: 3.4690 - val_acc: 0.6037 - val_categorical_accuracy: 0.6037\n",
      "Epoch 7/70\n",
      "7600/7600 [==============================] - 2s 259us/sample - loss: 3.3324 - acc: 0.6047 - categorical_accuracy: 0.6047 - val_loss: 3.1807 - val_acc: 0.6095 - val_categorical_accuracy: 0.6095\n",
      "Epoch 8/70\n",
      "7600/7600 [==============================] - 2s 267us/sample - loss: 3.0596 - acc: 0.6051 - categorical_accuracy: 0.6051 - val_loss: 2.9270 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 9/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 2.8207 - acc: 0.6061 - categorical_accuracy: 0.6061 - val_loss: 2.7036 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 10/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 2.6085 - acc: 0.6092 - categorical_accuracy: 0.6092 - val_loss: 2.5082 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 11/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 2.4264 - acc: 0.6145 - categorical_accuracy: 0.6145 - val_loss: 2.3422 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 12/70\n",
      "7600/7600 [==============================] - 2s 261us/sample - loss: 2.2722 - acc: 0.6137 - categorical_accuracy: 0.6137 - val_loss: 2.2012 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 13/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 2.1404 - acc: 0.6121 - categorical_accuracy: 0.6121 - val_loss: 2.0807 - val_acc: 0.6132 - val_categorical_accuracy: 0.6132\n",
      "Epoch 14/70\n",
      "7600/7600 [==============================] - 2s 261us/sample - loss: 2.0240 - acc: 0.6134 - categorical_accuracy: 0.6134 - val_loss: 1.9690 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 15/70\n",
      "7600/7600 [==============================] - 2s 260us/sample - loss: 1.9190 - acc: 0.6134 - categorical_accuracy: 0.6134 - val_loss: 1.8682 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 16/70\n",
      "7600/7600 [==============================] - 2s 260us/sample - loss: 1.8236 - acc: 0.6116 - categorical_accuracy: 0.6116 - val_loss: 1.7772 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 17/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.7333 - acc: 0.6137 - categorical_accuracy: 0.6137 - val_loss: 1.6921 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 18/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.6532 - acc: 0.6126 - categorical_accuracy: 0.6126 - val_loss: 1.6149 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 19/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.5808 - acc: 0.6124 - categorical_accuracy: 0.6124 - val_loss: 1.5479 - val_acc: 0.6084 - val_categorical_accuracy: 0.6084\n",
      "Epoch 20/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 1.5141 - acc: 0.6155 - categorical_accuracy: 0.6155 - val_loss: 1.4837 - val_acc: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 21/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 1.4540 - acc: 0.6103 - categorical_accuracy: 0.6103 - val_loss: 1.4291 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 22/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 1.4011 - acc: 0.6107 - categorical_accuracy: 0.6107 - val_loss: 1.3788 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 23/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.3559 - acc: 0.6074 - categorical_accuracy: 0.6074 - val_loss: 1.3342 - val_acc: 0.6042 - val_categorical_accuracy: 0.6042\n",
      "Epoch 24/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.3156 - acc: 0.6083 - categorical_accuracy: 0.6083 - val_loss: 1.2957 - val_acc: 0.6063 - val_categorical_accuracy: 0.6063\n",
      "Epoch 25/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.2815 - acc: 0.6079 - categorical_accuracy: 0.6079 - val_loss: 1.2632 - val_acc: 0.6063 - val_categorical_accuracy: 0.6063\n",
      "Epoch 26/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.2501 - acc: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.2347 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 27/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.2219 - acc: 0.6084 - categorical_accuracy: 0.6084 - val_loss: 1.2096 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 28/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.2003 - acc: 0.6084 - categorical_accuracy: 0.6084 - val_loss: 1.1905 - val_acc: 0.5989 - val_categorical_accuracy: 0.5989\n",
      "Epoch 29/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.1776 - acc: 0.6078 - categorical_accuracy: 0.6078 - val_loss: 1.1687 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 30/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.1619 - acc: 0.6066 - categorical_accuracy: 0.6066 - val_loss: 1.1517 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 31/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.1457 - acc: 0.6076 - categorical_accuracy: 0.6076 - val_loss: 1.1368 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 32/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.1324 - acc: 0.6072 - categorical_accuracy: 0.6072 - val_loss: 1.1247 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 33/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.1196 - acc: 0.6097 - categorical_accuracy: 0.6097 - val_loss: 1.1137 - val_acc: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 34/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.1110 - acc: 0.6096 - categorical_accuracy: 0.6096 - val_loss: 1.1041 - val_acc: 0.6011 - val_categorical_accuracy: 0.6011\n",
      "Epoch 35/70\n",
      "7600/7600 [==============================] - 2s 260us/sample - loss: 1.1006 - acc: 0.6103 - categorical_accuracy: 0.6103 - val_loss: 1.0953 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 36/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0947 - acc: 0.6087 - categorical_accuracy: 0.6087 - val_loss: 1.0881 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 37/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 1.0872 - acc: 0.6091 - categorical_accuracy: 0.6091 - val_loss: 1.0818 - val_acc: 0.6032 - val_categorical_accuracy: 0.6032\n",
      "Epoch 38/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0800 - acc: 0.6096 - categorical_accuracy: 0.6096 - val_loss: 1.0759 - val_acc: 0.6032 - val_categorical_accuracy: 0.6032\n",
      "Epoch 39/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0738 - acc: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.0703 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 40/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0705 - acc: 0.6092 - categorical_accuracy: 0.6092 - val_loss: 1.0675 - val_acc: 0.6100 - val_categorical_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0652 - acc: 0.6105 - categorical_accuracy: 0.6105 - val_loss: 1.0612 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 42/70\n",
      "7600/7600 [==============================] - 2s 259us/sample - loss: 1.0603 - acc: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.0579 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 43/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.0567 - acc: 0.6109 - categorical_accuracy: 0.6109 - val_loss: 1.0547 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 44/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.0544 - acc: 0.6126 - categorical_accuracy: 0.6126 - val_loss: 1.0521 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 45/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0529 - acc: 0.6120 - categorical_accuracy: 0.6120 - val_loss: 1.0500 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 46/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0501 - acc: 0.6125 - categorical_accuracy: 0.6125 - val_loss: 1.0468 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 47/70\n",
      "7600/7600 [==============================] - 2s 261us/sample - loss: 1.0458 - acc: 0.6122 - categorical_accuracy: 0.6122 - val_loss: 1.0457 - val_acc: 0.6026 - val_categorical_accuracy: 0.6026\n",
      "Epoch 48/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.0454 - acc: 0.6133 - categorical_accuracy: 0.6133 - val_loss: 1.0433 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 49/70\n",
      "7600/7600 [==============================] - 2s 261us/sample - loss: 1.0423 - acc: 0.6130 - categorical_accuracy: 0.6130 - val_loss: 1.0418 - val_acc: 0.6063 - val_categorical_accuracy: 0.6063\n",
      "Epoch 50/70\n",
      "7600/7600 [==============================] - 2s 269us/sample - loss: 1.0428 - acc: 0.6139 - categorical_accuracy: 0.6139 - val_loss: 1.0408 - val_acc: 0.6047 - val_categorical_accuracy: 0.6047\n",
      "Epoch 51/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0413 - acc: 0.6117 - categorical_accuracy: 0.6117 - val_loss: 1.0390 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 52/70\n",
      "7600/7600 [==============================] - 2s 264us/sample - loss: 1.0390 - acc: 0.6117 - categorical_accuracy: 0.6117 - val_loss: 1.0380 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 53/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0385 - acc: 0.6132 - categorical_accuracy: 0.6132 - val_loss: 1.0372 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 54/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0364 - acc: 0.6128 - categorical_accuracy: 0.6128 - val_loss: 1.0357 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 55/70\n",
      "7600/7600 [==============================] - 2s 265us/sample - loss: 1.0344 - acc: 0.6151 - categorical_accuracy: 0.6151 - val_loss: 1.0350 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 56/70\n",
      "7600/7600 [==============================] - 2s 267us/sample - loss: 1.0350 - acc: 0.6132 - categorical_accuracy: 0.6132 - val_loss: 1.0340 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 57/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0349 - acc: 0.6166 - categorical_accuracy: 0.6166 - val_loss: 1.0329 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 58/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.0318 - acc: 0.6151 - categorical_accuracy: 0.6151 - val_loss: 1.0319 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 59/70\n",
      "7600/7600 [==============================] - 2s 263us/sample - loss: 1.0298 - acc: 0.6143 - categorical_accuracy: 0.6143 - val_loss: 1.0312 - val_acc: 0.6084 - val_categorical_accuracy: 0.6084\n",
      "Epoch 60/70\n",
      "7600/7600 [==============================] - 2s 262us/sample - loss: 1.0320 - acc: 0.6154 - categorical_accuracy: 0.6154 - val_loss: 1.0320 - val_acc: 0.6100 - val_categorical_accuracy: 0.6100\n",
      "Epoch 61/70\n",
      "7600/7600 [==============================] - 2s 258us/sample - loss: 1.0304 - acc: 0.6154 - categorical_accuracy: 0.6154 - val_loss: 1.0304 - val_acc: 0.6111 - val_categorical_accuracy: 0.6111\n",
      "Epoch 62/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.0284 - acc: 0.6161 - categorical_accuracy: 0.6161 - val_loss: 1.0297 - val_acc: 0.6058 - val_categorical_accuracy: 0.6058\n",
      "Epoch 63/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.0297 - acc: 0.6155 - categorical_accuracy: 0.6155 - val_loss: 1.0294 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 64/70\n",
      "7600/7600 [==============================] - 2s 270us/sample - loss: 1.0278 - acc: 0.6146 - categorical_accuracy: 0.6146 - val_loss: 1.0283 - val_acc: 0.6100 - val_categorical_accuracy: 0.6100\n",
      "Epoch 65/70\n",
      "7600/7600 [==============================] - 2s 270us/sample - loss: 1.0277 - acc: 0.6176 - categorical_accuracy: 0.6176 - val_loss: 1.0278 - val_acc: 0.6126 - val_categorical_accuracy: 0.6126\n",
      "Epoch 66/70\n",
      "7600/7600 [==============================] - 2s 273us/sample - loss: 1.0273 - acc: 0.6157 - categorical_accuracy: 0.6157 - val_loss: 1.0272 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 67/70\n",
      "7600/7600 [==============================] - 2s 270us/sample - loss: 1.0260 - acc: 0.6139 - categorical_accuracy: 0.6139 - val_loss: 1.0264 - val_acc: 0.6084 - val_categorical_accuracy: 0.6084\n",
      "Epoch 68/70\n",
      "7600/7600 [==============================] - 2s 266us/sample - loss: 1.0261 - acc: 0.6167 - categorical_accuracy: 0.6167 - val_loss: 1.0261 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 69/70\n",
      "7600/7600 [==============================] - 2s 255us/sample - loss: 1.0261 - acc: 0.6162 - categorical_accuracy: 0.6162 - val_loss: 1.0254 - val_acc: 0.6084 - val_categorical_accuracy: 0.6084\n",
      "Epoch 70/70\n",
      "7600/7600 [==============================] - 2s 222us/sample - loss: 1.0224 - acc: 0.6161 - categorical_accuracy: 0.6161 - val_loss: 1.0250 - val_acc: 0.6100 - val_categorical_accuracy: 0.6100\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1091,   29,   14,    0],\n",
       "       [ 420,   44,   16,    0],\n",
       "       [ 153,   32,   24,    0],\n",
       "       [  48,   18,   11,    0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### PAS CELUI-LA!!\n",
    "'''\n",
    "history_age = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                            shuffle=True, batch_size=64, epochs=70, verbose=1, \n",
    "                            validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age)\n",
    "                           )\n",
    "\n",
    "# baseline for age group:\n",
    "print(y_val['age_group'].value_counts()[0]/y_val.shape[0])\n",
    "\n",
    "#score_age = model_age.evaluate([x_val_txt, x_val_img, x_val_lik], y_val_age, verbose=1)\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "likes_features (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_features (InputLayer)      [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "likes_embedding_block (Sequenti (None, 800)          80000       likes_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_layers (Sequential)       (None, 62)           63240       text_features[0][0]              \n",
      "                                                                 image_features[0][0]             \n",
      "                                                                 likes_embedding_block[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "age_group (Dense)               (None, 4)            252         dense_layers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 143,492\n",
      "Trainable params: 143,492\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Try different max number of liked pages per user!!\n",
    "\n",
    "# model category age using embedding for likes\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "image_features = tf.keras.Input([num_image_features], dtype=tf.float32, name=\"image_features\")\n",
    "text_features  = tf.keras.Input([num_text_features], dtype=tf.float32, name=\"text_features\")\n",
    "likes_features = tf.keras.Input([max_len], dtype=tf.int32, name=\"likes_features\")\n",
    "\n",
    "likes_embedding_block = tf.keras.Sequential(name=\"likes_embedding_block\")\n",
    "likes_embedding_block.add(tf.keras.layers.Embedding(10000, 8, input_length=max_len,\n",
    "                                                    #embeddings_regularizer=tf.keras.regularizers.L1L2(l1=0.0001, l2=0.0001),\n",
    "                                                   mask_zero=True))\n",
    "\n",
    "### GlobalAveragePooling1D averages the embeddings of all pages liked by a user\n",
    "#likes_embedding_block.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "likes_embedding_block.add(tf.keras.layers.Flatten())\n",
    "\n",
    "## Experimenting: Not helping at all... just learning the baseline\n",
    "# Trying to reduce contribution of likes to balance out input modalities\n",
    "#likes_embedding_block.add(tf.keras.layers.Dense(\n",
    "#    units = 128, activation= 'tanh', \n",
    "#    kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "## Experimenting\n",
    "\n",
    "condensed_likes = likes_embedding_block(likes_features)\n",
    "\n",
    "dense_layers = tf.keras.Sequential(name=\"dense_layers\")\n",
    "dense_layers.add(tf.keras.layers.Concatenate())\n",
    "for i in range(num_layers):\n",
    "    dense_layers.add(tf.keras.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation= 'tanh', #'tanh',\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg),      \n",
    "        ))\n",
    "        \n",
    "    dense_layers.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "features = dense_layers([text_features, image_features, condensed_likes])\n",
    "\n",
    "age_group = tf.keras.layers.Dense(units=4, activation=\"softmax\", name=\"age_group\")(features)\n",
    "\n",
    "model_age = tf.keras.Model(\n",
    "    inputs=[text_features, image_features, likes_features],\n",
    "    outputs= age_group\n",
    ")    \n",
    "\n",
    "model_age.compile(\n",
    "    optimizer = tf.keras.optimizers.get({\"class_name\": \"ADAM\", #'ADAM'\n",
    "                               \"config\": {\"learning_rate\": 0.0001}}),    \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc', 'categorical_accuracy']\n",
    ")\n",
    "\n",
    "print(model_age.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_500, x_val_500, y_train_500, y_val_500\n",
    "\n",
    "x_train_txt = x_train_100.iloc[:, :91].values\n",
    "x_train_img = x_train_100.iloc[:, 91:156].values\n",
    "x_train_lik = x_train_100.iloc[:, 156:].values\n",
    "\n",
    "x_val_txt = x_val_100.iloc[:, :91].values\n",
    "x_val_img = x_val_100.iloc[:, 91:156].values\n",
    "x_val_lik = x_val_100.iloc[:, 156:].values\n",
    "\n",
    "y_train_age = tf.keras.utils.to_categorical(y_train_100['age_group'].values)\n",
    "\n",
    "y_val_age = tf.keras.utils.to_categorical(y_val_100['age_group'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/30\n",
      "7600/7600 [==============================] - 3s 420us/sample - loss: 6.6899 - acc: 0.4746 - categorical_accuracy: 0.4746 - val_loss: 4.6266 - val_acc: 0.5758 - val_categorical_accuracy: 0.5758\n",
      "Epoch 2/30\n",
      "7600/7600 [==============================] - 2s 245us/sample - loss: 3.7514 - acc: 0.5568 - categorical_accuracy: 0.5568 - val_loss: 3.2982 - val_acc: 0.6021 - val_categorical_accuracy: 0.6021\n",
      "Epoch 3/30\n",
      "7600/7600 [==============================] - 2s 245us/sample - loss: 3.1316 - acc: 0.5709 - categorical_accuracy: 0.5709 - val_loss: 3.0042 - val_acc: 0.5600 - val_categorical_accuracy: 0.5600\n",
      "Epoch 4/30\n",
      "7600/7600 [==============================] - 2s 240us/sample - loss: 2.8670 - acc: 0.5734 - categorical_accuracy: 0.5734 - val_loss: 2.7674 - val_acc: 0.5826 - val_categorical_accuracy: 0.5826\n",
      "Epoch 5/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 2.6438 - acc: 0.5809 - categorical_accuracy: 0.5809 - val_loss: 2.5738 - val_acc: 0.6111 - val_categorical_accuracy: 0.6111\n",
      "Epoch 6/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 2.4562 - acc: 0.5895 - categorical_accuracy: 0.5895 - val_loss: 2.3980 - val_acc: 0.5884 - val_categorical_accuracy: 0.5884\n",
      "Epoch 7/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 2.2953 - acc: 0.5917 - categorical_accuracy: 0.5917 - val_loss: 2.2565 - val_acc: 0.5742 - val_categorical_accuracy: 0.5742\n",
      "Epoch 8/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 2.1597 - acc: 0.6009 - categorical_accuracy: 0.6009 - val_loss: 2.1476 - val_acc: 0.5411 - val_categorical_accuracy: 0.5411\n",
      "Epoch 9/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 2.0441 - acc: 0.5964 - categorical_accuracy: 0.5964 - val_loss: 2.0408 - val_acc: 0.5437 - val_categorical_accuracy: 0.5437\n",
      "Epoch 10/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 1.9377 - acc: 0.5991 - categorical_accuracy: 0.5991 - val_loss: 1.9366 - val_acc: 0.5868 - val_categorical_accuracy: 0.5868\n",
      "Epoch 11/30\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 1.8500 - acc: 0.6005 - categorical_accuracy: 0.6005 - val_loss: 1.8559 - val_acc: 0.6005 - val_categorical_accuracy: 0.6005\n",
      "Epoch 12/30\n",
      "7600/7600 [==============================] - 2s 242us/sample - loss: 1.7727 - acc: 0.6011 - categorical_accuracy: 0.6011 - val_loss: 1.7799 - val_acc: 0.5937 - val_categorical_accuracy: 0.5937\n",
      "Epoch 13/30\n",
      "7600/7600 [==============================] - 2s 243us/sample - loss: 1.7059 - acc: 0.6051 - categorical_accuracy: 0.6051 - val_loss: 1.7221 - val_acc: 0.6042 - val_categorical_accuracy: 0.6042\n",
      "Epoch 14/30\n",
      "7600/7600 [==============================] - 2s 242us/sample - loss: 1.6439 - acc: 0.6063 - categorical_accuracy: 0.6063 - val_loss: 1.6717 - val_acc: 0.5700 - val_categorical_accuracy: 0.5700\n",
      "Epoch 15/30\n",
      "7600/7600 [==============================] - 2s 242us/sample - loss: 1.5991 - acc: 0.6067 - categorical_accuracy: 0.6067 - val_loss: 1.6258 - val_acc: 0.6053 - val_categorical_accuracy: 0.6053\n",
      "Epoch 16/30\n",
      "7600/7600 [==============================] - 2s 243us/sample - loss: 1.5496 - acc: 0.6129 - categorical_accuracy: 0.6129 - val_loss: 1.5888 - val_acc: 0.5779 - val_categorical_accuracy: 0.5779\n",
      "Epoch 17/30\n",
      "7600/7600 [==============================] - 2s 242us/sample - loss: 1.5077 - acc: 0.6175 - categorical_accuracy: 0.6175 - val_loss: 1.5478 - val_acc: 0.6000 - val_categorical_accuracy: 0.6000\n",
      "Epoch 18/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 1.4672 - acc: 0.6247 - categorical_accuracy: 0.6247 - val_loss: 1.5195 - val_acc: 0.5874 - val_categorical_accuracy: 0.5874\n",
      "Epoch 19/30\n",
      "7600/7600 [==============================] - 2s 245us/sample - loss: 1.4323 - acc: 0.6289 - categorical_accuracy: 0.6289 - val_loss: 1.4797 - val_acc: 0.6247 - val_categorical_accuracy: 0.6247\n",
      "Epoch 20/30\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 1.3921 - acc: 0.6416 - categorical_accuracy: 0.6416 - val_loss: 1.4466 - val_acc: 0.6195 - val_categorical_accuracy: 0.6195\n",
      "Epoch 21/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 1.3467 - acc: 0.6632 - categorical_accuracy: 0.6632 - val_loss: 1.4059 - val_acc: 0.6458 - val_categorical_accuracy: 0.6458\n",
      "Epoch 22/30\n",
      "7600/7600 [==============================] - 2s 246us/sample - loss: 1.3061 - acc: 0.6786 - categorical_accuracy: 0.6786 - val_loss: 1.3888 - val_acc: 0.6142 - val_categorical_accuracy: 0.6142\n",
      "Epoch 23/30\n",
      "7600/7600 [==============================] - 2s 240us/sample - loss: 1.2651 - acc: 0.6866 - categorical_accuracy: 0.6866 - val_loss: 1.3629 - val_acc: 0.6442 - val_categorical_accuracy: 0.6442\n",
      "Epoch 24/30\n",
      "7600/7600 [==============================] - 2s 245us/sample - loss: 1.2268 - acc: 0.6993 - categorical_accuracy: 0.6993 - val_loss: 1.3489 - val_acc: 0.6463 - val_categorical_accuracy: 0.6463\n",
      "Epoch 25/30\n",
      "7600/7600 [==============================] - 2s 243us/sample - loss: 1.1955 - acc: 0.7087 - categorical_accuracy: 0.7087 - val_loss: 1.3385 - val_acc: 0.6526 - val_categorical_accuracy: 0.6526\n",
      "Epoch 26/30\n",
      "7600/7600 [==============================] - 2s 243us/sample - loss: 1.1677 - acc: 0.7145 - categorical_accuracy: 0.7145 - val_loss: 1.3329 - val_acc: 0.6458 - val_categorical_accuracy: 0.6458\n",
      "Epoch 27/30\n",
      "7600/7600 [==============================] - 2s 244us/sample - loss: 1.1372 - acc: 0.7291 - categorical_accuracy: 0.7291 - val_loss: 1.3294 - val_acc: 0.6663 - val_categorical_accuracy: 0.6663\n",
      "Epoch 28/30\n",
      "7600/7600 [==============================] - 2s 243us/sample - loss: 1.1051 - acc: 0.7338 - categorical_accuracy: 0.7338 - val_loss: 1.3315 - val_acc: 0.6726 - val_categorical_accuracy: 0.6726\n",
      "Epoch 29/30\n",
      "7600/7600 [==============================] - 2s 241us/sample - loss: 1.0851 - acc: 0.7379 - categorical_accuracy: 0.7379 - val_loss: 1.3356 - val_acc: 0.6632 - val_categorical_accuracy: 0.6632\n",
      "Epoch 30/30\n",
      "7600/7600 [==============================] - 2s 244us/sample - loss: 1.0561 - acc: 0.7543 - categorical_accuracy: 0.7543 - val_loss: 1.3421 - val_acc: 0.6753 - val_categorical_accuracy: 0.6753\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[891, 234,   9,   0],\n",
       "       [124, 289,  67,   0],\n",
       "       [ 19,  87, 103,   0],\n",
       "       [  7,  24,  46,   0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_age_balanced_mild = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=16, epochs=30, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     class_weight=age_weights_dict_first3\n",
    "                                    )\n",
    "\n",
    "# validation baseline for age group:\n",
    "print(y_val_100['age_group'].value_counts()[0]/y_val_100.shape[0])\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "likes_features (InputLayer)     [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_features (InputLayer)      [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "likes_embedding_block (Sequenti (None, 1600)         80000       likes_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_layers (Sequential)       (None, 62)           112840      text_features[0][0]              \n",
      "                                                                 image_features[0][0]             \n",
      "                                                                 likes_embedding_block[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "age_group (Dense)               (None, 4)            252         dense_layers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 193,092\n",
      "Trainable params: 193,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Try different max number of liked pages per user!!\n",
    "\n",
    "# model category age using embedding for likes\n",
    "\n",
    "max_len = 200\n",
    "\n",
    "image_features = tf.keras.Input([num_image_features], dtype=tf.float32, name=\"image_features\")\n",
    "text_features  = tf.keras.Input([num_text_features], dtype=tf.float32, name=\"text_features\")\n",
    "likes_features = tf.keras.Input([max_len], dtype=tf.int32, name=\"likes_features\")\n",
    "\n",
    "likes_embedding_block = tf.keras.Sequential(name=\"likes_embedding_block\")\n",
    "likes_embedding_block.add(tf.keras.layers.Embedding(10000, 8, input_length=max_len,\n",
    "                                                    #embeddings_regularizer=tf.keras.regularizers.L1L2(l1=0.0001, l2=0.0001),\n",
    "                                                   mask_zero=True))\n",
    "\n",
    "### GlobalAveragePooling1D averages the embeddings of all pages liked by a user\n",
    "#likes_embedding_block.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "likes_embedding_block.add(tf.keras.layers.Flatten())\n",
    "\n",
    "## Experimenting: Not helping at all... just learning the baseline\n",
    "# Trying to reduce contribution of likes to balance out input modalities\n",
    "#likes_embedding_block.add(tf.keras.layers.Dense(\n",
    "#    units = 128, activation= 'tanh', \n",
    "#    kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "## Experimenting\n",
    "\n",
    "condensed_likes = likes_embedding_block(likes_features)\n",
    "\n",
    "dense_layers = tf.keras.Sequential(name=\"dense_layers\")\n",
    "dense_layers.add(tf.keras.layers.Concatenate())\n",
    "for i in range(num_layers):\n",
    "    dense_layers.add(tf.keras.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation= 'tanh', #'tanh',\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg),      \n",
    "        ))\n",
    "        \n",
    "    dense_layers.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "features = dense_layers([text_features, image_features, condensed_likes])\n",
    "\n",
    "age_group = tf.keras.layers.Dense(units=4, activation=\"softmax\", name=\"age_group\")(features)\n",
    "\n",
    "model_age = tf.keras.Model(\n",
    "    inputs=[text_features, image_features, likes_features],\n",
    "    outputs= age_group\n",
    ")    \n",
    "\n",
    "model_age.compile(\n",
    "    optimizer = tf.keras.optimizers.get({\"class_name\": \"ADAM\", #'ADAM'\n",
    "                               \"config\": {\"learning_rate\": 0.0001}}),    \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc', 'categorical_accuracy']\n",
    ")\n",
    "\n",
    "print(model_age.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_500, x_val_500, y_train_500, y_val_500\n",
    "\n",
    "x_train_txt = x_train_200.iloc[:, :91].values\n",
    "x_train_img = x_train_200.iloc[:, 91:156].values\n",
    "x_train_lik = x_train_200.iloc[:, 156:].values\n",
    "\n",
    "x_val_txt = x_val_200.iloc[:, :91].values\n",
    "x_val_img = x_val_200.iloc[:, 91:156].values\n",
    "x_val_lik = x_val_200.iloc[:, 156:].values\n",
    "\n",
    "y_train_age = tf.keras.utils.to_categorical(y_train_200['age_group'].values)\n",
    "\n",
    "y_val_age = tf.keras.utils.to_categorical(y_val_200['age_group'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/30\n",
      "7600/7600 [==============================] - 3s 444us/sample - loss: 7.1958 - acc: 0.5289 - categorical_accuracy: 0.5289 - val_loss: 4.1471 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 2/30\n",
      "7600/7600 [==============================] - 2s 225us/sample - loss: 3.4122 - acc: 0.5662 - categorical_accuracy: 0.5662 - val_loss: 3.0775 - val_acc: 0.5647 - val_categorical_accuracy: 0.5647\n",
      "Epoch 3/30\n",
      "7600/7600 [==============================] - 2s 237us/sample - loss: 2.9789 - acc: 0.5632 - categorical_accuracy: 0.5632 - val_loss: 2.8278 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 4/30\n",
      "7600/7600 [==============================] - 2s 229us/sample - loss: 2.7497 - acc: 0.5726 - categorical_accuracy: 0.5726 - val_loss: 2.6132 - val_acc: 0.5932 - val_categorical_accuracy: 0.5932\n",
      "Epoch 5/30\n",
      "7600/7600 [==============================] - 2s 230us/sample - loss: 2.5541 - acc: 0.5853 - categorical_accuracy: 0.5853 - val_loss: 2.4360 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 6/30\n",
      "7600/7600 [==============================] - 2s 229us/sample - loss: 2.3766 - acc: 0.5913 - categorical_accuracy: 0.5913 - val_loss: 2.2948 - val_acc: 0.6074 - val_categorical_accuracy: 0.6074\n",
      "Epoch 7/30\n",
      "7600/7600 [==============================] - 2s 236us/sample - loss: 2.2278 - acc: 0.5949 - categorical_accuracy: 0.5949 - val_loss: 2.1436 - val_acc: 0.5895 - val_categorical_accuracy: 0.5895\n",
      "Epoch 8/30\n",
      "7600/7600 [==============================] - 2s 229us/sample - loss: 2.1043 - acc: 0.5933 - categorical_accuracy: 0.5933 - val_loss: 2.0342 - val_acc: 0.5895 - val_categorical_accuracy: 0.5895\n",
      "Epoch 9/30\n",
      "7600/7600 [==============================] - 2s 227us/sample - loss: 1.9943 - acc: 0.6036 - categorical_accuracy: 0.6036 - val_loss: 1.9354 - val_acc: 0.6032 - val_categorical_accuracy: 0.6032\n",
      "Epoch 10/30\n",
      "7600/7600 [==============================] - 2s 224us/sample - loss: 1.8999 - acc: 0.5983 - categorical_accuracy: 0.5983 - val_loss: 1.8414 - val_acc: 0.5884 - val_categorical_accuracy: 0.5884\n",
      "Epoch 11/30\n",
      "7600/7600 [==============================] - 2s 237us/sample - loss: 1.8152 - acc: 0.5968 - categorical_accuracy: 0.5968 - val_loss: 1.7714 - val_acc: 0.5963 - val_categorical_accuracy: 0.5963\n",
      "Epoch 12/30\n",
      "7600/7600 [==============================] - 2s 224us/sample - loss: 1.7431 - acc: 0.6064 - categorical_accuracy: 0.6064 - val_loss: 1.7082 - val_acc: 0.6121 - val_categorical_accuracy: 0.6121\n",
      "Epoch 13/30\n",
      "7600/7600 [==============================] - 2s 226us/sample - loss: 1.6789 - acc: 0.6064 - categorical_accuracy: 0.6064 - val_loss: 1.6582 - val_acc: 0.5884 - val_categorical_accuracy: 0.5884\n",
      "Epoch 14/30\n",
      "7600/7600 [==============================] - 2s 228us/sample - loss: 1.6187 - acc: 0.6109 - categorical_accuracy: 0.6109 - val_loss: 1.6013 - val_acc: 0.6000 - val_categorical_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "7600/7600 [==============================] - 2s 231us/sample - loss: 1.5642 - acc: 0.6166 - categorical_accuracy: 0.6166 - val_loss: 1.5557 - val_acc: 0.6147 - val_categorical_accuracy: 0.6147\n",
      "Epoch 16/30\n",
      "7600/7600 [==============================] - 2s 226us/sample - loss: 1.5145 - acc: 0.6296 - categorical_accuracy: 0.6296 - val_loss: 1.5159 - val_acc: 0.6132 - val_categorical_accuracy: 0.6132\n",
      "Epoch 17/30\n",
      "7600/7600 [==============================] - 2s 227us/sample - loss: 1.4625 - acc: 0.6412 - categorical_accuracy: 0.6412 - val_loss: 1.4736 - val_acc: 0.6263 - val_categorical_accuracy: 0.6263\n",
      "Epoch 18/30\n",
      "7600/7600 [==============================] - 2s 234us/sample - loss: 1.4099 - acc: 0.6537 - categorical_accuracy: 0.6537 - val_loss: 1.4396 - val_acc: 0.6221 - val_categorical_accuracy: 0.6221\n",
      "Epoch 19/30\n",
      "7600/7600 [==============================] - 2s 231us/sample - loss: 1.3696 - acc: 0.6666 - categorical_accuracy: 0.6666 - val_loss: 1.4126 - val_acc: 0.6374 - val_categorical_accuracy: 0.6374\n",
      "Epoch 20/30\n",
      "7600/7600 [==============================] - 2s 224us/sample - loss: 1.3216 - acc: 0.6797 - categorical_accuracy: 0.6797 - val_loss: 1.3866 - val_acc: 0.6379 - val_categorical_accuracy: 0.6379\n",
      "Epoch 21/30\n",
      "7600/7600 [==============================] - 2s 226us/sample - loss: 1.2833 - acc: 0.6882 - categorical_accuracy: 0.6882 - val_loss: 1.3752 - val_acc: 0.6558 - val_categorical_accuracy: 0.6558\n",
      "Epoch 22/30\n",
      "7600/7600 [==============================] - 2s 235us/sample - loss: 1.2555 - acc: 0.6950 - categorical_accuracy: 0.6950 - val_loss: 1.3653 - val_acc: 0.6453 - val_categorical_accuracy: 0.6453\n",
      "Epoch 23/30\n",
      "7600/7600 [==============================] - 2s 229us/sample - loss: 1.2248 - acc: 0.7037 - categorical_accuracy: 0.7037 - val_loss: 1.3646 - val_acc: 0.6558 - val_categorical_accuracy: 0.6558\n",
      "Epoch 24/30\n",
      "7600/7600 [==============================] - 2s 225us/sample - loss: 1.1975 - acc: 0.7054 - categorical_accuracy: 0.7054 - val_loss: 1.3408 - val_acc: 0.6537 - val_categorical_accuracy: 0.6537\n",
      "Epoch 25/30\n",
      "7600/7600 [==============================] - 2s 225us/sample - loss: 1.1645 - acc: 0.7186 - categorical_accuracy: 0.7186 - val_loss: 1.3456 - val_acc: 0.6547 - val_categorical_accuracy: 0.6547\n",
      "Epoch 26/30\n",
      "7600/7600 [==============================] - 2s 234us/sample - loss: 1.1455 - acc: 0.7241 - categorical_accuracy: 0.7241 - val_loss: 1.3528 - val_acc: 0.6579 - val_categorical_accuracy: 0.6579\n",
      "Epoch 27/30\n",
      "7600/7600 [==============================] - 2s 225us/sample - loss: 1.1182 - acc: 0.7280 - categorical_accuracy: 0.7280 - val_loss: 1.3462 - val_acc: 0.6432 - val_categorical_accuracy: 0.6432\n",
      "Epoch 28/30\n",
      "7600/7600 [==============================] - 2s 226us/sample - loss: 1.0984 - acc: 0.7387 - categorical_accuracy: 0.7387 - val_loss: 1.3749 - val_acc: 0.6679 - val_categorical_accuracy: 0.6679\n",
      "Epoch 29/30\n",
      "7600/7600 [==============================] - 2s 225us/sample - loss: 1.0771 - acc: 0.7446 - categorical_accuracy: 0.7446 - val_loss: 1.3563 - val_acc: 0.6437 - val_categorical_accuracy: 0.6437\n",
      "Epoch 30/30\n",
      "7600/7600 [==============================] - 2s 235us/sample - loss: 1.0514 - acc: 0.7484 - categorical_accuracy: 0.7484 - val_loss: 1.3715 - val_acc: 0.6589 - val_categorical_accuracy: 0.6589\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[898, 227,   9,   0],\n",
       "       [147, 271,  62,   0],\n",
       "       [ 16, 110,  83,   0],\n",
       "       [  8,  28,  41,   0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_age_balanced_mild = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=16, epochs=30, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     class_weight=age_weights_dict_first3\n",
    "                                    )\n",
    "\n",
    "# validation baseline for age group:\n",
    "print(y_val_200['age_group'].value_counts()[0]/y_val_200.shape[0])\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "likes_features (InputLayer)     [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_features (InputLayer)      [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "likes_embedding_block (Sequenti (None, 4000)         80000       likes_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_layers (Sequential)       (None, 62)           261640      text_features[0][0]              \n",
      "                                                                 image_features[0][0]             \n",
      "                                                                 likes_embedding_block[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "age_group (Dense)               (None, 4)            252         dense_layers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 341,892\n",
      "Trainable params: 341,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/50\n",
      "7600/7600 [==============================] - 2s 269us/sample - loss: 12.5291 - acc: 0.5245 - categorical_accuracy: 0.5245 - val_loss: 9.4136 - val_acc: 0.5826 - val_categorical_accuracy: 0.5826\n",
      "Epoch 2/50\n",
      "7600/7600 [==============================] - 1s 101us/sample - loss: 7.1854 - acc: 0.5754 - categorical_accuracy: 0.5754 - val_loss: 5.2689 - val_acc: 0.5821 - val_categorical_accuracy: 0.5821\n",
      "Epoch 3/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 4.1125 - acc: 0.5829 - categorical_accuracy: 0.5829 - val_loss: 3.2562 - val_acc: 0.6037 - val_categorical_accuracy: 0.6037\n",
      "Epoch 4/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 3.0063 - acc: 0.5834 - categorical_accuracy: 0.5834 - val_loss: 2.8743 - val_acc: 0.5937 - val_categorical_accuracy: 0.5937\n",
      "Epoch 5/50\n",
      "7600/7600 [==============================] - 1s 101us/sample - loss: 2.8185 - acc: 0.5861 - categorical_accuracy: 0.5861 - val_loss: 2.7580 - val_acc: 0.5674 - val_categorical_accuracy: 0.5674\n",
      "Epoch 6/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 2.6992 - acc: 0.5874 - categorical_accuracy: 0.5874 - val_loss: 2.6506 - val_acc: 0.5721 - val_categorical_accuracy: 0.5721\n",
      "Epoch 7/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 2.6038 - acc: 0.5858 - categorical_accuracy: 0.5858 - val_loss: 2.5609 - val_acc: 0.5589 - val_categorical_accuracy: 0.5589\n",
      "Epoch 8/50\n",
      "7600/7600 [==============================] - 1s 105us/sample - loss: 2.5119 - acc: 0.5932 - categorical_accuracy: 0.5932 - val_loss: 2.4677 - val_acc: 0.5926 - val_categorical_accuracy: 0.5926\n",
      "Epoch 9/50\n",
      "7600/7600 [==============================] - 1s 106us/sample - loss: 2.4253 - acc: 0.5932 - categorical_accuracy: 0.5932 - val_loss: 2.3875 - val_acc: 0.5768 - val_categorical_accuracy: 0.5768\n",
      "Epoch 10/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 2.3489 - acc: 0.5918 - categorical_accuracy: 0.5918 - val_loss: 2.3207 - val_acc: 0.5584 - val_categorical_accuracy: 0.5584\n",
      "Epoch 11/50\n",
      "7600/7600 [==============================] - 1s 106us/sample - loss: 2.2796 - acc: 0.5908 - categorical_accuracy: 0.5908 - val_loss: 2.2395 - val_acc: 0.5837 - val_categorical_accuracy: 0.5837\n",
      "Epoch 12/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 2.2054 - acc: 0.5999 - categorical_accuracy: 0.5999 - val_loss: 2.1729 - val_acc: 0.6000 - val_categorical_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 2.1378 - acc: 0.6007 - categorical_accuracy: 0.6007 - val_loss: 2.1186 - val_acc: 0.5811 - val_categorical_accuracy: 0.5811\n",
      "Epoch 14/50\n",
      "7600/7600 [==============================] - 1s 100us/sample - loss: 2.0804 - acc: 0.6033 - categorical_accuracy: 0.6033 - val_loss: 2.0585 - val_acc: 0.6021 - val_categorical_accuracy: 0.6021\n",
      "Epoch 15/50\n",
      "7600/7600 [==============================] - 1s 109us/sample - loss: 2.0247 - acc: 0.6032 - categorical_accuracy: 0.6032 - val_loss: 2.0087 - val_acc: 0.6063 - val_categorical_accuracy: 0.6063\n",
      "Epoch 16/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.9724 - acc: 0.5966 - categorical_accuracy: 0.5966 - val_loss: 1.9621 - val_acc: 0.5995 - val_categorical_accuracy: 0.5995\n",
      "Epoch 17/50\n",
      "7600/7600 [==============================] - 1s 100us/sample - loss: 1.9326 - acc: 0.6012 - categorical_accuracy: 0.6012 - val_loss: 1.9184 - val_acc: 0.5963 - val_categorical_accuracy: 0.5963\n",
      "Epoch 18/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.8833 - acc: 0.6028 - categorical_accuracy: 0.6028 - val_loss: 1.8805 - val_acc: 0.5879 - val_categorical_accuracy: 0.5879\n",
      "Epoch 19/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.8459 - acc: 0.5946 - categorical_accuracy: 0.5946 - val_loss: 1.8413 - val_acc: 0.5811 - val_categorical_accuracy: 0.5811\n",
      "Epoch 20/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.8041 - acc: 0.5974 - categorical_accuracy: 0.5974 - val_loss: 1.8032 - val_acc: 0.5963 - val_categorical_accuracy: 0.5963\n",
      "Epoch 21/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.7734 - acc: 0.6014 - categorical_accuracy: 0.6014 - val_loss: 1.7689 - val_acc: 0.6079 - val_categorical_accuracy: 0.6079\n",
      "Epoch 22/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.7425 - acc: 0.6086 - categorical_accuracy: 0.6086 - val_loss: 1.7389 - val_acc: 0.5916 - val_categorical_accuracy: 0.5916\n",
      "Epoch 23/50\n",
      "7600/7600 [==============================] - 1s 103us/sample - loss: 1.7121 - acc: 0.6076 - categorical_accuracy: 0.6076 - val_loss: 1.7054 - val_acc: 0.6095 - val_categorical_accuracy: 0.6095\n",
      "Epoch 24/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.6714 - acc: 0.6093 - categorical_accuracy: 0.6093 - val_loss: 1.6785 - val_acc: 0.6089 - val_categorical_accuracy: 0.6089\n",
      "Epoch 25/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.6456 - acc: 0.6122 - categorical_accuracy: 0.6122 - val_loss: 1.6587 - val_acc: 0.6026 - val_categorical_accuracy: 0.6026\n",
      "Epoch 26/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.6210 - acc: 0.6146 - categorical_accuracy: 0.6146 - val_loss: 1.6251 - val_acc: 0.6132 - val_categorical_accuracy: 0.6132\n",
      "Epoch 27/50\n",
      "7600/7600 [==============================] - 1s 109us/sample - loss: 1.5910 - acc: 0.6232 - categorical_accuracy: 0.6232 - val_loss: 1.6010 - val_acc: 0.6142 - val_categorical_accuracy: 0.6142\n",
      "Epoch 28/50\n",
      "7600/7600 [==============================] - 1s 102us/sample - loss: 1.5622 - acc: 0.6264 - categorical_accuracy: 0.6264 - val_loss: 1.5779 - val_acc: 0.6153 - val_categorical_accuracy: 0.6153\n",
      "Epoch 29/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.5390 - acc: 0.6312 - categorical_accuracy: 0.6312 - val_loss: 1.5630 - val_acc: 0.6116 - val_categorical_accuracy: 0.6116\n",
      "Epoch 30/50\n",
      "7600/7600 [==============================] - 1s 109us/sample - loss: 1.5090 - acc: 0.6411 - categorical_accuracy: 0.6411 - val_loss: 1.5333 - val_acc: 0.6268 - val_categorical_accuracy: 0.6268\n",
      "Epoch 31/50\n",
      "7600/7600 [==============================] - 1s 103us/sample - loss: 1.4782 - acc: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 1.5121 - val_acc: 0.6253 - val_categorical_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.4543 - acc: 0.6511 - categorical_accuracy: 0.6511 - val_loss: 1.4929 - val_acc: 0.6468 - val_categorical_accuracy: 0.6468\n",
      "Epoch 33/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.4285 - acc: 0.6614 - categorical_accuracy: 0.6614 - val_loss: 1.4695 - val_acc: 0.6421 - val_categorical_accuracy: 0.6421\n",
      "Epoch 34/50\n",
      "7600/7600 [==============================] - 1s 103us/sample - loss: 1.3984 - acc: 0.6691 - categorical_accuracy: 0.6691 - val_loss: 1.4507 - val_acc: 0.6505 - val_categorical_accuracy: 0.6505\n",
      "Epoch 35/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.3778 - acc: 0.6750 - categorical_accuracy: 0.6750 - val_loss: 1.4312 - val_acc: 0.6505 - val_categorical_accuracy: 0.6505\n",
      "Epoch 36/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.3542 - acc: 0.6779 - categorical_accuracy: 0.6779 - val_loss: 1.4193 - val_acc: 0.6563 - val_categorical_accuracy: 0.6563\n",
      "Epoch 37/50\n",
      "7600/7600 [==============================] - 1s 103us/sample - loss: 1.3292 - acc: 0.6853 - categorical_accuracy: 0.6853 - val_loss: 1.4025 - val_acc: 0.6600 - val_categorical_accuracy: 0.6600\n",
      "Epoch 38/50\n",
      "7600/7600 [==============================] - 1s 105us/sample - loss: 1.3088 - acc: 0.6896 - categorical_accuracy: 0.6896 - val_loss: 1.3843 - val_acc: 0.6537 - val_categorical_accuracy: 0.6537\n",
      "Epoch 39/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.2889 - acc: 0.6932 - categorical_accuracy: 0.6932 - val_loss: 1.3722 - val_acc: 0.6547 - val_categorical_accuracy: 0.6547\n",
      "Epoch 40/50\n",
      "7600/7600 [==============================] - 1s 105us/sample - loss: 1.2695 - acc: 0.6995 - categorical_accuracy: 0.6995 - val_loss: 1.3625 - val_acc: 0.6574 - val_categorical_accuracy: 0.6574\n",
      "Epoch 41/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.2497 - acc: 0.7050 - categorical_accuracy: 0.7050 - val_loss: 1.3607 - val_acc: 0.6668 - val_categorical_accuracy: 0.6668\n",
      "Epoch 42/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.2378 - acc: 0.7036 - categorical_accuracy: 0.7036 - val_loss: 1.3466 - val_acc: 0.6584 - val_categorical_accuracy: 0.6584\n",
      "Epoch 43/50\n",
      "7600/7600 [==============================] - 1s 106us/sample - loss: 1.2176 - acc: 0.7126 - categorical_accuracy: 0.7126 - val_loss: 1.3508 - val_acc: 0.6705 - val_categorical_accuracy: 0.6705\n",
      "Epoch 44/50\n",
      "7600/7600 [==============================] - 1s 108us/sample - loss: 1.1980 - acc: 0.7147 - categorical_accuracy: 0.7147 - val_loss: 1.3353 - val_acc: 0.6558 - val_categorical_accuracy: 0.6558\n",
      "Epoch 45/50\n",
      "7600/7600 [==============================] - 1s 107us/sample - loss: 1.1879 - acc: 0.7182 - categorical_accuracy: 0.7182 - val_loss: 1.3320 - val_acc: 0.6547 - val_categorical_accuracy: 0.6547\n",
      "Epoch 46/50\n",
      "7600/7600 [==============================] - 1s 100us/sample - loss: 1.1687 - acc: 0.7216 - categorical_accuracy: 0.7216 - val_loss: 1.3338 - val_acc: 0.6632 - val_categorical_accuracy: 0.6632\n",
      "Epoch 47/50\n",
      "7600/7600 [==============================] - 1s 109us/sample - loss: 1.1610 - acc: 0.7263 - categorical_accuracy: 0.7263 - val_loss: 1.3277 - val_acc: 0.6579 - val_categorical_accuracy: 0.6579\n",
      "Epoch 48/50\n",
      "7600/7600 [==============================] - 1s 111us/sample - loss: 1.1372 - acc: 0.7339 - categorical_accuracy: 0.7339 - val_loss: 1.3290 - val_acc: 0.6600 - val_categorical_accuracy: 0.6600\n",
      "Epoch 49/50\n",
      "7600/7600 [==============================] - 1s 106us/sample - loss: 1.1264 - acc: 0.7370 - categorical_accuracy: 0.7370 - val_loss: 1.3229 - val_acc: 0.6553 - val_categorical_accuracy: 0.6553\n",
      "Epoch 50/50\n",
      "7600/7600 [==============================] - 1s 112us/sample - loss: 1.1155 - acc: 0.7429 - categorical_accuracy: 0.7429 - val_loss: 1.3281 - val_acc: 0.6568 - val_categorical_accuracy: 0.6568\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[883, 243,   8,   0],\n",
       "       [159, 270,  51,   0],\n",
       "       [ 14, 100,  95,   0],\n",
       "       [  6,  43,  28,   0]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Try different max number of liked pages per user!!\n",
    "\n",
    "# model category age using embedding for likes\n",
    "\n",
    "max_len = 500\n",
    "\n",
    "image_features = tf.keras.Input([num_image_features], dtype=tf.float32, name=\"image_features\")\n",
    "text_features  = tf.keras.Input([num_text_features], dtype=tf.float32, name=\"text_features\")\n",
    "likes_features = tf.keras.Input([max_len], dtype=tf.int32, name=\"likes_features\")\n",
    "\n",
    "likes_embedding_block = tf.keras.Sequential(name=\"likes_embedding_block\")\n",
    "likes_embedding_block.add(tf.keras.layers.Embedding(10000, 8, input_length=max_len,\n",
    "                                                    #embeddings_regularizer=tf.keras.regularizers.L1L2(l1=0.0001, l2=0.0001),\n",
    "                                                   mask_zero=True))\n",
    "\n",
    "### GlobalAveragePooling1D averages the embeddings of all pages liked by a user\n",
    "#likes_embedding_block.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "likes_embedding_block.add(tf.keras.layers.Flatten())\n",
    "\n",
    "## Experimenting: Not helping at all... just learning the baseline\n",
    "# Trying to reduce contribution of likes to balance out input modalities\n",
    "#likes_embedding_block.add(tf.keras.layers.Dense(\n",
    "#    units = 128, activation= 'tanh', \n",
    "#    kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "## Experimenting\n",
    "\n",
    "condensed_likes = likes_embedding_block(likes_features)\n",
    "\n",
    "dense_layers = tf.keras.Sequential(name=\"dense_layers\")\n",
    "dense_layers.add(tf.keras.layers.Concatenate())\n",
    "for i in range(num_layers):\n",
    "    dense_layers.add(tf.keras.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation= 'tanh', #'tanh',\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg),      \n",
    "        ))\n",
    "        \n",
    "    dense_layers.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "features = dense_layers([text_features, image_features, condensed_likes])\n",
    "\n",
    "age_group = tf.keras.layers.Dense(units=4, activation=\"softmax\", name=\"age_group\")(features)\n",
    "\n",
    "model_age = tf.keras.Model(\n",
    "    inputs=[text_features, image_features, likes_features],\n",
    "    outputs= age_group\n",
    ")    \n",
    "\n",
    "model_age.compile(\n",
    "    optimizer = tf.keras.optimizers.get({\"class_name\": \"ADAM\", #'ADAM'\n",
    "                               \"config\": {\"learning_rate\": 0.0001}}),    \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc', 'categorical_accuracy']\n",
    ")\n",
    "\n",
    "print(model_age.summary())\n",
    "\n",
    "#x_train_500, x_val_500, y_train_500, y_val_500\n",
    "\n",
    "x_train_txt = x_train_500.iloc[:, :91].values\n",
    "x_train_img = x_train_500.iloc[:, 91:156].values\n",
    "x_train_lik = x_train_500.iloc[:, 156:].values\n",
    "\n",
    "x_val_txt = x_val_500.iloc[:, :91].values\n",
    "x_val_img = x_val_500.iloc[:, 91:156].values\n",
    "x_val_lik = x_val_500.iloc[:, 156:].values\n",
    "\n",
    "y_train_age = tf.keras.utils.to_categorical(y_train_500['age_group'].values)\n",
    "\n",
    "y_val_age = tf.keras.utils.to_categorical(y_val_500['age_group'].values)\n",
    "\n",
    "history_age_balanced_mild = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=64, epochs=50, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     class_weight=age_weights_dict_first3\n",
    "                                    )\n",
    "\n",
    "# validation baseline for age group:\n",
    "print(y_val_500['age_group'].value_counts()[0]/y_val_500.shape[0])\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "likes_features (InputLayer)     [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_features (InputLayer)      [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_features (InputLayer)     [(None, 65)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "likes_embedding_block (Sequenti (None, 8000)         80000       likes_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_layers (Sequential)       (None, 62)           509640      text_features[0][0]              \n",
      "                                                                 image_features[0][0]             \n",
      "                                                                 likes_embedding_block[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "age_group (Dense)               (None, 4)            252         dense_layers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 589,892\n",
      "Trainable params: 589,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 7600 samples, validate on 1900 samples\n",
      "Epoch 1/55\n",
      "7600/7600 [==============================] - 2s 276us/sample - loss: 14.6572 - acc: 0.5212 - categorical_accuracy: 0.5212 - val_loss: 9.2790 - val_acc: 0.4837 - val_categorical_accuracy: 0.4837\n",
      "Epoch 2/55\n",
      "7600/7600 [==============================] - 1s 140us/sample - loss: 6.0376 - acc: 0.5561 - categorical_accuracy: 0.5561 - val_loss: 3.7124 - val_acc: 0.5921 - val_categorical_accuracy: 0.5921\n",
      "Epoch 3/55\n",
      "7600/7600 [==============================] - 1s 138us/sample - loss: 3.0941 - acc: 0.5801 - categorical_accuracy: 0.5801 - val_loss: 2.8794 - val_acc: 0.5695 - val_categorical_accuracy: 0.5695\n",
      "Epoch 4/55\n",
      "7600/7600 [==============================] - 1s 133us/sample - loss: 2.8070 - acc: 0.5712 - categorical_accuracy: 0.5712 - val_loss: 2.7543 - val_acc: 0.5847 - val_categorical_accuracy: 0.5847\n",
      "Epoch 5/55\n",
      "7600/7600 [==============================] - 1s 133us/sample - loss: 2.6910 - acc: 0.5828 - categorical_accuracy: 0.5828 - val_loss: 2.6541 - val_acc: 0.5837 - val_categorical_accuracy: 0.5837\n",
      "Epoch 6/55\n",
      "7600/7600 [==============================] - 1s 134us/sample - loss: 2.5936 - acc: 0.5884 - categorical_accuracy: 0.5884 - val_loss: 2.5588 - val_acc: 0.5821 - val_categorical_accuracy: 0.5821\n",
      "Epoch 7/55\n",
      "7600/7600 [==============================] - 1s 134us/sample - loss: 2.5012 - acc: 0.5850 - categorical_accuracy: 0.5850 - val_loss: 2.4769 - val_acc: 0.5874 - val_categorical_accuracy: 0.5874\n",
      "Epoch 8/55\n",
      "7600/7600 [==============================] - 1s 133us/sample - loss: 2.4189 - acc: 0.5814 - categorical_accuracy: 0.5814 - val_loss: 2.4000 - val_acc: 0.5900 - val_categorical_accuracy: 0.5900\n",
      "Epoch 9/55\n",
      "7600/7600 [==============================] - 1s 134us/sample - loss: 2.3440 - acc: 0.5887 - categorical_accuracy: 0.5887 - val_loss: 2.3202 - val_acc: 0.5753 - val_categorical_accuracy: 0.5753\n",
      "Epoch 10/55\n",
      "7600/7600 [==============================] - 1s 138us/sample - loss: 2.2709 - acc: 0.5903 - categorical_accuracy: 0.5903 - val_loss: 2.2498 - val_acc: 0.5942 - val_categorical_accuracy: 0.5942\n",
      "Epoch 11/55\n",
      "7600/7600 [==============================] - 1s 133us/sample - loss: 2.2042 - acc: 0.5947 - categorical_accuracy: 0.5947 - val_loss: 2.1786 - val_acc: 0.5942 - val_categorical_accuracy: 0.5942\n",
      "Epoch 12/55\n",
      "7600/7600 [==============================] - 1s 127us/sample - loss: 2.1360 - acc: 0.6032 - categorical_accuracy: 0.6032 - val_loss: 2.1265 - val_acc: 0.5768 - val_categorical_accuracy: 0.5768\n",
      "Epoch 13/55\n",
      "7600/7600 [==============================] - 1s 127us/sample - loss: 2.0802 - acc: 0.5974 - categorical_accuracy: 0.5974 - val_loss: 2.0669 - val_acc: 0.5926 - val_categorical_accuracy: 0.5926\n",
      "Epoch 14/55\n",
      "7600/7600 [==============================] - 1s 127us/sample - loss: 2.0266 - acc: 0.6042 - categorical_accuracy: 0.6042 - val_loss: 2.0165 - val_acc: 0.5853 - val_categorical_accuracy: 0.5853\n",
      "Epoch 15/55\n",
      "7600/7600 [==============================] - 1s 140us/sample - loss: 1.9695 - acc: 0.5982 - categorical_accuracy: 0.5982 - val_loss: 1.9692 - val_acc: 0.6100 - val_categorical_accuracy: 0.6100\n",
      "Epoch 16/55\n",
      "7600/7600 [==============================] - 1s 144us/sample - loss: 1.9217 - acc: 0.5983 - categorical_accuracy: 0.5983 - val_loss: 1.9272 - val_acc: 0.6021 - val_categorical_accuracy: 0.6021\n",
      "Epoch 17/55\n",
      "7600/7600 [==============================] - 1s 141us/sample - loss: 1.8783 - acc: 0.6012 - categorical_accuracy: 0.6012 - val_loss: 1.8834 - val_acc: 0.5953 - val_categorical_accuracy: 0.5953\n",
      "Epoch 18/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.8362 - acc: 0.6008 - categorical_accuracy: 0.6008 - val_loss: 1.8485 - val_acc: 0.5574 - val_categorical_accuracy: 0.5574\n",
      "Epoch 19/55\n",
      "7600/7600 [==============================] - 1s 159us/sample - loss: 1.7960 - acc: 0.5997 - categorical_accuracy: 0.5997 - val_loss: 1.8071 - val_acc: 0.5989 - val_categorical_accuracy: 0.5989\n",
      "Epoch 20/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.7605 - acc: 0.6054 - categorical_accuracy: 0.6054 - val_loss: 1.7723 - val_acc: 0.5905 - val_categorical_accuracy: 0.5905\n",
      "Epoch 21/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.7297 - acc: 0.6084 - categorical_accuracy: 0.6084 - val_loss: 1.7409 - val_acc: 0.5974 - val_categorical_accuracy: 0.5974\n",
      "Epoch 22/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.6999 - acc: 0.6099 - categorical_accuracy: 0.6099 - val_loss: 1.7213 - val_acc: 0.5800 - val_categorical_accuracy: 0.5800\n",
      "Epoch 23/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.6677 - acc: 0.6105 - categorical_accuracy: 0.6105 - val_loss: 1.6858 - val_acc: 0.5968 - val_categorical_accuracy: 0.5968\n",
      "Epoch 24/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.6405 - acc: 0.6126 - categorical_accuracy: 0.6126 - val_loss: 1.6609 - val_acc: 0.5932 - val_categorical_accuracy: 0.5932\n",
      "Epoch 25/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.6134 - acc: 0.6162 - categorical_accuracy: 0.6162 - val_loss: 1.6379 - val_acc: 0.6005 - val_categorical_accuracy: 0.6005\n",
      "Epoch 26/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.5891 - acc: 0.6180 - categorical_accuracy: 0.6180 - val_loss: 1.6251 - val_acc: 0.6068 - val_categorical_accuracy: 0.6068\n",
      "Epoch 27/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.5723 - acc: 0.6233 - categorical_accuracy: 0.6233 - val_loss: 1.6015 - val_acc: 0.6184 - val_categorical_accuracy: 0.6184\n",
      "Epoch 28/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.5446 - acc: 0.6250 - categorical_accuracy: 0.6250 - val_loss: 1.5782 - val_acc: 0.6105 - val_categorical_accuracy: 0.6105\n",
      "Epoch 29/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.5217 - acc: 0.6266 - categorical_accuracy: 0.6266 - val_loss: 1.5592 - val_acc: 0.6195 - val_categorical_accuracy: 0.6195\n",
      "Epoch 30/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.4971 - acc: 0.6342 - categorical_accuracy: 0.6342 - val_loss: 1.5413 - val_acc: 0.6274 - val_categorical_accuracy: 0.6274\n",
      "Epoch 31/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.4742 - acc: 0.6409 - categorical_accuracy: 0.6409 - val_loss: 1.5182 - val_acc: 0.6205 - val_categorical_accuracy: 0.6205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.4558 - acc: 0.6420 - categorical_accuracy: 0.6420 - val_loss: 1.5006 - val_acc: 0.6289 - val_categorical_accuracy: 0.6289\n",
      "Epoch 33/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.4325 - acc: 0.6475 - categorical_accuracy: 0.6475 - val_loss: 1.4824 - val_acc: 0.6289 - val_categorical_accuracy: 0.6289\n",
      "Epoch 34/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.4099 - acc: 0.6537 - categorical_accuracy: 0.6537 - val_loss: 1.4651 - val_acc: 0.6326 - val_categorical_accuracy: 0.6326\n",
      "Epoch 35/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.3921 - acc: 0.6625 - categorical_accuracy: 0.6625 - val_loss: 1.4504 - val_acc: 0.6316 - val_categorical_accuracy: 0.6316\n",
      "Epoch 36/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.3738 - acc: 0.6692 - categorical_accuracy: 0.6692 - val_loss: 1.4360 - val_acc: 0.6274 - val_categorical_accuracy: 0.6274\n",
      "Epoch 37/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.3541 - acc: 0.6736 - categorical_accuracy: 0.6736 - val_loss: 1.4252 - val_acc: 0.6379 - val_categorical_accuracy: 0.6379\n",
      "Epoch 38/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.3316 - acc: 0.6799 - categorical_accuracy: 0.6799 - val_loss: 1.4086 - val_acc: 0.6411 - val_categorical_accuracy: 0.6411\n",
      "Epoch 39/55\n",
      "7600/7600 [==============================] - 1s 163us/sample - loss: 1.3183 - acc: 0.6820 - categorical_accuracy: 0.6820 - val_loss: 1.4015 - val_acc: 0.6437 - val_categorical_accuracy: 0.6437\n",
      "Epoch 40/55\n",
      "7600/7600 [==============================] - 1s 163us/sample - loss: 1.2963 - acc: 0.6868 - categorical_accuracy: 0.6868 - val_loss: 1.3884 - val_acc: 0.6368 - val_categorical_accuracy: 0.6368\n",
      "Epoch 41/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.2822 - acc: 0.6909 - categorical_accuracy: 0.6909 - val_loss: 1.3813 - val_acc: 0.6384 - val_categorical_accuracy: 0.6384\n",
      "Epoch 42/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.2653 - acc: 0.6959 - categorical_accuracy: 0.6959 - val_loss: 1.3746 - val_acc: 0.6416 - val_categorical_accuracy: 0.6416\n",
      "Epoch 43/55\n",
      "7600/7600 [==============================] - 1s 159us/sample - loss: 1.2546 - acc: 0.7012 - categorical_accuracy: 0.7012 - val_loss: 1.3667 - val_acc: 0.6395 - val_categorical_accuracy: 0.6395\n",
      "Epoch 44/55\n",
      "7600/7600 [==============================] - 1s 158us/sample - loss: 1.2369 - acc: 0.7017 - categorical_accuracy: 0.7017 - val_loss: 1.3625 - val_acc: 0.6342 - val_categorical_accuracy: 0.6342\n",
      "Epoch 45/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.2243 - acc: 0.7026 - categorical_accuracy: 0.7026 - val_loss: 1.3691 - val_acc: 0.6647 - val_categorical_accuracy: 0.6647\n",
      "Epoch 46/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.2186 - acc: 0.7057 - categorical_accuracy: 0.7057 - val_loss: 1.3585 - val_acc: 0.6468 - val_categorical_accuracy: 0.6468\n",
      "Epoch 47/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.2035 - acc: 0.7138 - categorical_accuracy: 0.7138 - val_loss: 1.3534 - val_acc: 0.6447 - val_categorical_accuracy: 0.6447\n",
      "Epoch 48/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.1869 - acc: 0.7118 - categorical_accuracy: 0.7118 - val_loss: 1.3486 - val_acc: 0.6458 - val_categorical_accuracy: 0.6458\n",
      "Epoch 49/55\n",
      "7600/7600 [==============================] - 1s 161us/sample - loss: 1.1802 - acc: 0.7143 - categorical_accuracy: 0.7143 - val_loss: 1.3541 - val_acc: 0.6589 - val_categorical_accuracy: 0.6589\n",
      "Epoch 50/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.1699 - acc: 0.7232 - categorical_accuracy: 0.7232 - val_loss: 1.3490 - val_acc: 0.6479 - val_categorical_accuracy: 0.6479\n",
      "Epoch 51/55\n",
      "7600/7600 [==============================] - 1s 162us/sample - loss: 1.1541 - acc: 0.7243 - categorical_accuracy: 0.7243 - val_loss: 1.3596 - val_acc: 0.6737 - val_categorical_accuracy: 0.6737\n",
      "Epoch 52/55\n",
      "7600/7600 [==============================] - 1s 163us/sample - loss: 1.1418 - acc: 0.7270 - categorical_accuracy: 0.7270 - val_loss: 1.3487 - val_acc: 0.6468 - val_categorical_accuracy: 0.6468\n",
      "Epoch 53/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.1280 - acc: 0.7307 - categorical_accuracy: 0.7307 - val_loss: 1.3512 - val_acc: 0.6584 - val_categorical_accuracy: 0.6584\n",
      "Epoch 54/55\n",
      "7600/7600 [==============================] - 1s 160us/sample - loss: 1.1124 - acc: 0.7389 - categorical_accuracy: 0.7389 - val_loss: 1.3498 - val_acc: 0.6416 - val_categorical_accuracy: 0.6416\n",
      "Epoch 55/55\n",
      "7600/7600 [==============================] - 1s 163us/sample - loss: 1.1035 - acc: 0.7416 - categorical_accuracy: 0.7416 - val_loss: 1.3594 - val_acc: 0.6584 - val_categorical_accuracy: 0.6584\n",
      "0.5968421052631578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[859, 266,   9,   0],\n",
       "       [115, 302,  63,   0],\n",
       "       [ 15, 104,  90,   0],\n",
       "       [  7,  37,  33,   0]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Try different max number of liked pages per user!!\n",
    "\n",
    "# model category age using embedding for likes\n",
    "\n",
    "max_len = 1000\n",
    "\n",
    "image_features = tf.keras.Input([num_image_features], dtype=tf.float32, name=\"image_features\")\n",
    "text_features  = tf.keras.Input([num_text_features], dtype=tf.float32, name=\"text_features\")\n",
    "likes_features = tf.keras.Input([max_len], dtype=tf.int32, name=\"likes_features\")\n",
    "\n",
    "likes_embedding_block = tf.keras.Sequential(name=\"likes_embedding_block\")\n",
    "likes_embedding_block.add(tf.keras.layers.Embedding(10000, 8, input_length=max_len,\n",
    "                                                    #embeddings_regularizer=tf.keras.regularizers.L1L2(l1=0.0001, l2=0.0001),\n",
    "                                                   mask_zero=True))\n",
    "\n",
    "### GlobalAveragePooling1D averages the embeddings of all pages liked by a user\n",
    "#likes_embedding_block.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "likes_embedding_block.add(tf.keras.layers.Flatten())\n",
    "\n",
    "## Experimenting: Not helping at all... just learning the baseline\n",
    "# Trying to reduce contribution of likes to balance out input modalities\n",
    "#likes_embedding_block.add(tf.keras.layers.Dense(\n",
    "#    units = 128, activation= 'tanh', \n",
    "#    kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg)))\n",
    "## Experimenting\n",
    "\n",
    "condensed_likes = likes_embedding_block(likes_features)\n",
    "\n",
    "dense_layers = tf.keras.Sequential(name=\"dense_layers\")\n",
    "dense_layers.add(tf.keras.layers.Concatenate())\n",
    "for i in range(num_layers):\n",
    "    dense_layers.add(tf.keras.layers.Dense(\n",
    "        units=dense_units,\n",
    "        activation= 'tanh', #'tanh',\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1_reg, l2=l2_reg),      \n",
    "        ))\n",
    "        \n",
    "    dense_layers.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "features = dense_layers([text_features, image_features, condensed_likes])\n",
    "\n",
    "age_group = tf.keras.layers.Dense(units=4, activation=\"softmax\", name=\"age_group\")(features)\n",
    "\n",
    "model_age = tf.keras.Model(\n",
    "    inputs=[text_features, image_features, likes_features],\n",
    "    outputs= age_group\n",
    ")    \n",
    "\n",
    "model_age.compile(\n",
    "    optimizer = tf.keras.optimizers.get({\"class_name\": \"ADAM\", #'ADAM'\n",
    "                               \"config\": {\"learning_rate\": 0.0001}}),    \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc', 'categorical_accuracy']\n",
    ")\n",
    "\n",
    "print(model_age.summary())\n",
    "\n",
    "#x_train_500, x_val_500, y_train_500, y_val_500\n",
    "\n",
    "x_train_txt = x_train_1000.iloc[:, :91].values\n",
    "x_train_img = x_train_1000.iloc[:, 91:156].values\n",
    "x_train_lik = x_train_1000.iloc[:, 156:].values\n",
    "\n",
    "x_val_txt = x_val_1000.iloc[:, :91].values\n",
    "x_val_img = x_val_1000.iloc[:, 91:156].values\n",
    "x_val_lik = x_val_1000.iloc[:, 156:].values\n",
    "\n",
    "y_train_age = tf.keras.utils.to_categorical(y_train_1000['age_group'].values)\n",
    "\n",
    "y_val_age = tf.keras.utils.to_categorical(y_val_1000['age_group'].values)\n",
    "\n",
    "history_age_balanced_mild = model_age.fit([x_train_txt, x_train_img, x_train_lik], y_train_age, \n",
    "                                     shuffle=True, batch_size=64, epochs=55, verbose=1,\n",
    "                                     validation_data=([x_val_txt, x_val_img, x_val_lik], y_val_age),\n",
    "                                     class_weight=age_weights_dict_first3\n",
    "                                    )\n",
    "\n",
    "# validation baseline for age group:\n",
    "print(y_val_1000['age_group'].value_counts()[0]/y_val_1000.shape[0])\n",
    "\n",
    "## Create confusion matrix\n",
    "# 0 = < 25\n",
    "# 1 = 24-35\n",
    "# 2 = 35-50\n",
    "# 3 = 50+\n",
    "\n",
    "y_pred = np.argmax(model_age.predict([x_val_txt, x_val_img, x_val_lik]), axis=1)\n",
    "y_true = np.argmax(y_val_age, axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
