{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import *\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is a slightly modified version of the code from the preprocessing_pipeline.py \n",
    "# script that can stand alone in a notebook\n",
    "\n",
    "# to skip scaling... \n",
    "\n",
    "def get_text_data(input_dir):\n",
    "    \"\"\"\n",
    "    Purpose: preprocess liwc and nrc\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        id_list {numpy array of strings}: array of user ids sorted alphabetically,\n",
    "                                        to determine order of features and labels DataFrames\n",
    "        text_data {pandas DataFrame of float}: unscaled text data (liwc and nrc combined)\n",
    "    \"\"\"\n",
    "    # Load and sort text data\n",
    "    liwc = pd.read_csv(os.path.join(input_dir, 'Text/liwc.csv'), sep = ',')\n",
    "    liwc = liwc.sort_values(by=['userId'])\n",
    "\n",
    "    nrc = pd.read_csv(os.path.join(input_dir, 'Text/nrc.csv'), sep = ',')\n",
    "    nrc = nrc.sort_values(by=['userId'])\n",
    "\n",
    "    # Build list of subject ids ordered alphabetically\n",
    "    # Check if same subject lists in both sorted DataFrames (liwc and nrc)\n",
    "    if np.array_equal(liwc['userId'], nrc['userId']):\n",
    "        id_list = liwc['userId'].to_numpy()\n",
    "    else:\n",
    "        raise Exception('userIds do not match between liwc and nrc data')\n",
    "\n",
    "    # merge liwc and nrc DataFrames using userId as index\n",
    "    liwc.set_index('userId', inplace=True)\n",
    "    nrc.set_index('userId', inplace=True)\n",
    "\n",
    "    text_data = pd.concat([liwc, nrc], axis=1, sort=False)\n",
    "\n",
    "    return id_list, text_data\n",
    "\n",
    "\n",
    "def get_image_clean(sub_ids, oxford, means):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 2)\n",
    "    Input:\n",
    "        sub_ids {numpy array of strings}: ordered list of userIDs\n",
    "        oxford {pandas DataFrame of floats}: unscaled oxford features of users with 1+ face\n",
    "        means {list of float}: mean values for each feature averaged from train set,\n",
    "                    to replace missing values for userids with no face (train and test set)\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "                with mean values replacing missing entries\n",
    "    '''\n",
    "    # list of ids with at least one face on image: 7174 out of 9500 in train set\n",
    "    ox_list = np.sort(oxford['userId'].unique(), axis=None)\n",
    "    # list of ids in text_list who have no face metrics in oxford.csv (2326 in train set)\n",
    "    ox_noface = np.setdiff1d(sub_ids, ox_list)\n",
    "\n",
    "    # Create DataFrame for userids with no face (1 row per userid)\n",
    "    # values are mean metrics averaged from users with entries (training set)\n",
    "    ox_nf = pd.DataFrame(ox_noface, columns = ['userId'])\n",
    "    columns = oxford.columns[2:].tolist()\n",
    "    for column, mean in zip(columns, means):\n",
    "        ox_nf.insert(loc=ox_nf.shape[1], column=column, value=mean, allow_duplicates=True)\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='noface', value=1, allow_duplicates=True)\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    ox_nf.set_index('userId', inplace=True)\n",
    "\n",
    "    # Format DataFrame from userids with 1+ face\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='noface', value=0, allow_duplicates=True)\n",
    "    # list userIds with multiple faces (714 in train set)\n",
    "    ox_multiples = oxford['userId'][oxford['userId'].duplicated()].tolist()\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    multi_mask = pd.Series([uid in ox_multiples for uid in oxford['userId']])\n",
    "    i = oxford[multi_mask].index\n",
    "    oxford.loc[i, 'multiface'] = 1\n",
    "    # drop duplicate entries with same userId (keep first entry per userId)\n",
    "    oxford.drop_duplicates(subset ='userId', keep='first', inplace=True)\n",
    "\n",
    "    # merge the two DataFrames\n",
    "    oxford.drop(['faceID'], axis=1, inplace=True)\n",
    "    oxford.set_index('userId', inplace=True)\n",
    "    image_data = pd.concat([ox_nf, oxford], axis=0, sort=False).sort_values(by=['userId'])\n",
    "\n",
    "    if not np.array_equal(image_data.index, sub_ids):\n",
    "        raise Exception('userIds do not match between oxford file and id list')\n",
    "\n",
    "        ### ADD THE HIGH LEVEL PRE-PROCESSING WHEN DONE (22 NOV)\n",
    "        \n",
    "    return image_data\n",
    "\n",
    "\n",
    "def get_image_raw(data_dir):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 1)\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "    '''\n",
    "    # Load data of oxford features extracted from profile picture (face metrics)\n",
    "    # 7915 entries; some users have no face, some have multiple faces on image.\n",
    "    # userids with 1+ face on image: 7174 out of 9500 (train set)\n",
    "    # duplicated entries (userids with > 1 face on same image): 741 in train set\n",
    "    oxford = pd.read_csv(os.path.join(data_dir, \"Image\", \"oxford.csv\"), sep = ',')\n",
    "    oxford = oxford.sort_values(by=['userId'])\n",
    "    '''\n",
    "    NOTE: headPose_pitch has NO RANGE, drop that feature\n",
    "    '''\n",
    "    oxford.drop(['headPose_pitch'], axis=1, inplace=True)\n",
    "\n",
    "    return oxford\n",
    "\n",
    "\n",
    "def get_likes_kept(data_dir, num_features) -> List[str]:\n",
    "    '''\n",
    "    Purpose: get list of likes to keep as features\n",
    "    Input:\n",
    "        data_dir {str} : the parent input directory\n",
    "        num_features {int} : the number of likes to keep as features,\n",
    "                        starting from those with highest frequencies\n",
    "    Output:\n",
    "        freq_like_id {List of strings}: frequency of most frequent likes,\n",
    "                    (number = num_features), in descending ordered, indexed by like_id\n",
    "    '''\n",
    "    #Why return frequency?\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "    like_ids_to_keep = relation['like_id'].value_counts(sort=True, ascending=False)[:num_features] #This sorts features by frequency\n",
    "\n",
    "    #sort like indices (which are the keys associated with the values kepts)\n",
    "    likes_int64_list = sorted(like_ids_to_keep.keys()) # This sorts indices by like_id\n",
    "    likes_str_list = [str(l) for l in likes_int64_list]\n",
    "    return likes_str_list\n",
    "\n",
    "\n",
    "def get_relations(data_dir: str, sub_ids: List[str], like_ids_to_keep: List[str]):\n",
    "    '''\n",
    "    Purpose: preprocess relations dataset ('likes')\n",
    "\n",
    "    Input:\n",
    "        data_dir {str} -- the parent input directory\n",
    "        sub_ids {numpy array of strings} -- the ordered list of userids\n",
    "        like_ids_to_keep {List[str]} -- The list of page IDs to keep.\n",
    "\n",
    "    Returns:\n",
    "        relations_data -- multihot matrix of the like_id. Rows are indexed with userid, entries are boolean.\n",
    "    '''\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    ## One HUGE step:\n",
    "    # likes_to_keep = like_ids_to_keep.keys()\n",
    "    # kept_relations = relation[relation.like_id.isin(likes_to_keep)]\n",
    "    # multi_hot_relations = pd.get_dummies(kept_relations, columns=[\"like_id\"], prefix=\"\")\n",
    "    # multi_hot = multi_hot_relations.groupby((\"userid\")).sum()\n",
    "    # return multi_hot_relations\n",
    "    ###\n",
    "    total_num_pages = len(like_ids_to_keep)\n",
    "    # Create a multihot likes matrix of booleans (rows = userids, cols = likes), by batch\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Create empty DataFrame with sub_ids as index list\n",
    "    relation_data = pd.DataFrame(sub_ids, columns = ['userid'])\n",
    "    relation_data.set_index('userid', inplace=True)\n",
    "\n",
    "    for start_index in range(0, total_num_pages, batch_size):\n",
    "        end_index = min(start_index + batch_size, total_num_pages)\n",
    "\n",
    "        # sets are better for membership testing than lists.\n",
    "        like_ids_for_this_batch = set(like_ids_to_keep[start_index:end_index])\n",
    "\n",
    "        filtered_table = relation[relation['like_id'].isin(like_ids_for_this_batch)]\n",
    "        ## THIS is the slow part:\n",
    "        relHot = pd.get_dummies(filtered_table, columns=['like_id'], prefix=\"\", prefix_sep=\"\")\n",
    "        ##\n",
    "        relHot = relHot.groupby(['userid']).sum().astype(float) # this makes userid the index\n",
    "\n",
    "        relation_data = pd.concat([relation_data, relHot], axis=1, sort=True)\n",
    "\n",
    "    relation_data = relation_data.reindex(like_ids_to_keep, axis=1)\n",
    "    relation_data.fillna(0.0, inplace=True)\n",
    "    relation_data = relation_data.astype(\"bool\")\n",
    "\n",
    "    # will be different if users in relation.csv are not in sub_ids\n",
    "    if not np.array_equal(relation_data.index, sub_ids):\n",
    "        raise Exception(f\"\"\"userIds do not match between relation file and id list:\n",
    "    {relation_data.index}\n",
    "    {sub_ids}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    return relation_data\n",
    "\n",
    "\n",
    "def make_label_dict(labels):\n",
    "    '''\n",
    "    Purpose: make dictionnary of labels from pandas DataFrame\n",
    "    Input:\n",
    "        labels {pandas DataFrame}: labels ordered per userids (alphabetical order)\n",
    "    Output:\n",
    "        labels_dict {dictionary of pandas DataFrames}: labels (one entry per metric) ordered alphabetically\n",
    "                by userid for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    gender = labels['gender']\n",
    "\n",
    "    age_grps = labels[['age_xx_24', 'age_25_34', 'age_35_49', 'age_50_xx']]\n",
    "\n",
    "    '''\n",
    "    Note: : each DataFrames (value) is indexed by userid in labels_dict\n",
    "    '''\n",
    "    labels_dict = {}\n",
    "    labels_dict['userid'] = labels.index\n",
    "    labels_dict['gender'] = gender\n",
    "    labels_dict['age_grps'] = age_grps\n",
    "    labels_dict['ope'] = labels['ope']\n",
    "    labels_dict['con'] = labels['con']\n",
    "    labels_dict['ext'] = labels['ext']\n",
    "    labels_dict['agr'] = labels['agr']\n",
    "    labels_dict['neu'] = labels['neu']\n",
    "\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def preprocess_labels(data_dir, sub_ids):\n",
    "    '''\n",
    "    Purpose: preprocess entry labels from training set\n",
    "    Input:\n",
    "        datadir {string} : path to training data directory\n",
    "        sub_ids {numpy array of strings}: list of subject ids ordered alphabetically\n",
    "    Output:\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    labels = pd.read_csv(os.path.join(data_dir, \"Profile\", \"Profile.csv\"))\n",
    "    labels = labels.sort_values(by=['userid'])\n",
    "    # check if same subject ids in labels and sub_ids\n",
    "    if not np.array_equal(labels['userid'].to_numpy(), sub_ids):\n",
    "        raise Exception('userIds do not match between profiles labels and id list')\n",
    "\n",
    "    def age_group_id(age_str: str) -> int:\n",
    "        \"\"\"Returns the age group category ID (an integer from 0 to 3) for the given age (string)\n",
    "\n",
    "        Arguments:\n",
    "            age_str {str} -- the age\n",
    "\n",
    "        Returns:\n",
    "            int -- the ID of the age group: 0 for xx-24, 1 for 25-34, 2 for 35-49 and 3 for 50-xx.\n",
    "        \"\"\"\n",
    "        age = int(age_str)\n",
    "        if age <= 24:\n",
    "            return 0\n",
    "        elif age <= 34:\n",
    "            return 1\n",
    "        elif age <= 49:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    labels = labels.assign(age_group = lambda dt: pd.Series([age_group_id(age_str) for age_str in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_xx_24 = lambda dt: pd.Series([int(age) <= 24 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_25_34 = lambda dt: pd.Series([25 <= int(age) <= 34 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_35_49 = lambda dt: pd.Series([35 <= int(age) <= 49 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_50_xx = lambda dt: pd.Series([50 <= int(age) for age in dt[\"age\"]]))\n",
    "\n",
    "    labels = labels.drop(['Unnamed: 0'], axis=1)\n",
    "    labels.set_index('userid', inplace=True)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def preprocess_train(data_dir, num_likes=10_000, scaling=True):\n",
    "    '''\n",
    "    Purpose: preprocesses training dataset (with labels) and returns scaled features,\n",
    "    labels and parameters to scale the test data set\n",
    "    Input\n",
    "        data_dir {string}: path to ~/Train data directory\n",
    "        num_likes {int}: number of like_ids to keep as features\n",
    "        scaling {boolean}: if True, Robust scaling applied to data; no scaling if False                \n",
    "    Output:\n",
    "        train_features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        **(updated:)features_q10_q90 {tupple of 2 pandas Series}: series of 10th and 90th quantile values of\n",
    "                text + image features from train dataset, to be used to scale test data.\n",
    "                Note that the multihot relation features do not necessitate scaling.\n",
    "        image_means {list of float}: means from oxford dataset to replace missing entries in oxford test set\n",
    "        likes_kept {list of strings}: ordered likes_ids to serve as columns for test set relation features matrix\n",
    "        train_labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    TO CONSIDER: convert outputted pandas to tensorflow tf.data.Dataset...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_means = image_data_raw.iloc[:, 2:].mean().tolist()\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    Update: scaling w RobustScaler rather than MinMaxScaler algo, due to outliers\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = features_to_scale.min()\n",
    "    #feat_max = features_to_scale.max()\n",
    "    feat_q10 = features_to_scale.quantile(q = 0.10)\n",
    "    feat_q90 = features_to_scale.quantile(q = 0.90)\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    #features_min_max = (feat_min, feat_max)\n",
    "    if scaling:\n",
    "        feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "    else:\n",
    "        feat_scaled = features_to_scale\n",
    "    features_q10_q90 = (feat_q10, feat_q90)\n",
    "\n",
    "    #if DEBUG:\n",
    "    #    likes_kept = [str(v) for v in range(num_likes)]\n",
    "    #else:\n",
    "    likes_kept = get_likes_kept(data_dir, num_likes)\n",
    "\n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    train_features = pd.concat([feat_scaled, image_data.iloc[:, -2:], likes_data], axis=1, sort=False)\n",
    "\n",
    "    # DataFrame of training set labels\n",
    "    train_labels = preprocess_labels(data_dir, sub_ids)\n",
    "\n",
    "    #return train_features, features_min_max, image_means, likes_kept, train_labels\n",
    "    return train_features, features_q10_q90, image_means, likes_kept, train_labels\n",
    "\n",
    "\n",
    "#def preprocess_test(data_dir, min_max_train, image_means_train, likes_kept_train):\n",
    "def preprocess_test(data_dir, q10_q90_train, image_means_train, likes_kept_train, scaling=True):\n",
    "    '''\n",
    "    Purpose: preprocesses test dataset (no labels)\n",
    "    Input:\n",
    "        datadir {string}: path to Test data directory\n",
    "        (**updated)q10_q90_train {tupple of two numpy arrays}: 10th and 90th quantile values for\n",
    "                concatenated text and image features (from train set)\n",
    "        image_means_train {list of float}: means from oxford training dataset to replace\n",
    "                missing entries in oxford test set\n",
    "        likes_kept_train {list of strings}: most frequent likes_ids from train set\n",
    "                (ordered by frequency) to serve as columns in relation features matrix\n",
    "        scaling {boolean}: if True, Robust scaling applied to data; no scaling if False       \n",
    "    Output:\n",
    "        test_features {pandas DataFrame}: vectorized features of test set\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means_train)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = min_max_train[0]\n",
    "    #feat_max = min_max_train[1]\n",
    "    feat_q10 = q10_q90_train[0]\n",
    "    feat_q90 = q10_q90_train[1]\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    if scaling:\n",
    "        feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "    else:\n",
    "        feat_scaled = features_to_scale\n",
    "    \n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept_train)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    test_features = pd.concat([feat_scaled, image_data.iloc[:, -2:], likes_data], axis=1, sort=False)\n",
    "\n",
    "    return test_features\n",
    "\n",
    "\n",
    "def get_train_val_sets(features, labels, val_prop):\n",
    "    '''\n",
    "    Purpose: Splits training dataset into a train and a validation set of\n",
    "    ratio determined by val_prop (x = features, y = labels)\n",
    "    Input\n",
    "        features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "        val_prop {float between 0 and 1}: proportion of sample in validation set\n",
    "                    (e.g. 0.2 = 20% validation, 80% training)\n",
    "    Output:\n",
    "        x_train, x_val {pandas DataFrames}: vectorized features for train and validation sets\n",
    "        y_train, y_val {pandas DataFrames}: train and validation set labels\n",
    "\n",
    "    TO DO: convert outputted pandas to tensorflow tf.data.Dataset?...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # NOTE: UNUSED\n",
    "    from sklearn import model_selection\n",
    "    x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        features, # training features to split\n",
    "        labels, # training labels to split\n",
    "        test_size = val_prop, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "        shuffle= True,\n",
    "        #stratify = y_data[:1],\n",
    "        # random_state = 42  # can use to always obtain the same train/validation split\n",
    "        )\n",
    "\n",
    "    return x_train, x_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/teaching/user07/.local/lib/python3.7/site-packages/ipykernel_launcher.py:76: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# to preprocess the training dataset:\n",
    "# 1. set path to Train directory\n",
    "# 2. call preprocess_train\n",
    "\n",
    "train_path = '../Train' #modify if working from other directory\n",
    "\n",
    "train_features, features_q10_q90, image_means, likes_kept, train_labels = preprocess_train(train_path, num_likes=10_000, scaling=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    train_features, # training features to split\n",
    "    train_labels, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels['gender']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Numerals</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>...</th>\n",
       "      <th>10150131036435262</th>\n",
       "      <th>10150136203045543</th>\n",
       "      <th>10150138573815473</th>\n",
       "      <th>10150145087245298</th>\n",
       "      <th>10150145163490188</th>\n",
       "      <th>10150145214185538</th>\n",
       "      <th>10150147152190368</th>\n",
       "      <th>10150154095435553</th>\n",
       "      <th>10150157058260374</th>\n",
       "      <th>10150169313485249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0da7b1011ddc89416d6ac7ebbd4786be</td>\n",
       "      <td>100</td>\n",
       "      <td>4.76</td>\n",
       "      <td>19.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4532d4a5d06a6a5c75c9605af694598</td>\n",
       "      <td>182</td>\n",
       "      <td>11.38</td>\n",
       "      <td>13.19</td>\n",
       "      <td>81.87</td>\n",
       "      <td>3.30</td>\n",
       "      <td>51.65</td>\n",
       "      <td>13.74</td>\n",
       "      <td>9.89</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92b488e28cb1ea9f74bebefeaa152b9c</td>\n",
       "      <td>169</td>\n",
       "      <td>15.36</td>\n",
       "      <td>19.53</td>\n",
       "      <td>79.88</td>\n",
       "      <td>1.78</td>\n",
       "      <td>46.15</td>\n",
       "      <td>17.16</td>\n",
       "      <td>10.65</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6689d6569984c1d130057441fb4fde1c</td>\n",
       "      <td>175</td>\n",
       "      <td>87.50</td>\n",
       "      <td>20.57</td>\n",
       "      <td>84.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.29</td>\n",
       "      <td>20.00</td>\n",
       "      <td>16.57</td>\n",
       "      <td>10.86</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01c41fb8d8a33e01d69c23887327aaf7</td>\n",
       "      <td>190</td>\n",
       "      <td>11.88</td>\n",
       "      <td>16.32</td>\n",
       "      <td>87.37</td>\n",
       "      <td>1.05</td>\n",
       "      <td>55.26</td>\n",
       "      <td>11.05</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.21</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   WC    WPS  Sixltr    Dic  Numerals  funct  \\\n",
       "userId                                                                         \n",
       "0da7b1011ddc89416d6ac7ebbd4786be  100   4.76   19.00  64.00      0.00  35.00   \n",
       "f4532d4a5d06a6a5c75c9605af694598  182  11.38   13.19  81.87      3.30  51.65   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c  169  15.36   19.53  79.88      1.78  46.15   \n",
       "6689d6569984c1d130057441fb4fde1c  175  87.50   20.57  84.57      0.00  54.29   \n",
       "01c41fb8d8a33e01d69c23887327aaf7  190  11.88   16.32  87.37      1.05  55.26   \n",
       "\n",
       "                                  pronoun  ppron      i    we  ...  \\\n",
       "userId                                                         ...   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be    12.00   7.00   4.00  2.00  ...   \n",
       "f4532d4a5d06a6a5c75c9605af694598    13.74   9.89   7.14  0.55  ...   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c    17.16  10.65   6.51  0.00  ...   \n",
       "6689d6569984c1d130057441fb4fde1c    20.00  16.57  10.86  0.57  ...   \n",
       "01c41fb8d8a33e01d69c23887327aaf7    11.05   6.84   4.21  1.58  ...   \n",
       "\n",
       "                                  10150131036435262  10150136203045543  \\\n",
       "userId                                                                   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be              False              False   \n",
       "f4532d4a5d06a6a5c75c9605af694598              False              False   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c              False              False   \n",
       "6689d6569984c1d130057441fb4fde1c              False              False   \n",
       "01c41fb8d8a33e01d69c23887327aaf7              False              False   \n",
       "\n",
       "                                  10150138573815473  10150145087245298  \\\n",
       "userId                                                                   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be              False              False   \n",
       "f4532d4a5d06a6a5c75c9605af694598              False              False   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c              False              False   \n",
       "6689d6569984c1d130057441fb4fde1c              False              False   \n",
       "01c41fb8d8a33e01d69c23887327aaf7              False              False   \n",
       "\n",
       "                                  10150145163490188  10150145214185538  \\\n",
       "userId                                                                   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be              False              False   \n",
       "f4532d4a5d06a6a5c75c9605af694598              False              False   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c              False              False   \n",
       "6689d6569984c1d130057441fb4fde1c              False              False   \n",
       "01c41fb8d8a33e01d69c23887327aaf7              False              False   \n",
       "\n",
       "                                  10150147152190368  10150154095435553  \\\n",
       "userId                                                                   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be              False              False   \n",
       "f4532d4a5d06a6a5c75c9605af694598              False              False   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c              False              False   \n",
       "6689d6569984c1d130057441fb4fde1c              False              False   \n",
       "01c41fb8d8a33e01d69c23887327aaf7              False              False   \n",
       "\n",
       "                                  10150157058260374  10150169313485249  \n",
       "userId                                                                  \n",
       "0da7b1011ddc89416d6ac7ebbd4786be              False              False  \n",
       "f4532d4a5d06a6a5c75c9605af694598              False              False  \n",
       "92b488e28cb1ea9f74bebefeaa152b9c              False              False  \n",
       "6689d6569984c1d130057441fb4fde1c              False              False  \n",
       "01c41fb8d8a33e01d69c23887327aaf7              False              False  \n",
       "\n",
       "[5 rows x 10156 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()\n",
    "############################ END OF OLD PREPROCESSING EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[91:156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_IMAGES=\"/home/mila/teaching/user07/Train/Image/oxford.csv\"\n",
    "# oxford = pd.read_csv(PATH_IMAGES)\n",
    "# oxford = oxford.rename(columns={\"userId\":\"userid\"})\n",
    "# oxford.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford_train = x_train.iloc[:,91:156]\n",
    "oxford_val = x_val.iloc[:,91:156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface',\n",
       "       'eyebrow_length', 'vert_eye', 'hori_eye', 'width_nose_root',\n",
       "       'nose_root_to_tip', 'width_nose', 'length_mouth', 'bottomEye_to_mouth',\n",
       "       'width_lips'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eyebrowRightOuter_x</th>\n",
       "      <th>eyebrowRightInner_x</th>\n",
       "      <th>eyebrowRightOuter_y</th>\n",
       "      <th>eyebrowRightInner_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0da7b1011ddc89416d6ac7ebbd4786be</td>\n",
       "      <td>78.60000</td>\n",
       "      <td>63.200000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4532d4a5d06a6a5c75c9605af694598</td>\n",
       "      <td>138.20000</td>\n",
       "      <td>111.700000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>48.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92b488e28cb1ea9f74bebefeaa152b9c</td>\n",
       "      <td>149.50000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>88.400000</td>\n",
       "      <td>85.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6689d6569984c1d130057441fb4fde1c</td>\n",
       "      <td>172.60000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>59.400000</td>\n",
       "      <td>59.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01c41fb8d8a33e01d69c23887327aaf7</td>\n",
       "      <td>137.20000</td>\n",
       "      <td>113.600000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>93.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4f1cfb30a2b832daafe8c877f5e17986</td>\n",
       "      <td>77.80000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>58.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71056931276dd72a5959b950ee5a4171</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48ec4381852aa7399ceee39bf1034284</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b2be41464b53ffc6deae9536ddfd3aee</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5f496b4d5f8ef072a354893a3ddd77ca</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  eyebrowRightOuter_x  eyebrowRightInner_x  \\\n",
       "userId                                                                       \n",
       "0da7b1011ddc89416d6ac7ebbd4786be             78.60000            63.200000   \n",
       "f4532d4a5d06a6a5c75c9605af694598            138.20000           111.700000   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c            149.50000           123.500000   \n",
       "6689d6569984c1d130057441fb4fde1c            172.60000           153.000000   \n",
       "01c41fb8d8a33e01d69c23887327aaf7            137.20000           113.600000   \n",
       "...                                               ...                  ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986             77.80000            54.100000   \n",
       "71056931276dd72a5959b950ee5a4171            120.00000           107.000000   \n",
       "48ec4381852aa7399ceee39bf1034284            129.31957           106.935944   \n",
       "b2be41464b53ffc6deae9536ddfd3aee            129.31957           106.935944   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca            129.31957           106.935944   \n",
       "\n",
       "                                  eyebrowRightOuter_y  eyebrowRightInner_y  \n",
       "userId                                                                      \n",
       "0da7b1011ddc89416d6ac7ebbd4786be            24.200000            23.900000  \n",
       "f4532d4a5d06a6a5c75c9605af694598            59.000000            48.400000  \n",
       "92b488e28cb1ea9f74bebefeaa152b9c            88.400000            85.900000  \n",
       "6689d6569984c1d130057441fb4fde1c            59.400000            59.400000  \n",
       "01c41fb8d8a33e01d69c23887327aaf7            93.200000            93.900000  \n",
       "...                                               ...                  ...  \n",
       "4f1cfb30a2b832daafe8c877f5e17986            51.600000            58.100000  \n",
       "71056931276dd72a5959b950ee5a4171            60.600000            59.000000  \n",
       "48ec4381852aa7399ceee39bf1034284            67.210385            66.812129  \n",
       "b2be41464b53ffc6deae9536ddfd3aee            67.210385            66.812129  \n",
       "5f496b4d5f8ef072a354893a3ddd77ca            67.210385            66.812129  \n",
       "\n",
       "[7600 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train[['eyebrowRightOuter_x','eyebrowRightInner_x', 'eyebrowRightOuter_y','eyebrowRightInner_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,y1,x2,y2):\n",
    "    return np.sqrt(np.square(x1-x2)+np.square(y1-y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Engineering interesting features for:\n",
    "-gender\n",
    "\n",
    "-age group\n",
    "\n",
    "Assumption: Oxford features not useful for personality...\n",
    "\n",
    "Scaling = divide by face rectangle width/height the new feature\n",
    "\n",
    "New features:\n",
    "o eyebrow length AVG X\n",
    "o width nose root X\n",
    "o length nose root to tip X should be good...\n",
    "o width altar AVG X tip - top\n",
    "o width lips = width upper + width bottom X\n",
    "o width nose = altar to altar X\n",
    "o vert eye AVG X\n",
    "o hori eye AVG X\n",
    "o transversal length center of eye to nose tip! (normalize transversal) NO\n",
    "o length mouth X\n",
    "o bottomEye_to_mouth X avg\n",
    "\n",
    "Pandas tips:\n",
    "df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32) to assign a new column with result of operation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "oxford_train = oxford_train.assign(eyebrow_length=lambda x: (distance(x.eyebrowRightInner_x, x.eyebrowRightInner_y,\n",
    "                                                                        x.eyebrowRightOuter_x,x.eyebrowRightOuter_y)\n",
    "                                                             + distance(x.eyebrowLeftInner_x, x.eyebrowLeftInner_y,\n",
    "                                                                        x.eyebrowLeftOuter_x,x.eyebrowLeftOuter_y)\n",
    "                                                            )/2/x.faceRectangle_width\n",
    "                                  )\n",
    "\n",
    "oxford_train = oxford_train.assign(vert_eye=lambda x: (distance(x.eyeRightInner_x, x.eyeRightInner_y,\n",
    "                                                                        x.eyeRightOuter_x,x.eyeRightOuter_y)\n",
    "                                                             + distance(x.eyeLeftInner_x, x.eyeLeftInner_y,\n",
    "                                                                        x.eyeLeftOuter_x,x.eyeLeftOuter_y)\n",
    "                                                            )/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(hori_eye=lambda x: (distance(x.eyeRightTop_x, x.eyeRightTop_y,\n",
    "                                                                        x.eyeRightBottom_x,x.eyeRightBottom_y)\n",
    "                                                             + distance(x.eyeLeftTop_x, x.eyeLeftTop_y,\n",
    "                                                                        x.eyeLeftBottom_x,x.eyeLeftBottom_y)\n",
    "                                                            )/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(width_nose_root=lambda x: distance(x.noseRootLeft_x,x.noseRootLeft_y,\n",
    "                                                                     x.noseRootRight_x,x.noseRootRight_y)/x.faceRectangle_width )\n",
    "\n",
    "oxford_train = oxford_train.assign(nose_root_to_tip=lambda x: distance(np.abs(x.noseRootLeft_x-x.noseRootRight_x)/2,np.abs(x.noseRootLeft_y-x.noseRootRight_y)/2,\n",
    "                                                                     x.noseTip_x,x.noseTip_y)/x.faceRectangle_width )\n",
    "\n",
    "oxford_train = oxford_train.assign(width_nose=lambda x: distance(x.noseRightAlarOutTip_x, x.noseRightAlarOutTip_y,\n",
    "                                                                        x.noseLeftAlarOutTip_x,x.noseLeftAlarOutTip_y)/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(length_mouth=lambda x: distance( x.mouthRight_x, x.mouthRight_y, x.mouthLeft_x, x.mouthLeft_y)/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(bottomEye_to_mouth=lambda x: (distance( x.mouthRight_x, x.mouthRight_y, x.eyeRightBottom_x, x.eyeRightBottom_y)\n",
    "                                                                 +distance( x.mouthLeft_x, x.mouthLeft_y, x.eyeLeftBottom_x, x.eyeLeftBottom_y))/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(width_lips=lambda x: (distance( x.upperLipTop_x, x.upperLipTop_y, x.upperLipBottom_x, x.upperLipBottom_y)+\n",
    "                                  distance( x.underLipTop_x, x.underLipTop_y, x.underLipBottom_x, x.underLipBottom_y))/x.faceRectangle_width)\n",
    "\n",
    "#oxford_train = oxford_train.assign(pupil_to_nose_tip=lambda x: distance( pupilRight_x, pupilRight_y, upperLipBottom_x, upperLipBottom_y)+\n",
    "#                                  distance( underLipTop_x, underLipTop_y, underLipBottom_x, underLipBottom_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faceRectangle_width</th>\n",
       "      <th>faceRectangle_height</th>\n",
       "      <th>faceRectangle_left</th>\n",
       "      <th>faceRectangle_top</th>\n",
       "      <th>pupilLeft_x</th>\n",
       "      <th>pupilLeft_y</th>\n",
       "      <th>pupilRight_x</th>\n",
       "      <th>pupilRight_y</th>\n",
       "      <th>noseTip_x</th>\n",
       "      <th>noseTip_y</th>\n",
       "      <th>...</th>\n",
       "      <th>multiface</th>\n",
       "      <th>eyebrow_length</th>\n",
       "      <th>vert_eye</th>\n",
       "      <th>hori_eye</th>\n",
       "      <th>width_nose_root</th>\n",
       "      <th>nose_root_to_tip</th>\n",
       "      <th>width_nose</th>\n",
       "      <th>length_mouth</th>\n",
       "      <th>bottomEye_to_mouth</th>\n",
       "      <th>width_lips</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0da7b1011ddc89416d6ac7ebbd4786be</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>71.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>58.8</td>\n",
       "      <td>37.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346420</td>\n",
       "      <td>0.129501</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.125925</td>\n",
       "      <td>1.562855</td>\n",
       "      <td>0.318639</td>\n",
       "      <td>0.495545</td>\n",
       "      <td>0.400481</td>\n",
       "      <td>0.072347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4532d4a5d06a6a5c75c9605af694598</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>122.7</td>\n",
       "      <td>66.6</td>\n",
       "      <td>88.3</td>\n",
       "      <td>77.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263808</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.065284</td>\n",
       "      <td>0.126044</td>\n",
       "      <td>1.302427</td>\n",
       "      <td>0.312663</td>\n",
       "      <td>0.396313</td>\n",
       "      <td>0.421080</td>\n",
       "      <td>0.084717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92b488e28cb1ea9f74bebefeaa152b9c</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>93.4</td>\n",
       "      <td>100.9</td>\n",
       "      <td>136.3</td>\n",
       "      <td>97.5</td>\n",
       "      <td>116.3</td>\n",
       "      <td>122.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305133</td>\n",
       "      <td>0.152062</td>\n",
       "      <td>0.057525</td>\n",
       "      <td>0.128429</td>\n",
       "      <td>1.872479</td>\n",
       "      <td>0.321036</td>\n",
       "      <td>0.523562</td>\n",
       "      <td>0.361221</td>\n",
       "      <td>0.114977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6689d6569984c1d130057441fb4fde1c</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>142.3</td>\n",
       "      <td>69.3</td>\n",
       "      <td>163.4</td>\n",
       "      <td>67.2</td>\n",
       "      <td>140.6</td>\n",
       "      <td>81.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249099</td>\n",
       "      <td>0.116041</td>\n",
       "      <td>0.047728</td>\n",
       "      <td>0.137087</td>\n",
       "      <td>2.952325</td>\n",
       "      <td>0.350078</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.477167</td>\n",
       "      <td>0.101014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01c41fb8d8a33e01d69c23887327aaf7</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.3</td>\n",
       "      <td>101.1</td>\n",
       "      <td>125.5</td>\n",
       "      <td>100.9</td>\n",
       "      <td>108.4</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347459</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>2.342329</td>\n",
       "      <td>0.341794</td>\n",
       "      <td>0.470341</td>\n",
       "      <td>0.432254</td>\n",
       "      <td>0.081635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  faceRectangle_width  faceRectangle_height  \\\n",
       "userId                                                                        \n",
       "0da7b1011ddc89416d6ac7ebbd4786be                 43.0                  43.0   \n",
       "f4532d4a5d06a6a5c75c9605af694598                 87.0                  87.0   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c                 88.0                  88.0   \n",
       "6689d6569984c1d130057441fb4fde1c                 54.0                  54.0   \n",
       "01c41fb8d8a33e01d69c23887327aaf7                 67.0                  67.0   \n",
       "\n",
       "                                  faceRectangle_left  faceRectangle_top  \\\n",
       "userId                                                                    \n",
       "0da7b1011ddc89416d6ac7ebbd4786be                39.0               15.0   \n",
       "f4532d4a5d06a6a5c75c9605af694598                53.0               38.0   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c                72.0               73.0   \n",
       "6689d6569984c1d130057441fb4fde1c               125.0               54.0   \n",
       "01c41fb8d8a33e01d69c23887327aaf7                76.0               82.0   \n",
       "\n",
       "                                  pupilLeft_x  pupilLeft_y  pupilRight_x  \\\n",
       "userId                                                                     \n",
       "0da7b1011ddc89416d6ac7ebbd4786be         51.7         28.8          71.6   \n",
       "f4532d4a5d06a6a5c75c9605af694598         82.5         62.0         122.7   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c         93.4        100.9         136.3   \n",
       "6689d6569984c1d130057441fb4fde1c        142.3         69.3         163.4   \n",
       "01c41fb8d8a33e01d69c23887327aaf7         96.3        101.1         125.5   \n",
       "\n",
       "                                  pupilRight_y  noseTip_x  noseTip_y  ...  \\\n",
       "userId                                                                ...   \n",
       "0da7b1011ddc89416d6ac7ebbd4786be          27.4       58.8       37.2  ...   \n",
       "f4532d4a5d06a6a5c75c9605af694598          66.6       88.3       77.9  ...   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c          97.5      116.3      122.2  ...   \n",
       "6689d6569984c1d130057441fb4fde1c          67.2      140.6       81.8  ...   \n",
       "01c41fb8d8a33e01d69c23887327aaf7         100.9      108.4      117.0  ...   \n",
       "\n",
       "                                  multiface  eyebrow_length  vert_eye  \\\n",
       "userId                                                                  \n",
       "0da7b1011ddc89416d6ac7ebbd4786be          0        0.346420  0.129501   \n",
       "f4532d4a5d06a6a5c75c9605af694598          0        0.263808  0.159180   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c          0        0.305133  0.152062   \n",
       "6689d6569984c1d130057441fb4fde1c          1        0.249099  0.116041   \n",
       "01c41fb8d8a33e01d69c23887327aaf7          0        0.347459  0.130399   \n",
       "\n",
       "                                  hori_eye  width_nose_root  nose_root_to_tip  \\\n",
       "userId                                                                          \n",
       "0da7b1011ddc89416d6ac7ebbd4786be  0.040370         0.125925          1.562855   \n",
       "f4532d4a5d06a6a5c75c9605af694598  0.065284         0.126044          1.302427   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c  0.057525         0.128429          1.872479   \n",
       "6689d6569984c1d130057441fb4fde1c  0.047728         0.137087          2.952325   \n",
       "01c41fb8d8a33e01d69c23887327aaf7  0.031573         0.111950          2.342329   \n",
       "\n",
       "                                  width_nose  length_mouth  \\\n",
       "userId                                                       \n",
       "0da7b1011ddc89416d6ac7ebbd4786be    0.318639      0.495545   \n",
       "f4532d4a5d06a6a5c75c9605af694598    0.312663      0.396313   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c    0.321036      0.523562   \n",
       "6689d6569984c1d130057441fb4fde1c    0.350078      0.393121   \n",
       "01c41fb8d8a33e01d69c23887327aaf7    0.341794      0.470341   \n",
       "\n",
       "                                  bottomEye_to_mouth  width_lips  \n",
       "userId                                                            \n",
       "0da7b1011ddc89416d6ac7ebbd4786be            0.400481    0.072347  \n",
       "f4532d4a5d06a6a5c75c9605af694598            0.421080    0.084717  \n",
       "92b488e28cb1ea9f74bebefeaa152b9c            0.361221    0.114977  \n",
       "6689d6569984c1d130057441fb4fde1c            0.477167    0.101014  \n",
       "01c41fb8d8a33e01d69c23887327aaf7            0.432254    0.081635  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface',\n",
       "       'eyebrow_length', 'vert_eye', 'hori_eye', 'width_nose_root',\n",
       "       'nose_root_to_tip', 'width_nose', 'length_mouth', 'bottomEye_to_mouth',\n",
       "       'width_lips'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep the good columns\n",
    "\"\"\"\n",
    "oxford_train_modified = oxford_train[['faceRectangle_width', 'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns', 'eyebrow_length', 'vert_eye', 'hori_eye', 'width_nose_root',\n",
    "       'nose_root_to_tip', 'width_nose', 'length_mouth', 'bottomEye_to_mouth',\n",
    "       'width_lips','headPose_yaw', 'noface', 'multiface']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faceRectangle_width</th>\n",
       "      <th>facialHair_mustache</th>\n",
       "      <th>facialHair_beard</th>\n",
       "      <th>facialHair_sideburns</th>\n",
       "      <th>eyebrow_length</th>\n",
       "      <th>vert_eye</th>\n",
       "      <th>hori_eye</th>\n",
       "      <th>width_nose_root</th>\n",
       "      <th>nose_root_to_tip</th>\n",
       "      <th>width_nose</th>\n",
       "      <th>length_mouth</th>\n",
       "      <th>bottomEye_to_mouth</th>\n",
       "      <th>width_lips</th>\n",
       "      <th>headPose_yaw</th>\n",
       "      <th>noface</th>\n",
       "      <th>multiface</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0da7b1011ddc89416d6ac7ebbd4786be</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.346420</td>\n",
       "      <td>0.129501</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.125925</td>\n",
       "      <td>1.562855</td>\n",
       "      <td>0.318639</td>\n",
       "      <td>0.495545</td>\n",
       "      <td>0.400481</td>\n",
       "      <td>0.072347</td>\n",
       "      <td>-9.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4532d4a5d06a6a5c75c9605af694598</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263808</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.065284</td>\n",
       "      <td>0.126044</td>\n",
       "      <td>1.302427</td>\n",
       "      <td>0.312663</td>\n",
       "      <td>0.396313</td>\n",
       "      <td>0.421080</td>\n",
       "      <td>0.084717</td>\n",
       "      <td>-24.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92b488e28cb1ea9f74bebefeaa152b9c</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.305133</td>\n",
       "      <td>0.152062</td>\n",
       "      <td>0.057525</td>\n",
       "      <td>0.128429</td>\n",
       "      <td>1.872479</td>\n",
       "      <td>0.321036</td>\n",
       "      <td>0.523562</td>\n",
       "      <td>0.361221</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6689d6569984c1d130057441fb4fde1c</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249099</td>\n",
       "      <td>0.116041</td>\n",
       "      <td>0.047728</td>\n",
       "      <td>0.137087</td>\n",
       "      <td>2.952325</td>\n",
       "      <td>0.350078</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.477167</td>\n",
       "      <td>0.101014</td>\n",
       "      <td>-41.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>01c41fb8d8a33e01d69c23887327aaf7</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.347459</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>2.342329</td>\n",
       "      <td>0.341794</td>\n",
       "      <td>0.470341</td>\n",
       "      <td>0.432254</td>\n",
       "      <td>0.081635</td>\n",
       "      <td>-3.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4f1cfb30a2b832daafe8c877f5e17986</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289979</td>\n",
       "      <td>0.151415</td>\n",
       "      <td>0.056390</td>\n",
       "      <td>0.119528</td>\n",
       "      <td>1.400435</td>\n",
       "      <td>0.312044</td>\n",
       "      <td>0.342934</td>\n",
       "      <td>0.477350</td>\n",
       "      <td>0.107828</td>\n",
       "      <td>-27.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71056931276dd72a5959b950ee5a4171</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323438</td>\n",
       "      <td>0.135366</td>\n",
       "      <td>0.058974</td>\n",
       "      <td>0.162788</td>\n",
       "      <td>3.026947</td>\n",
       "      <td>0.306961</td>\n",
       "      <td>0.432796</td>\n",
       "      <td>0.420524</td>\n",
       "      <td>0.071041</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48ec4381852aa7399ceee39bf1034284</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b2be41464b53ffc6deae9536ddfd3aee</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5f496b4d5f8ef072a354893a3ddd77ca</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  faceRectangle_width  facialHair_mustache  \\\n",
       "userId                                                                       \n",
       "0da7b1011ddc89416d6ac7ebbd4786be            43.000000               0.5000   \n",
       "f4532d4a5d06a6a5c75c9605af694598            87.000000               0.0000   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c            88.000000               0.1000   \n",
       "6689d6569984c1d130057441fb4fde1c            54.000000               0.0000   \n",
       "01c41fb8d8a33e01d69c23887327aaf7            67.000000               0.4000   \n",
       "...                                               ...                  ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986            71.000000               0.0000   \n",
       "71056931276dd72a5959b950ee5a4171            40.000000               0.0000   \n",
       "48ec4381852aa7399ceee39bf1034284            78.358307               0.0941   \n",
       "b2be41464b53ffc6deae9536ddfd3aee            78.358307               0.0941   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca            78.358307               0.0941   \n",
       "\n",
       "                                  facialHair_beard  facialHair_sideburns  \\\n",
       "userId                                                                     \n",
       "0da7b1011ddc89416d6ac7ebbd4786be          0.400000              0.400000   \n",
       "f4532d4a5d06a6a5c75c9605af694598          0.000000              0.000000   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c          0.300000              0.100000   \n",
       "6689d6569984c1d130057441fb4fde1c          0.200000              0.000000   \n",
       "01c41fb8d8a33e01d69c23887327aaf7          0.400000              0.200000   \n",
       "...                                            ...                   ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986          0.000000              0.000000   \n",
       "71056931276dd72a5959b950ee5a4171          0.000000              0.000000   \n",
       "48ec4381852aa7399ceee39bf1034284          0.107732              0.080884   \n",
       "b2be41464b53ffc6deae9536ddfd3aee          0.107732              0.080884   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca          0.107732              0.080884   \n",
       "\n",
       "                                  eyebrow_length  vert_eye  hori_eye  \\\n",
       "userId                                                                 \n",
       "0da7b1011ddc89416d6ac7ebbd4786be        0.346420  0.129501  0.040370   \n",
       "f4532d4a5d06a6a5c75c9605af694598        0.263808  0.159180  0.065284   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c        0.305133  0.152062  0.057525   \n",
       "6689d6569984c1d130057441fb4fde1c        0.249099  0.116041  0.047728   \n",
       "01c41fb8d8a33e01d69c23887327aaf7        0.347459  0.130399  0.031573   \n",
       "...                                          ...       ...       ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986        0.289979  0.151415  0.056390   \n",
       "71056931276dd72a5959b950ee5a4171        0.323438  0.135366  0.058974   \n",
       "48ec4381852aa7399ceee39bf1034284        0.286042  0.144742  0.060173   \n",
       "b2be41464b53ffc6deae9536ddfd3aee        0.286042  0.144742  0.060173   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca        0.286042  0.144742  0.060173   \n",
       "\n",
       "                                  width_nose_root  nose_root_to_tip  \\\n",
       "userId                                                                \n",
       "0da7b1011ddc89416d6ac7ebbd4786be         0.125925          1.562855   \n",
       "f4532d4a5d06a6a5c75c9605af694598         0.126044          1.302427   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c         0.128429          1.872479   \n",
       "6689d6569984c1d130057441fb4fde1c         0.137087          2.952325   \n",
       "01c41fb8d8a33e01d69c23887327aaf7         0.111950          2.342329   \n",
       "...                                           ...               ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986         0.119528          1.400435   \n",
       "71056931276dd72a5959b950ee5a4171         0.162788          3.026947   \n",
       "48ec4381852aa7399ceee39bf1034284         0.125329          1.712697   \n",
       "b2be41464b53ffc6deae9536ddfd3aee         0.125329          1.712697   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca         0.125329          1.712697   \n",
       "\n",
       "                                  width_nose  length_mouth  \\\n",
       "userId                                                       \n",
       "0da7b1011ddc89416d6ac7ebbd4786be    0.318639      0.495545   \n",
       "f4532d4a5d06a6a5c75c9605af694598    0.312663      0.396313   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c    0.321036      0.523562   \n",
       "6689d6569984c1d130057441fb4fde1c    0.350078      0.393121   \n",
       "01c41fb8d8a33e01d69c23887327aaf7    0.341794      0.470341   \n",
       "...                                      ...           ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986    0.312044      0.342934   \n",
       "71056931276dd72a5959b950ee5a4171    0.306961      0.432796   \n",
       "48ec4381852aa7399ceee39bf1034284    0.287348      0.406576   \n",
       "b2be41464b53ffc6deae9536ddfd3aee    0.287348      0.406576   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca    0.287348      0.406576   \n",
       "\n",
       "                                  bottomEye_to_mouth  width_lips  \\\n",
       "userId                                                             \n",
       "0da7b1011ddc89416d6ac7ebbd4786be            0.400481    0.072347   \n",
       "f4532d4a5d06a6a5c75c9605af694598            0.421080    0.084717   \n",
       "92b488e28cb1ea9f74bebefeaa152b9c            0.361221    0.114977   \n",
       "6689d6569984c1d130057441fb4fde1c            0.477167    0.101014   \n",
       "01c41fb8d8a33e01d69c23887327aaf7            0.432254    0.081635   \n",
       "...                                              ...         ...   \n",
       "4f1cfb30a2b832daafe8c877f5e17986            0.477350    0.107828   \n",
       "71056931276dd72a5959b950ee5a4171            0.420524    0.071041   \n",
       "48ec4381852aa7399ceee39bf1034284            0.422805    0.097812   \n",
       "b2be41464b53ffc6deae9536ddfd3aee            0.422805    0.097812   \n",
       "5f496b4d5f8ef072a354893a3ddd77ca            0.422805    0.097812   \n",
       "\n",
       "                                  headPose_yaw  noface  multiface  \n",
       "userId                                                             \n",
       "0da7b1011ddc89416d6ac7ebbd4786be     -9.400000       0          0  \n",
       "f4532d4a5d06a6a5c75c9605af694598    -24.100000       0          0  \n",
       "92b488e28cb1ea9f74bebefeaa152b9c     -0.200000       0          0  \n",
       "6689d6569984c1d130057441fb4fde1c    -41.100000       0          1  \n",
       "01c41fb8d8a33e01d69c23887327aaf7     -3.600000       0          0  \n",
       "...                                        ...     ...        ...  \n",
       "4f1cfb30a2b832daafe8c877f5e17986    -27.700000       0          0  \n",
       "71056931276dd72a5959b950ee5a4171     -4.200000       0          0  \n",
       "48ec4381852aa7399ceee39bf1034284     -0.536096       1          0  \n",
       "b2be41464b53ffc6deae9536ddfd3aee     -0.536096       1          0  \n",
       "5f496b4d5f8ef072a354893a3ddd77ca     -0.536096       1          0  \n",
       "\n",
       "[7600 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it got all the columns right\n",
    "oxford_train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'facialHair_mustache', 'facialHair_beard',\n",
       "       'facialHair_sideburns', 'eyebrow_length', 'vert_eye', 'hori_eye',\n",
       "       'width_nose_root', 'nose_root_to_tip', 'width_nose', 'length_mouth',\n",
       "       'bottomEye_to_mouth', 'width_lips', 'headPose_yaw', 'noface',\n",
       "       'multiface'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train_modified.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oxford_train_modified.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
