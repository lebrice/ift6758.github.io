{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import *\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is a slightly modified version of the code from the preprocessing_pipeline.py \n",
    "# script that can stand alone in a notebook\n",
    "\n",
    "# to skip scaling... \n",
    "\n",
    "def get_text_data(input_dir):\n",
    "    \"\"\"\n",
    "    Purpose: preprocess liwc and nrc\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        id_list {numpy array of strings}: array of user ids sorted alphabetically,\n",
    "                                        to determine order of features and labels DataFrames\n",
    "        text_data {pandas DataFrame of float}: unscaled text data (liwc and nrc combined)\n",
    "    \"\"\"\n",
    "    # Load and sort text data\n",
    "    liwc = pd.read_csv(os.path.join(input_dir, 'Text/liwc.csv'), sep = ',')\n",
    "    liwc = liwc.sort_values(by=['userId'])\n",
    "\n",
    "    nrc = pd.read_csv(os.path.join(input_dir, 'Text/nrc.csv'), sep = ',')\n",
    "    nrc = nrc.sort_values(by=['userId'])\n",
    "\n",
    "    # Build list of subject ids ordered alphabetically\n",
    "    # Check if same subject lists in both sorted DataFrames (liwc and nrc)\n",
    "    if np.array_equal(liwc['userId'], nrc['userId']):\n",
    "        id_list = liwc['userId'].to_numpy()\n",
    "    else:\n",
    "        raise Exception('userIds do not match between liwc and nrc data')\n",
    "\n",
    "    # merge liwc and nrc DataFrames using userId as index\n",
    "    liwc.set_index('userId', inplace=True)\n",
    "    nrc.set_index('userId', inplace=True)\n",
    "\n",
    "    text_data = pd.concat([liwc, nrc], axis=1, sort=False)\n",
    "\n",
    "    return id_list, text_data\n",
    "\n",
    "\n",
    "def get_image_clean(sub_ids, oxford, means):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 2)\n",
    "    Input:\n",
    "        sub_ids {numpy array of strings}: ordered list of userIDs\n",
    "        oxford {pandas DataFrame of floats}: unscaled oxford features of users with 1+ face\n",
    "        means {list of float}: mean values for each feature averaged from train set,\n",
    "                    to replace missing values for userids with no face (train and test set)\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "                with mean values replacing missing entries\n",
    "    '''\n",
    "    # list of ids with at least one face on image: 7174 out of 9500 in train set\n",
    "    ox_list = np.sort(oxford['userId'].unique(), axis=None)\n",
    "    # list of ids in text_list who have no face metrics in oxford.csv (2326 in train set)\n",
    "    ox_noface = np.setdiff1d(sub_ids, ox_list)\n",
    "\n",
    "    # Create DataFrame for userids with no face (1 row per userid)\n",
    "    # values are mean metrics averaged from users with entries (training set)\n",
    "    ox_nf = pd.DataFrame(ox_noface, columns = ['userId'])\n",
    "    columns = oxford.columns[2:].tolist()\n",
    "    for column, mean in zip(columns, means):\n",
    "        ox_nf.insert(loc=ox_nf.shape[1], column=column, value=mean, allow_duplicates=True)\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='noface', value=1, allow_duplicates=True)\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    ox_nf.insert(loc=ox_nf.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    ox_nf.set_index('userId', inplace=True)\n",
    "\n",
    "    # Format DataFrame from userids with 1+ face\n",
    "    # insert column 'noface' = 1 if no face in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='noface', value=0, allow_duplicates=True)\n",
    "    # list userIds with multiple faces (714 in train set)\n",
    "    ox_multiples = oxford['userId'][oxford['userId'].duplicated()].tolist()\n",
    "    # insert column 'multiface' = 1 if many faces in image, else 0\n",
    "    oxford.insert(loc=oxford.shape[1], column='multiface', value=0, allow_duplicates=True)\n",
    "    multi_mask = pd.Series([uid in ox_multiples for uid in oxford['userId']])\n",
    "    i = oxford[multi_mask].index\n",
    "    oxford.loc[i, 'multiface'] = 1\n",
    "    # drop duplicate entries with same userId (keep first entry per userId)\n",
    "    oxford.drop_duplicates(subset ='userId', keep='first', inplace=True)\n",
    "\n",
    "    # merge the two DataFrames\n",
    "    oxford.drop(['faceID'], axis=1, inplace=True)\n",
    "    oxford.set_index('userId', inplace=True)\n",
    "    image_data = pd.concat([ox_nf, oxford], axis=0, sort=False).sort_values(by=['userId'])\n",
    "\n",
    "    if not np.array_equal(image_data.index, sub_ids):\n",
    "        raise Exception('userIds do not match between oxford file and id list')\n",
    "\n",
    "        ### ADD THE HIGH LEVEL PRE-PROCESSING WHEN DONE (22 NOV)\n",
    "        \n",
    "    return image_data\n",
    "\n",
    "\n",
    "def get_image_raw(data_dir):\n",
    "    '''\n",
    "    Purpose: preprocess oxford metrics derived from profile pictures (part 1)\n",
    "    Input\n",
    "        input_dir {string} : path to input_directory (ex, \"~/Train\")\n",
    "    Output:\n",
    "        image_data {pandas DataFrame of float}: unscaled oxford image data\n",
    "    '''\n",
    "    # Load data of oxford features extracted from profile picture (face metrics)\n",
    "    # 7915 entries; some users have no face, some have multiple faces on image.\n",
    "    # userids with 1+ face on image: 7174 out of 9500 (train set)\n",
    "    # duplicated entries (userids with > 1 face on same image): 741 in train set\n",
    "    oxford = pd.read_csv(os.path.join(data_dir, \"Image\", \"oxford.csv\"), sep = ',')\n",
    "    oxford = oxford.sort_values(by=['userId'])\n",
    "    '''\n",
    "    NOTE: headPose_pitch has NO RANGE, drop that feature\n",
    "    '''\n",
    "    oxford.drop(['headPose_pitch'], axis=1, inplace=True)\n",
    "\n",
    "    return oxford\n",
    "\n",
    "\n",
    "def get_likes_kept(data_dir, num_features) -> List[str]:\n",
    "    '''\n",
    "    Purpose: get list of likes to keep as features\n",
    "    Input:\n",
    "        data_dir {str} : the parent input directory\n",
    "        num_features {int} : the number of likes to keep as features,\n",
    "                        starting from those with highest frequencies\n",
    "    Output:\n",
    "        freq_like_id {List of strings}: frequency of most frequent likes,\n",
    "                    (number = num_features), in descending ordered, indexed by like_id\n",
    "    '''\n",
    "    #Why return frequency?\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "    like_ids_to_keep = relation['like_id'].value_counts(sort=True, ascending=False)[:num_features] #This sorts features by frequency\n",
    "\n",
    "    #sort like indices (which are the keys associated with the values kepts)\n",
    "    likes_int64_list = sorted(like_ids_to_keep.keys()) # This sorts indices by like_id\n",
    "    likes_str_list = [str(l) for l in likes_int64_list]\n",
    "    return likes_str_list\n",
    "\n",
    "\n",
    "def get_relations(data_dir: str, sub_ids: List[str], like_ids_to_keep: List[str]):\n",
    "    '''\n",
    "    Purpose: preprocess relations dataset ('likes')\n",
    "\n",
    "    Input:\n",
    "        data_dir {str} -- the parent input directory\n",
    "        sub_ids {numpy array of strings} -- the ordered list of userids\n",
    "        like_ids_to_keep {List[str]} -- The list of page IDs to keep.\n",
    "\n",
    "    Returns:\n",
    "        relations_data -- multihot matrix of the like_id. Rows are indexed with userid, entries are boolean.\n",
    "    '''\n",
    "    relation = pd.read_csv(os.path.join(data_dir, \"Relation\", \"Relation.csv\")) #, index_col=1)\n",
    "    relation = relation.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    ## One HUGE step:\n",
    "    # likes_to_keep = like_ids_to_keep.keys()\n",
    "    # kept_relations = relation[relation.like_id.isin(likes_to_keep)]\n",
    "    # multi_hot_relations = pd.get_dummies(kept_relations, columns=[\"like_id\"], prefix=\"\")\n",
    "    # multi_hot = multi_hot_relations.groupby((\"userid\")).sum()\n",
    "    # return multi_hot_relations\n",
    "    ###\n",
    "    total_num_pages = len(like_ids_to_keep)\n",
    "    # Create a multihot likes matrix of booleans (rows = userids, cols = likes), by batch\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Create empty DataFrame with sub_ids as index list\n",
    "    relation_data = pd.DataFrame(sub_ids, columns = ['userid'])\n",
    "    relation_data.set_index('userid', inplace=True)\n",
    "\n",
    "    for start_index in range(0, total_num_pages, batch_size):\n",
    "        end_index = min(start_index + batch_size, total_num_pages)\n",
    "\n",
    "        # sets are better for membership testing than lists.\n",
    "        like_ids_for_this_batch = set(like_ids_to_keep[start_index:end_index])\n",
    "\n",
    "        filtered_table = relation[relation['like_id'].isin(like_ids_for_this_batch)]\n",
    "        ## THIS is the slow part:\n",
    "        relHot = pd.get_dummies(filtered_table, columns=['like_id'], prefix=\"\", prefix_sep=\"\")\n",
    "        ##\n",
    "        relHot = relHot.groupby(['userid']).sum().astype(float) # this makes userid the index\n",
    "\n",
    "        relation_data = pd.concat([relation_data, relHot], axis=1, sort=True)\n",
    "\n",
    "    relation_data = relation_data.reindex(like_ids_to_keep, axis=1)\n",
    "    relation_data.fillna(0.0, inplace=True)\n",
    "    relation_data = relation_data.astype(\"bool\")\n",
    "\n",
    "    # will be different if users in relation.csv are not in sub_ids\n",
    "    if not np.array_equal(relation_data.index, sub_ids):\n",
    "        raise Exception(f\"\"\"userIds do not match between relation file and id list:\n",
    "    {relation_data.index}\n",
    "    {sub_ids}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    return relation_data\n",
    "\n",
    "\n",
    "def make_label_dict(labels):\n",
    "    '''\n",
    "    Purpose: make dictionnary of labels from pandas DataFrame\n",
    "    Input:\n",
    "        labels {pandas DataFrame}: labels ordered per userids (alphabetical order)\n",
    "    Output:\n",
    "        labels_dict {dictionary of pandas DataFrames}: labels (one entry per metric) ordered alphabetically\n",
    "                by userid for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    gender = labels['gender']\n",
    "\n",
    "    age_grps = labels[['age_xx_24', 'age_25_34', 'age_35_49', 'age_50_xx']]\n",
    "\n",
    "    '''\n",
    "    Note: : each DataFrames (value) is indexed by userid in labels_dict\n",
    "    '''\n",
    "    labels_dict = {}\n",
    "    labels_dict['userid'] = labels.index\n",
    "    labels_dict['gender'] = gender\n",
    "    labels_dict['age_grps'] = age_grps\n",
    "    labels_dict['ope'] = labels['ope']\n",
    "    labels_dict['con'] = labels['con']\n",
    "    labels_dict['ext'] = labels['ext']\n",
    "    labels_dict['agr'] = labels['agr']\n",
    "    labels_dict['neu'] = labels['neu']\n",
    "\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def preprocess_labels(data_dir, sub_ids):\n",
    "    '''\n",
    "    Purpose: preprocess entry labels from training set\n",
    "    Input:\n",
    "        datadir {string} : path to training data directory\n",
    "        sub_ids {numpy array of strings}: list of subject ids ordered alphabetically\n",
    "    Output:\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    '''\n",
    "    labels = pd.read_csv(os.path.join(data_dir, \"Profile\", \"Profile.csv\"))\n",
    "    labels = labels.sort_values(by=['userid'])\n",
    "    # check if same subject ids in labels and sub_ids\n",
    "    if not np.array_equal(labels['userid'].to_numpy(), sub_ids):\n",
    "        raise Exception('userIds do not match between profiles labels and id list')\n",
    "\n",
    "    def age_group_id(age_str: str) -> int:\n",
    "        \"\"\"Returns the age group category ID (an integer from 0 to 3) for the given age (string)\n",
    "\n",
    "        Arguments:\n",
    "            age_str {str} -- the age\n",
    "\n",
    "        Returns:\n",
    "            int -- the ID of the age group: 0 for xx-24, 1 for 25-34, 2 for 35-49 and 3 for 50-xx.\n",
    "        \"\"\"\n",
    "        age = int(age_str)\n",
    "        if age <= 24:\n",
    "            return 0\n",
    "        elif age <= 34:\n",
    "            return 1\n",
    "        elif age <= 49:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    labels = labels.assign(age_group = lambda dt: pd.Series([age_group_id(age_str) for age_str in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_xx_24 = lambda dt: pd.Series([int(age) <= 24 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_25_34 = lambda dt: pd.Series([25 <= int(age) <= 34 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_35_49 = lambda dt: pd.Series([35 <= int(age) <= 49 for age in dt[\"age\"]]))\n",
    "    # labels = labels.assign(age_50_xx = lambda dt: pd.Series([50 <= int(age) for age in dt[\"age\"]]))\n",
    "\n",
    "    labels = labels.drop(['Unnamed: 0'], axis=1)\n",
    "    labels.set_index('userid', inplace=True)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def preprocess_train(data_dir, num_likes=10_000, scaling=True):\n",
    "    '''\n",
    "    Purpose: preprocesses training dataset (with labels) and returns scaled features,\n",
    "    labels and parameters to scale the test data set\n",
    "    Input\n",
    "        data_dir {string}: path to ~/Train data directory\n",
    "        num_likes {int}: number of like_ids to keep as features\n",
    "        scaling {boolean}: if True, Robust scaling applied to data; no scaling if False                \n",
    "    Output:\n",
    "        train_features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        **(updated:)features_q10_q90 {tupple of 2 pandas Series}: series of 10th and 90th quantile values of\n",
    "                text + image features from train dataset, to be used to scale test data.\n",
    "                Note that the multihot relation features do not necessitate scaling.\n",
    "        image_means {list of float}: means from oxford dataset to replace missing entries in oxford test set\n",
    "        likes_kept {list of strings}: ordered likes_ids to serve as columns for test set relation features matrix\n",
    "        train_labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "\n",
    "    TO CONSIDER: convert outputted pandas to tensorflow tf.data.Dataset...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_means = image_data_raw.iloc[:, 2:].mean().tolist()\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    Update: scaling w RobustScaler rather than MinMaxScaler algo, due to outliers\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = features_to_scale.min()\n",
    "    #feat_max = features_to_scale.max()\n",
    "    feat_q10 = features_to_scale.quantile(q = 0.10)\n",
    "    feat_q90 = features_to_scale.quantile(q = 0.90)\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    #features_min_max = (feat_min, feat_max)\n",
    "    if scaling:\n",
    "        feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "    else:\n",
    "        feat_scaled = features_to_scale\n",
    "    features_q10_q90 = (feat_q10, feat_q90)\n",
    "\n",
    "    #if DEBUG:\n",
    "    #    likes_kept = [str(v) for v in range(num_likes)]\n",
    "    #else:\n",
    "    likes_kept = get_likes_kept(data_dir, num_likes)\n",
    "\n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    train_features = pd.concat([feat_scaled, image_data.iloc[:, -2:], likes_data], axis=1, sort=False)\n",
    "\n",
    "    # DataFrame of training set labels\n",
    "    train_labels = preprocess_labels(data_dir, sub_ids)\n",
    "\n",
    "    #return train_features, features_min_max, image_means, likes_kept, train_labels\n",
    "    return train_features, features_q10_q90, image_means, likes_kept, train_labels\n",
    "\n",
    "\n",
    "#def preprocess_test(data_dir, min_max_train, image_means_train, likes_kept_train):\n",
    "def preprocess_test(data_dir, q10_q90_train, image_means_train, likes_kept_train, scaling=True):\n",
    "    '''\n",
    "    Purpose: preprocesses test dataset (no labels)\n",
    "    Input:\n",
    "        datadir {string}: path to Test data directory\n",
    "        (**updated)q10_q90_train {tupple of two numpy arrays}: 10th and 90th quantile values for\n",
    "                concatenated text and image features (from train set)\n",
    "        image_means_train {list of float}: means from oxford training dataset to replace\n",
    "                missing entries in oxford test set\n",
    "        likes_kept_train {list of strings}: most frequent likes_ids from train set\n",
    "                (ordered by frequency) to serve as columns in relation features matrix\n",
    "        scaling {boolean}: if True, Robust scaling applied to data; no scaling if False       \n",
    "    Output:\n",
    "        test_features {pandas DataFrame}: vectorized features of test set\n",
    "    '''\n",
    "    # sub_ids: a numpy array of subject ids ordered alphabetically.\n",
    "    # text_data: a pandas DataFrame of unscaled text data (liwc and nrc)\n",
    "    sub_ids, text_data = get_text_data(data_dir)\n",
    "\n",
    "    # image_data: pandas dataframe of oxford data\n",
    "    # image_min_max: a tupple of 2 pandas series, the min and max values from oxford training features\n",
    "    image_data_raw = get_image_raw(data_dir)\n",
    "    image_data = get_image_clean(sub_ids, image_data_raw, image_means_train)\n",
    "\n",
    "    '''\n",
    "    Note: Scale the text and image data BEFORE concatenating with relations\n",
    "    '''\n",
    "    features_to_scale = pd.concat([text_data, image_data.iloc[:, :-2]], axis=1, sort=False)\n",
    "    #feat_min = min_max_train[0]\n",
    "    #feat_max = min_max_train[1]\n",
    "    feat_q10 = q10_q90_train[0]\n",
    "    feat_q90 = q10_q90_train[1]\n",
    "\n",
    "    #feat_scaled = (features_to_scale - feat_min) / (feat_max - feat_min)\n",
    "    if scaling:\n",
    "        feat_scaled = (features_to_scale - feat_q10) / (feat_q90 - feat_q10)\n",
    "    else:\n",
    "        feat_scaled = features_to_scale\n",
    "    \n",
    "    # multi-hot matrix of likes from train data\n",
    "    likes_data = get_relations(data_dir, sub_ids, likes_kept_train)\n",
    "\n",
    "    # concatenate all scaled features into a single DataFrame\n",
    "    test_features = pd.concat([feat_scaled, image_data.iloc[:, -2:], likes_data], axis=1, sort=False)\n",
    "\n",
    "    return test_features\n",
    "\n",
    "\n",
    "def get_train_val_sets(features, labels, val_prop):\n",
    "    '''\n",
    "    Purpose: Splits training dataset into a train and a validation set of\n",
    "    ratio determined by val_prop (x = features, y = labels)\n",
    "    Input\n",
    "        features {pandas DataFrame}: vectorized features scaled between 0 and 1\n",
    "                for each user id in the training set, concatenated for all modalities\n",
    "                (order = text + image + relation), with userid as DataFrame index.\n",
    "        labels {pandas DataFrame}: labels ordered by userid (alphabetically)\n",
    "                for the training set, with userids as index.\n",
    "        val_prop {float between 0 and 1}: proportion of sample in validation set\n",
    "                    (e.g. 0.2 = 20% validation, 80% training)\n",
    "    Output:\n",
    "        x_train, x_val {pandas DataFrames}: vectorized features for train and validation sets\n",
    "        y_train, y_val {pandas DataFrames}: train and validation set labels\n",
    "\n",
    "    TO DO: convert outputted pandas to tensorflow tf.data.Dataset?...\n",
    "    https://www.tensorflow.org/guide/data\n",
    "    '''\n",
    "    # NOTE: UNUSED\n",
    "    from sklearn import model_selection\n",
    "    x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "        features, # training features to split\n",
    "        labels, # training labels to split\n",
    "        test_size = val_prop, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "        shuffle= True,\n",
    "        #stratify = y_data[:1],\n",
    "        # random_state = 42  # can use to always obtain the same train/validation split\n",
    "        )\n",
    "\n",
    "    return x_train, x_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/teaching/user07/.local/lib/python3.7/site-packages/ipykernel_launcher.py:76: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# to preprocess the training dataset:\n",
    "# 1. set path to Train directory\n",
    "# 2. call preprocess_train\n",
    "\n",
    "train_path = '../Train' #modify if working from other directory\n",
    "\n",
    "train_features, features_q10_q90, image_means, likes_kept, train_labels = preprocess_train(train_path, num_likes=10_000, scaling=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    train_features, # training features to split\n",
    "    train_labels, # training labels to split\n",
    "    test_size = 0.2, # between 0 and 1, proportion of sample in validation set (e.g., 0.2)\n",
    "    shuffle= True,\n",
    "    stratify = train_labels['gender']\n",
    "    # random_state = 42  # can use to always obtain the same train/validation split\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>Numerals</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>...</th>\n",
       "      <th>10150131036435262</th>\n",
       "      <th>10150136203045543</th>\n",
       "      <th>10150138573815473</th>\n",
       "      <th>10150145087245298</th>\n",
       "      <th>10150145163490188</th>\n",
       "      <th>10150145214185538</th>\n",
       "      <th>10150147152190368</th>\n",
       "      <th>10150154095435553</th>\n",
       "      <th>10150157058260374</th>\n",
       "      <th>10150169313485249</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>74ddafbef361165f17b988990447e0f7</td>\n",
       "      <td>149</td>\n",
       "      <td>12.42</td>\n",
       "      <td>25.50</td>\n",
       "      <td>79.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.95</td>\n",
       "      <td>11.41</td>\n",
       "      <td>6.71</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2b0734f33b86d34a9a2c720c8312be0a</td>\n",
       "      <td>171</td>\n",
       "      <td>19.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>86.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.63</td>\n",
       "      <td>11.70</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4f707bb35f4804b8928141b8845a9869</td>\n",
       "      <td>174</td>\n",
       "      <td>19.33</td>\n",
       "      <td>23.56</td>\n",
       "      <td>79.89</td>\n",
       "      <td>1.15</td>\n",
       "      <td>47.70</td>\n",
       "      <td>9.77</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47f53d9fbd9e5443cf5ea733b69a8e6c</td>\n",
       "      <td>48</td>\n",
       "      <td>16.00</td>\n",
       "      <td>43.75</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.33</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4dc9915cb305be43aad6536c7edad4de</td>\n",
       "      <td>62</td>\n",
       "      <td>8.86</td>\n",
       "      <td>22.58</td>\n",
       "      <td>67.74</td>\n",
       "      <td>9.68</td>\n",
       "      <td>38.71</td>\n",
       "      <td>8.06</td>\n",
       "      <td>6.45</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   WC    WPS  Sixltr    Dic  Numerals  funct  \\\n",
       "userId                                                                         \n",
       "74ddafbef361165f17b988990447e0f7  149  12.42   25.50  79.87      0.00  42.95   \n",
       "2b0734f33b86d34a9a2c720c8312be0a  171  19.00   22.22  86.55      0.00  52.63   \n",
       "4f707bb35f4804b8928141b8845a9869  174  19.33   23.56  79.89      1.15  47.70   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c   48  16.00   43.75  16.67      0.00   8.33   \n",
       "4dc9915cb305be43aad6536c7edad4de   62   8.86   22.58  67.74      9.68  38.71   \n",
       "\n",
       "                                  pronoun  ppron     i    we  ...  \\\n",
       "userId                                                        ...   \n",
       "74ddafbef361165f17b988990447e0f7    11.41   6.71  2.68  0.00  ...   \n",
       "2b0734f33b86d34a9a2c720c8312be0a    11.70   8.77  0.00  0.58  ...   \n",
       "4f707bb35f4804b8928141b8845a9869     9.77   3.45  1.72  0.00  ...   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c     2.08   0.00  0.00  0.00  ...   \n",
       "4dc9915cb305be43aad6536c7edad4de     8.06   6.45  1.61  0.00  ...   \n",
       "\n",
       "                                  10150131036435262  10150136203045543  \\\n",
       "userId                                                                   \n",
       "74ddafbef361165f17b988990447e0f7              False              False   \n",
       "2b0734f33b86d34a9a2c720c8312be0a              False              False   \n",
       "4f707bb35f4804b8928141b8845a9869              False              False   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c              False              False   \n",
       "4dc9915cb305be43aad6536c7edad4de              False              False   \n",
       "\n",
       "                                  10150138573815473  10150145087245298  \\\n",
       "userId                                                                   \n",
       "74ddafbef361165f17b988990447e0f7              False              False   \n",
       "2b0734f33b86d34a9a2c720c8312be0a              False              False   \n",
       "4f707bb35f4804b8928141b8845a9869              False              False   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c              False              False   \n",
       "4dc9915cb305be43aad6536c7edad4de              False              False   \n",
       "\n",
       "                                  10150145163490188  10150145214185538  \\\n",
       "userId                                                                   \n",
       "74ddafbef361165f17b988990447e0f7              False              False   \n",
       "2b0734f33b86d34a9a2c720c8312be0a              False              False   \n",
       "4f707bb35f4804b8928141b8845a9869              False              False   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c              False              False   \n",
       "4dc9915cb305be43aad6536c7edad4de              False              False   \n",
       "\n",
       "                                  10150147152190368  10150154095435553  \\\n",
       "userId                                                                   \n",
       "74ddafbef361165f17b988990447e0f7              False              False   \n",
       "2b0734f33b86d34a9a2c720c8312be0a              False              False   \n",
       "4f707bb35f4804b8928141b8845a9869              False              False   \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c              False              False   \n",
       "4dc9915cb305be43aad6536c7edad4de              False              False   \n",
       "\n",
       "                                  10150157058260374  10150169313485249  \n",
       "userId                                                                  \n",
       "74ddafbef361165f17b988990447e0f7              False              False  \n",
       "2b0734f33b86d34a9a2c720c8312be0a              False              False  \n",
       "4f707bb35f4804b8928141b8845a9869              False              False  \n",
       "47f53d9fbd9e5443cf5ea733b69a8e6c              False              False  \n",
       "4dc9915cb305be43aad6536c7edad4de              False              False  \n",
       "\n",
       "[5 rows x 10156 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()\n",
    "############################ END OF OLD PREPROCESSING EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns[91:156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_IMAGES=\"/home/mila/teaching/user07/Train/Image/oxford.csv\"\n",
    "# oxford = pd.read_csv(PATH_IMAGES)\n",
    "# oxford = oxford.rename(columns={\"userId\":\"userid\"})\n",
    "# oxford.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford_train = x_train.iloc[:,91:156]\n",
    "oxford_val = x_val.iloc[:,91:156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eyebrowRightOuter_x</th>\n",
       "      <th>eyebrowRightInner_x</th>\n",
       "      <th>eyebrowRightOuter_y</th>\n",
       "      <th>eyebrowRightInner_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>e730faad3a9c31f04ca603ebfc133ffb</td>\n",
       "      <td>139.50000</td>\n",
       "      <td>122.600000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>40.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71113ca6993812e7d0ebd2acc91d8923</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8829e40d59d36e54bcede0bdd2d5bd91</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76390a30d39df13f3dac6fe809d67d52</td>\n",
       "      <td>134.30000</td>\n",
       "      <td>117.700000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>40.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2457db378f14d65ebcf7adedf6950cae</td>\n",
       "      <td>101.80000</td>\n",
       "      <td>70.200000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>101.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563e8daa9b7161aed01e685e9afa95d8</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bd7fee1f201e704829c8759b5f57aac9</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>132.600000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>29.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1abb7b4a86abe8f54ccb27c16e131f26</td>\n",
       "      <td>97.20000</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>31.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2f01cddc19d8950a9dc84659c171c910</td>\n",
       "      <td>129.31957</td>\n",
       "      <td>106.935944</td>\n",
       "      <td>67.210385</td>\n",
       "      <td>66.812129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90568589eb85b0d24a68bf56b9a1a7ec</td>\n",
       "      <td>144.80000</td>\n",
       "      <td>120.800000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  eyebrowRightOuter_x  eyebrowRightInner_x  \\\n",
       "userId                                                                       \n",
       "e730faad3a9c31f04ca603ebfc133ffb            139.50000           122.600000   \n",
       "71113ca6993812e7d0ebd2acc91d8923            129.31957           106.935944   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            129.31957           106.935944   \n",
       "76390a30d39df13f3dac6fe809d67d52            134.30000           117.700000   \n",
       "2457db378f14d65ebcf7adedf6950cae            101.80000            70.200000   \n",
       "...                                               ...                  ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8            129.31957           106.935944   \n",
       "bd7fee1f201e704829c8759b5f57aac9            154.00000           132.600000   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26             97.20000            87.400000   \n",
       "2f01cddc19d8950a9dc84659c171c910            129.31957           106.935944   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec            144.80000           120.800000   \n",
       "\n",
       "                                  eyebrowRightOuter_y  eyebrowRightInner_y  \n",
       "userId                                                                      \n",
       "e730faad3a9c31f04ca603ebfc133ffb            42.500000            40.300000  \n",
       "71113ca6993812e7d0ebd2acc91d8923            67.210385            66.812129  \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            67.210385            66.812129  \n",
       "76390a30d39df13f3dac6fe809d67d52            43.000000            40.200000  \n",
       "2457db378f14d65ebcf7adedf6950cae            99.000000           101.100000  \n",
       "...                                               ...                  ...  \n",
       "563e8daa9b7161aed01e685e9afa95d8            67.210385            66.812129  \n",
       "bd7fee1f201e704829c8759b5f57aac9            25.200000            29.900000  \n",
       "1abb7b4a86abe8f54ccb27c16e131f26            31.500000            31.400000  \n",
       "2f01cddc19d8950a9dc84659c171c910            67.210385            66.812129  \n",
       "90568589eb85b0d24a68bf56b9a1a7ec            80.000000            79.200000  \n",
       "\n",
       "[7600 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train[['eyebrowRightOuter_x','eyebrowRightInner_x', 'eyebrowRightOuter_y','eyebrowRightInner_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,y1,x2,y2):\n",
    "    return np.sqrt(np.square(x1-x2)+np.square(y1-y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Engineering interesting features for:\n",
    "-gender\n",
    "\n",
    "-age group\n",
    "\n",
    "Assumption: Oxford features not useful for personality...\n",
    "\n",
    "Scaling = divide by face rectangle width/height the new feature\n",
    "\n",
    "New features:\n",
    "o eyebrow length AVG X\n",
    "o width nose root X\n",
    "o length nose root to tip X should be good...\n",
    "o width altar AVG X tip - top\n",
    "o width lips = width upper + width bottom X\n",
    "o width nose = altar to altar X\n",
    "o vert eye AVG X\n",
    "o hori eye AVG X\n",
    "o transversal length center of eye to nose tip! (normalize transversal) NO\n",
    "o length mouth X\n",
    "o bottomEye_to_mouth X avg\n",
    "\n",
    "Pandas tips:\n",
    "df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32) to assign a new column with result of operation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "oxford_train = oxford_train.assign(eyebrow_length=lambda x: (distance(x.eyebrowRightInner_x, x.eyebrowRightInner_y,\n",
    "                                                                        x.eyebrowRightOuter_x,x.eyebrowRightOuter_y)\n",
    "                                                             + distance(x.eyebrowLeftInner_x, x.eyebrowLeftInner_y,\n",
    "                                                                        x.eyebrowLeftOuter_x,x.eyebrowLeftOuter_y)\n",
    "                                                            )/2/x.faceRectangle_width\n",
    "                                  )\n",
    "\n",
    "oxford_train = oxford_train.assign(vert_eye=lambda x: (distance(x.eyeRightInner_x, x.eyeRightInner_y,\n",
    "                                                                        x.eyeRightOuter_x,x.eyeRightOuter_y)\n",
    "                                                             + distance(x.eyeLeftInner_x, x.eyeLeftInner_y,\n",
    "                                                                        x.eyeLeftOuter_x,x.eyeLeftOuter_y)\n",
    "                                                            )/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(hori_eye=lambda x: (distance(x.eyeRightTop_x, x.eyeRightTop_y,\n",
    "                                                                        x.eyeRightBottom_x,x.eyeRightBottom_y)\n",
    "                                                             + distance(x.eyeLeftTop_x, x.eyeLeftTop_y,\n",
    "                                                                        x.eyeLeftBottom_x,x.eyeLeftBottom_y)\n",
    "                                                            )/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(width_nose_root=lambda x: distance(x.noseRootLeft_x,x.noseRootLeft_y,\n",
    "                                                                     x.noseRootRight_x,x.noseRootRight_y)/x.faceRectangle_width )\n",
    "\n",
    "oxford_train = oxford_train.assign(nose_root_to_tip=lambda x: distance(np.abs(x.noseRootLeft_x-x.noseRootRight_x)/2,np.abs(x.noseRootLeft_y-x.noseRootRight_y)/2,\n",
    "                                                                     x.noseTip_x,x.noseTip_y)/x.faceRectangle_width )\n",
    "\n",
    "oxford_train = oxford_train.assign(width_nose=lambda x: distance(x.noseRightAlarOutTip_x, x.noseRightAlarOutTip_y,\n",
    "                                                                        x.noseLeftAlarOutTip_x,x.noseLeftAlarOutTip_y)/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(length_mouth=lambda x: distance( x.mouthRight_x, x.mouthRight_y, x.mouthLeft_x, x.mouthLeft_y)/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(bottomEye_to_mouth=lambda x: (distance( x.mouthRight_x, x.mouthRight_y, x.eyeRightBottom_x, x.eyeRightBottom_y)\n",
    "                                                                 +distance( x.mouthLeft_x, x.mouthLeft_y, x.eyeLeftBottom_x, x.eyeLeftBottom_y))/2/x.faceRectangle_width)\n",
    "\n",
    "oxford_train = oxford_train.assign(width_lips=lambda x: (distance( x.upperLipTop_x, x.upperLipTop_y, x.upperLipBottom_x, x.upperLipBottom_y)+\n",
    "                                  distance( x.underLipTop_x, x.underLipTop_y, x.underLipBottom_x, x.underLipBottom_y))/x.faceRectangle_width)\n",
    "\n",
    "#oxford_train = oxford_train.assign(pupil_to_nose_tip=lambda x: distance( pupilRight_x, pupilRight_y, upperLipBottom_x, upperLipBottom_y)+\n",
    "#                                  distance( underLipTop_x, underLipTop_y, underLipBottom_x, underLipBottom_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faceRectangle_width</th>\n",
       "      <th>faceRectangle_height</th>\n",
       "      <th>faceRectangle_left</th>\n",
       "      <th>faceRectangle_top</th>\n",
       "      <th>pupilLeft_x</th>\n",
       "      <th>pupilLeft_y</th>\n",
       "      <th>pupilRight_x</th>\n",
       "      <th>pupilRight_y</th>\n",
       "      <th>noseTip_x</th>\n",
       "      <th>noseTip_y</th>\n",
       "      <th>...</th>\n",
       "      <th>multiface</th>\n",
       "      <th>eyebrow_length</th>\n",
       "      <th>vert_eye</th>\n",
       "      <th>hori_eye</th>\n",
       "      <th>width_nose_root</th>\n",
       "      <th>nose_root_to_tip</th>\n",
       "      <th>width_nose</th>\n",
       "      <th>length_mouth</th>\n",
       "      <th>bottomEye_to_mouth</th>\n",
       "      <th>width_lips</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>e730faad3a9c31f04ca603ebfc133ffb</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>107.800000</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>130.40000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>117.100000</td>\n",
       "      <td>53.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318537</td>\n",
       "      <td>0.157646</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>0.139599</td>\n",
       "      <td>2.620150</td>\n",
       "      <td>0.325060</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.417309</td>\n",
       "      <td>0.108685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71113ca6993812e7d0ebd2acc91d8923</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>78.532533</td>\n",
       "      <td>59.513708</td>\n",
       "      <td>53.225395</td>\n",
       "      <td>81.355565</td>\n",
       "      <td>74.873165</td>\n",
       "      <td>115.75674</td>\n",
       "      <td>74.694428</td>\n",
       "      <td>98.746684</td>\n",
       "      <td>95.969438</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8829e40d59d36e54bcede0bdd2d5bd91</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>78.532533</td>\n",
       "      <td>59.513708</td>\n",
       "      <td>53.225395</td>\n",
       "      <td>81.355565</td>\n",
       "      <td>74.873165</td>\n",
       "      <td>115.75674</td>\n",
       "      <td>74.694428</td>\n",
       "      <td>98.746684</td>\n",
       "      <td>95.969438</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76390a30d39df13f3dac6fe809d67d52</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>47.400000</td>\n",
       "      <td>125.60000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>111.900000</td>\n",
       "      <td>60.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278923</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>0.032717</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>1.836289</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>0.431601</td>\n",
       "      <td>0.413034</td>\n",
       "      <td>0.125018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2457db378f14d65ebcf7adedf6950cae</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>111.200000</td>\n",
       "      <td>80.50000</td>\n",
       "      <td>109.100000</td>\n",
       "      <td>57.100000</td>\n",
       "      <td>146.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282793</td>\n",
       "      <td>0.172484</td>\n",
       "      <td>0.075764</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>1.346879</td>\n",
       "      <td>0.321295</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.388489</td>\n",
       "      <td>0.085919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  faceRectangle_width  faceRectangle_height  \\\n",
       "userId                                                                        \n",
       "e730faad3a9c31f04ca603ebfc133ffb            48.000000             48.000000   \n",
       "71113ca6993812e7d0ebd2acc91d8923            78.358307             78.532533   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            78.358307             78.532533   \n",
       "76390a30d39df13f3dac6fe809d67d52            67.000000             67.000000   \n",
       "2457db378f14d65ebcf7adedf6950cae           115.000000            115.000000   \n",
       "\n",
       "                                  faceRectangle_left  faceRectangle_top  \\\n",
       "userId                                                                    \n",
       "e730faad3a9c31f04ca603ebfc133ffb           95.000000          32.000000   \n",
       "71113ca6993812e7d0ebd2acc91d8923           59.513708          53.225395   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91           59.513708          53.225395   \n",
       "76390a30d39df13f3dac6fe809d67d52           76.000000          28.000000   \n",
       "2457db378f14d65ebcf7adedf6950cae            0.000000          79.000000   \n",
       "\n",
       "                                  pupilLeft_x  pupilLeft_y  pupilRight_x  \\\n",
       "userId                                                                     \n",
       "e730faad3a9c31f04ca603ebfc133ffb   107.800000    46.800000     130.40000   \n",
       "71113ca6993812e7d0ebd2acc91d8923    81.355565    74.873165     115.75674   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91    81.355565    74.873165     115.75674   \n",
       "76390a30d39df13f3dac6fe809d67d52    93.500000    47.400000     125.60000   \n",
       "2457db378f14d65ebcf7adedf6950cae    29.100000   111.200000      80.50000   \n",
       "\n",
       "                                  pupilRight_y   noseTip_x   noseTip_y  ...  \\\n",
       "userId                                                                  ...   \n",
       "e730faad3a9c31f04ca603ebfc133ffb     46.300000  117.100000   53.700000  ...   \n",
       "71113ca6993812e7d0ebd2acc91d8923     74.694428   98.746684   95.969438  ...   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91     74.694428   98.746684   95.969438  ...   \n",
       "76390a30d39df13f3dac6fe809d67d52     48.800000  111.900000   60.700000  ...   \n",
       "2457db378f14d65ebcf7adedf6950cae    109.100000   57.100000  146.800000  ...   \n",
       "\n",
       "                                  multiface  eyebrow_length  vert_eye  \\\n",
       "userId                                                                  \n",
       "e730faad3a9c31f04ca603ebfc133ffb          0        0.318537  0.157646   \n",
       "71113ca6993812e7d0ebd2acc91d8923          0        0.286042  0.144742   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91          0        0.286042  0.144742   \n",
       "76390a30d39df13f3dac6fe809d67d52          0        0.278923  0.139435   \n",
       "2457db378f14d65ebcf7adedf6950cae          0        0.282793  0.172484   \n",
       "\n",
       "                                  hori_eye  width_nose_root  nose_root_to_tip  \\\n",
       "userId                                                                          \n",
       "e730faad3a9c31f04ca603ebfc133ffb  0.067875         0.139599          2.620150   \n",
       "71113ca6993812e7d0ebd2acc91d8923  0.060173         0.125329          1.712697   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91  0.060173         0.125329          1.712697   \n",
       "76390a30d39df13f3dac6fe809d67d52  0.032717         0.143354          1.836289   \n",
       "2457db378f14d65ebcf7adedf6950cae  0.075764         0.126114          1.346879   \n",
       "\n",
       "                                  width_nose  length_mouth  \\\n",
       "userId                                                       \n",
       "e730faad3a9c31f04ca603ebfc133ffb    0.325060      0.417000   \n",
       "71113ca6993812e7d0ebd2acc91d8923    0.287348      0.406576   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91    0.287348      0.406576   \n",
       "76390a30d39df13f3dac6fe809d67d52    0.288156      0.431601   \n",
       "2457db378f14d65ebcf7adedf6950cae    0.321295      0.460185   \n",
       "\n",
       "                                  bottomEye_to_mouth  width_lips  \n",
       "userId                                                            \n",
       "e730faad3a9c31f04ca603ebfc133ffb            0.417309    0.108685  \n",
       "71113ca6993812e7d0ebd2acc91d8923            0.422805    0.097812  \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            0.422805    0.097812  \n",
       "76390a30d39df13f3dac6fe809d67d52            0.413034    0.125018  \n",
       "2457db378f14d65ebcf7adedf6950cae            0.388489    0.085919  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faceRectangle_width', 'faceRectangle_height', 'faceRectangle_left',\n",
       "       'faceRectangle_top', 'pupilLeft_x', 'pupilLeft_y', 'pupilRight_x',\n",
       "       'pupilRight_y', 'noseTip_x', 'noseTip_y', 'mouthLeft_x', 'mouthLeft_y',\n",
       "       'mouthRight_x', 'mouthRight_y', 'eyebrowLeftOuter_x',\n",
       "       'eyebrowLeftOuter_y', 'eyebrowLeftInner_x', 'eyebrowLeftInner_y',\n",
       "       'eyeLeftOuter_x', 'eyeLeftOuter_y', 'eyeLeftTop_x', 'eyeLeftTop_y',\n",
       "       'eyeLeftBottom_x', 'eyeLeftBottom_y', 'eyeLeftInner_x',\n",
       "       'eyeLeftInner_y', 'eyebrowRightInner_x', 'eyebrowRightInner_y',\n",
       "       'eyebrowRightOuter_x', 'eyebrowRightOuter_y', 'eyeRightInner_x',\n",
       "       'eyeRightInner_y', 'eyeRightTop_x', 'eyeRightTop_y', 'eyeRightBottom_x',\n",
       "       'eyeRightBottom_y', 'eyeRightOuter_x', 'eyeRightOuter_y',\n",
       "       'noseRootLeft_x', 'noseRootLeft_y', 'noseRootRight_x',\n",
       "       'noseRootRight_y', 'noseLeftAlarTop_x', 'noseLeftAlarTop_y',\n",
       "       'noseRightAlarTop_x', 'noseRightAlarTop_y', 'noseLeftAlarOutTip_x',\n",
       "       'noseLeftAlarOutTip_y', 'noseRightAlarOutTip_x',\n",
       "       'noseRightAlarOutTip_y', 'upperLipTop_x', 'upperLipTop_y',\n",
       "       'upperLipBottom_x', 'upperLipBottom_y', 'underLipTop_x',\n",
       "       'underLipTop_y', 'underLipBottom_x', 'underLipBottom_y',\n",
       "       'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns',\n",
       "       'headPose_roll', 'headPose_yaw', 'noface', 'multiface',\n",
       "       'eyebrow_length', 'vert_eye', 'hori_eye', 'width_nose_root',\n",
       "       'nose_root_to_tip', 'width_nose', 'length_mouth', 'bottomEye_to_mouth',\n",
       "       'width_lips'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep the good columns\n",
    "\"\"\"\n",
    "oxford_train_modified = oxford_train[['faceRectangle_width', 'facialHair_mustache', 'facialHair_beard', 'facialHair_sideburns', 'eyebrow_length', 'vert_eye', 'hori_eye', 'width_nose_root',\n",
    "       'nose_root_to_tip', 'width_nose', 'length_mouth', 'bottomEye_to_mouth',\n",
    "       'width_lips','headPose_yaw', 'noface', 'multiface']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faceRectangle_width</th>\n",
       "      <th>facialHair_mustache</th>\n",
       "      <th>facialHair_beard</th>\n",
       "      <th>facialHair_sideburns</th>\n",
       "      <th>eyebrow_length</th>\n",
       "      <th>vert_eye</th>\n",
       "      <th>hori_eye</th>\n",
       "      <th>width_nose_root</th>\n",
       "      <th>nose_root_to_tip</th>\n",
       "      <th>width_nose</th>\n",
       "      <th>length_mouth</th>\n",
       "      <th>bottomEye_to_mouth</th>\n",
       "      <th>width_lips</th>\n",
       "      <th>headPose_yaw</th>\n",
       "      <th>noface</th>\n",
       "      <th>multiface</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>e730faad3a9c31f04ca603ebfc133ffb</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.318537</td>\n",
       "      <td>0.157646</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>0.139599</td>\n",
       "      <td>2.620150</td>\n",
       "      <td>0.325060</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.417309</td>\n",
       "      <td>0.108685</td>\n",
       "      <td>-11.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71113ca6993812e7d0ebd2acc91d8923</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8829e40d59d36e54bcede0bdd2d5bd91</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76390a30d39df13f3dac6fe809d67d52</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.278923</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>0.032717</td>\n",
       "      <td>0.143354</td>\n",
       "      <td>1.836289</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>0.431601</td>\n",
       "      <td>0.413034</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2457db378f14d65ebcf7adedf6950cae</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282793</td>\n",
       "      <td>0.172484</td>\n",
       "      <td>0.075764</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>1.346879</td>\n",
       "      <td>0.321295</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.388489</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563e8daa9b7161aed01e685e9afa95d8</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bd7fee1f201e704829c8759b5f57aac9</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305381</td>\n",
       "      <td>0.174046</td>\n",
       "      <td>0.086208</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>1.262422</td>\n",
       "      <td>0.298613</td>\n",
       "      <td>0.387678</td>\n",
       "      <td>0.420071</td>\n",
       "      <td>0.115979</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1abb7b4a86abe8f54ccb27c16e131f26</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.321263</td>\n",
       "      <td>0.143163</td>\n",
       "      <td>0.048812</td>\n",
       "      <td>0.133593</td>\n",
       "      <td>2.575829</td>\n",
       "      <td>0.286596</td>\n",
       "      <td>0.447920</td>\n",
       "      <td>0.414496</td>\n",
       "      <td>0.097647</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2f01cddc19d8950a9dc84659c171c910</td>\n",
       "      <td>78.358307</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.107732</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>1.712697</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.422805</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.536096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90568589eb85b0d24a68bf56b9a1a7ec</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309846</td>\n",
       "      <td>0.125196</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.121509</td>\n",
       "      <td>1.622391</td>\n",
       "      <td>0.314781</td>\n",
       "      <td>0.484267</td>\n",
       "      <td>0.420337</td>\n",
       "      <td>0.077408</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  faceRectangle_width  facialHair_mustache  \\\n",
       "userId                                                                       \n",
       "e730faad3a9c31f04ca603ebfc133ffb            48.000000               0.2000   \n",
       "71113ca6993812e7d0ebd2acc91d8923            78.358307               0.0941   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            78.358307               0.0941   \n",
       "76390a30d39df13f3dac6fe809d67d52            67.000000               0.7000   \n",
       "2457db378f14d65ebcf7adedf6950cae           115.000000               0.0000   \n",
       "...                                               ...                  ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8            78.358307               0.0941   \n",
       "bd7fee1f201e704829c8759b5f57aac9           123.000000               0.0000   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26            36.000000               0.5000   \n",
       "2f01cddc19d8950a9dc84659c171c910            78.358307               0.0941   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec            95.000000               0.0000   \n",
       "\n",
       "                                  facialHair_beard  facialHair_sideburns  \\\n",
       "userId                                                                     \n",
       "e730faad3a9c31f04ca603ebfc133ffb          0.200000              0.300000   \n",
       "71113ca6993812e7d0ebd2acc91d8923          0.107732              0.080884   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91          0.107732              0.080884   \n",
       "76390a30d39df13f3dac6fe809d67d52          0.500000              0.600000   \n",
       "2457db378f14d65ebcf7adedf6950cae          0.000000              0.000000   \n",
       "...                                            ...                   ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8          0.107732              0.080884   \n",
       "bd7fee1f201e704829c8759b5f57aac9          0.000000              0.000000   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26          0.100000              0.100000   \n",
       "2f01cddc19d8950a9dc84659c171c910          0.107732              0.080884   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec          0.000000              0.000000   \n",
       "\n",
       "                                  eyebrow_length  vert_eye  hori_eye  \\\n",
       "userId                                                                 \n",
       "e730faad3a9c31f04ca603ebfc133ffb        0.318537  0.157646  0.067875   \n",
       "71113ca6993812e7d0ebd2acc91d8923        0.286042  0.144742  0.060173   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91        0.286042  0.144742  0.060173   \n",
       "76390a30d39df13f3dac6fe809d67d52        0.278923  0.139435  0.032717   \n",
       "2457db378f14d65ebcf7adedf6950cae        0.282793  0.172484  0.075764   \n",
       "...                                          ...       ...       ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8        0.286042  0.144742  0.060173   \n",
       "bd7fee1f201e704829c8759b5f57aac9        0.305381  0.174046  0.086208   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26        0.321263  0.143163  0.048812   \n",
       "2f01cddc19d8950a9dc84659c171c910        0.286042  0.144742  0.060173   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec        0.309846  0.125196  0.037895   \n",
       "\n",
       "                                  width_nose_root  nose_root_to_tip  \\\n",
       "userId                                                                \n",
       "e730faad3a9c31f04ca603ebfc133ffb         0.139599          2.620150   \n",
       "71113ca6993812e7d0ebd2acc91d8923         0.125329          1.712697   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91         0.125329          1.712697   \n",
       "76390a30d39df13f3dac6fe809d67d52         0.143354          1.836289   \n",
       "2457db378f14d65ebcf7adedf6950cae         0.126114          1.346879   \n",
       "...                                           ...               ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8         0.125329          1.712697   \n",
       "bd7fee1f201e704829c8759b5f57aac9         0.109624          1.262422   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26         0.133593          2.575829   \n",
       "2f01cddc19d8950a9dc84659c171c910         0.125329          1.712697   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec         0.121509          1.622391   \n",
       "\n",
       "                                  width_nose  length_mouth  \\\n",
       "userId                                                       \n",
       "e730faad3a9c31f04ca603ebfc133ffb    0.325060      0.417000   \n",
       "71113ca6993812e7d0ebd2acc91d8923    0.287348      0.406576   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91    0.287348      0.406576   \n",
       "76390a30d39df13f3dac6fe809d67d52    0.288156      0.431601   \n",
       "2457db378f14d65ebcf7adedf6950cae    0.321295      0.460185   \n",
       "...                                      ...           ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8    0.287348      0.406576   \n",
       "bd7fee1f201e704829c8759b5f57aac9    0.298613      0.387678   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26    0.286596      0.447920   \n",
       "2f01cddc19d8950a9dc84659c171c910    0.287348      0.406576   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec    0.314781      0.484267   \n",
       "\n",
       "                                  bottomEye_to_mouth  width_lips  \\\n",
       "userId                                                             \n",
       "e730faad3a9c31f04ca603ebfc133ffb            0.417309    0.108685   \n",
       "71113ca6993812e7d0ebd2acc91d8923            0.422805    0.097812   \n",
       "8829e40d59d36e54bcede0bdd2d5bd91            0.422805    0.097812   \n",
       "76390a30d39df13f3dac6fe809d67d52            0.413034    0.125018   \n",
       "2457db378f14d65ebcf7adedf6950cae            0.388489    0.085919   \n",
       "...                                              ...         ...   \n",
       "563e8daa9b7161aed01e685e9afa95d8            0.422805    0.097812   \n",
       "bd7fee1f201e704829c8759b5f57aac9            0.420071    0.115979   \n",
       "1abb7b4a86abe8f54ccb27c16e131f26            0.414496    0.097647   \n",
       "2f01cddc19d8950a9dc84659c171c910            0.422805    0.097812   \n",
       "90568589eb85b0d24a68bf56b9a1a7ec            0.420337    0.077408   \n",
       "\n",
       "                                  headPose_yaw  noface  multiface  \n",
       "userId                                                             \n",
       "e730faad3a9c31f04ca603ebfc133ffb    -11.400000       0          0  \n",
       "71113ca6993812e7d0ebd2acc91d8923     -0.536096       1          0  \n",
       "8829e40d59d36e54bcede0bdd2d5bd91     -0.536096       1          0  \n",
       "76390a30d39df13f3dac6fe809d67d52      8.300000       0          0  \n",
       "2457db378f14d65ebcf7adedf6950cae      2.200000       0          0  \n",
       "...                                        ...     ...        ...  \n",
       "563e8daa9b7161aed01e685e9afa95d8     -0.536096       1          0  \n",
       "bd7fee1f201e704829c8759b5f57aac9     30.900000       0          0  \n",
       "1abb7b4a86abe8f54ccb27c16e131f26     11.100000       0          0  \n",
       "2f01cddc19d8950a9dc84659c171c910     -0.536096       1          0  \n",
       "90568589eb85b0d24a68bf56b9a1a7ec     12.900000       0          0  \n",
       "\n",
       "[7600 rows x 16 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it got all the columns right\n",
    "oxford_train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
